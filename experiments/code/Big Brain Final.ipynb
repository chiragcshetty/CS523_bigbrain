{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d25bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import optim, nn\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0,'..')\n",
    "import copy\n",
    "\n",
    "#############################################\n",
    "## Copy of Inceptionv3, slightly modified for recording intermeridates\n",
    "#sys.path.append('/home/cshetty2/sct/pytorch')\n",
    "#import reformated_models.inception_modified as inception_modified\n",
    "\n",
    "## Modified Alexnet, with a'factor' by which it can be made 'fat' \n",
    "#import simple_model as sm\n",
    "\n",
    "## Placer libs of baechi\n",
    "#sys.path.append('/home/cshetty2/sct')\n",
    "#from placer.placer_lib import *\n",
    "##############################################\n",
    "\n",
    "#import dummyModels as dm\n",
    "import baechiTest_dummyModels as dm\n",
    "\n",
    "\n",
    "######## For profiler (some experiments. Not required) #################\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######## For debug purposes ONLY ########\n",
    "import ctypes, gc\n",
    "import psutil, os\n",
    "\n",
    "###############################Utilities#################################\n",
    "### From https://discuss.pytorch.org/t/how-pytorch-releases-variable-garbage/7277\n",
    "def memReport():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            print(type(obj), obj.size())\n",
    "    \n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "        \n",
    "## Print memory of all available GPU's\n",
    "def print_gpu_memory():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        #print(torch.cuda.get_device_name(i))\n",
    "        print(\"GPU:\", i)\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,8), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,8), 'GB')\n",
    "        #print(\"-----------------\")\n",
    "        #GPUtil.showUtilization()\n",
    "        print(\"-----------\")\n",
    "        \n",
    "\n",
    "def b2mb(x):\n",
    "    return round(x/1024**2,8)\n",
    "\n",
    "def b2gb(x):\n",
    "    return round(x/1024**3,8)\n",
    "\n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    sys._jupyter_stdout = sys.stdout\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "#########################################\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff1ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from random import expovariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0073f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baechi_units_bigbrain import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cda29",
   "metadata": {},
   "source": [
    "Experiment aims to demonstrate the advantage of packing training jobs on GPU (based on the resource requirements) rather than allotting integer number of GPUs per job (as container based approach would do)\n",
    "\n",
    "Measure: Throughput for these two cases and compare:\n",
    "- (1) one GPU allocation for each incoming jobs on FCFS basis\n",
    "- (2) decide a split of the incoming model among the two GPUs and run on best effort basis (the entire model maybe placed on one GPUs)\n",
    "\n",
    "Expectation: (2) should be more than (1) for two reasons:\n",
    "- granualr GPU allocation is more efficient\n",
    "- the model choosen itself runs faster when split across 2 gpus than 1 as described in next section\n",
    "\n",
    "Primitives:\n",
    "\n",
    "- GPUs : Setup consists of only 2 GPUs on one node\n",
    "- Jobs : All incoming jobs will be of same kind - to train a model dm.parallelModelThreeLayerSplit as described below\n",
    "- Training Script: run_train() is the main training routine. When a job arrives, a split for the model among two GPU's is \n",
    "- Job queue: jobs arrive as poisson process. Job queue maintains the cluster state and allots jobs with appropriate split while preventing OOMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a818dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, fct, repetable): \n",
    "    if model_name == \"inception_v3\":\n",
    "        model = inception_modified.inception_v3(pretrained=True)\n",
    "        inp_size_single = (3, 299, 299)\n",
    "        opt_size = 1000\n",
    "\n",
    "    if model_name == \"TallParallelModel\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, 512*factor)\n",
    "        model = dm.tallParallelModel(factor, repetable)\n",
    "        opt_size = 512*factor\n",
    "\n",
    "\n",
    "    if model_name == \"ParallelTwoLayer\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, int(512*factor))\n",
    "        model = dm.parallelTwoLayer(factor, repetable)\n",
    "        opt_size = 512*fct\n",
    "\n",
    "    if model_name == \"ParallelThreeLayer\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, int(512*factor))\n",
    "        model = dm.parallelThreeLayer(factor, repetable)\n",
    "        opt_size = 512*fct\n",
    "        \n",
    "    return model, inp_size_single, opt_size\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0319b0a",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5835308",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Performs training loop, Given a model (split across GPUs if needed) and other training parameters\n",
    "def run_train(model, batch_size, Nrun, inp_size_single, opt_size, \\\n",
    "              first_gpu, final_gpu, repetable ):     \n",
    "\n",
    "    ## Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.0001); \n",
    "    ## Loss Criterion\n",
    "    criterion = nn.MSELoss()\n",
    "    inp_size = (batch_size,) +  inp_size_single\n",
    "\n",
    "    result = []\n",
    "    times = []\n",
    "    \n",
    "    for run_no in range(Nrun):\n",
    "        with torch.cuda.stream(torch.cuda.Stream(device=first_gpu)):\n",
    "        #torch.cuda.synchronize(0);torch.cuda.synchronize(1);torch.cuda.synchronize(2);torch.cuda.synchronize(3)\n",
    "            if repetable:\n",
    "                labels = (torch.ones((batch_size, opt_size))*(0.1)).to(final_gpu)\n",
    "                inp = torch.ones(inp_size)* (0.000001) * (-1)**run_no; # Fixed set of inputs (but varying across epochs) \n",
    "            else:\n",
    "                labels = (torch.randn((batch_size, opt_size))*(0.1)).to(final_gpu)\n",
    "                inp = torch.randn(inp_size)* (0.000001); \n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            inp = inp.to(first_gpu); \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## forward run\n",
    "            output = model(inp)\n",
    "            ## compute loss\n",
    "            loss = criterion(output, labels )\n",
    "            ## Backward run\n",
    "            loss.backward(loss)\n",
    "            ## update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            #torch.cuda.synchronize(0);torch.cuda.synchronize(1);torch.cuda.synchronize(2);torch.cuda.synchronize(3)\n",
    "            output_cpu = output.cpu() # to synchronize the cpu thread with gpus (instead of torch.cuda.synchronize)\n",
    "            end = time.time()\n",
    "\n",
    "            times.append(1000*(end-start))\n",
    "        \n",
    "    if len(times)>10:\n",
    "        gpu_time = np.mean(times[10:])\n",
    "    else:\n",
    "        gpu_time = True\n",
    "        \n",
    "    print(output) ## Check: Should be same across runs if repetable=1\n",
    "    \n",
    "    #### Release memory\n",
    "    del inp\n",
    "    del output\n",
    "    del model\n",
    "    try:\n",
    "        del labels\n",
    "        del optimizer\n",
    "        del loss\n",
    "    except: pass\n",
    "    gc.collect()              ## To clean any circular references\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    #print(\"~\"*10);print_gpu_memory();print(\"~\"*10)\n",
    "\n",
    "    return gpu_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2b2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be865bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48fd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### GLOBALS #####################################3\n",
    "\n",
    "### dict of (gpu_id, fraction of gpu available)\n",
    "resource_manager   = {}  \n",
    "resource_manager[0]= available_mem #available_mem defined in \"baechi_units_bigbrain\"\n",
    "resource_manager[1]= available_mem # = gpu_memory - mem_occupied_by_library\n",
    "resource_manager[2]= available_mem # = 8000MB - 1500MB\n",
    "## GPU 3 is used for profiling. So not available\n",
    "\n",
    "### dict of job_id -> dict{gpu_allotted, status_flag, arrival_time, entry_time, exit_time}\n",
    "job_queue          = {}  \n",
    "\n",
    "end_exp_flag = [0] #flag to indicate end of experiment\n",
    "\n",
    "baseline_packing_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fddf1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_gpus = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1be38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_gpu():\n",
    "    if resource_manager[0] > 0.9*(1/baseline_packing_number)*available_mem :\n",
    "        return 0\n",
    "    elif resource_manager[1] > 0.9*(1/baseline_packing_number)*available_mem:\n",
    "        return 1\n",
    "    elif resource_manager[2] > 0.9*(1/baseline_packing_number)*available_mem:\n",
    "        return 2\n",
    "    else:\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989006c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_resource(mem_requirement, update_type):\n",
    "    '''\n",
    "    mem_requirement -> array containing memory requirement (or release) per gpu\n",
    "    update_type -> release/acquire\n",
    "    returns 1 if sucessful, and 0 otherwise\n",
    "    '''\n",
    "    if update_type == \"release\":\n",
    "        change =  1.0\n",
    "    elif update_type == \"acquire\":\n",
    "        change = -1.0\n",
    "        \n",
    "    temp = {}\n",
    "    for i in resource_manager:\n",
    "        temp[i] = resource_manager[i] + mem_requirement[i]*change\n",
    "        if temp[i] <0:\n",
    "            print(\"NEGATIVE MEMORY! Allotment not successful\")\n",
    "            return 0\n",
    "        \n",
    "    for i in resource_manager:\n",
    "        resource_manager[i] = temp[i]\n",
    "        device_list[i]['memory_size'] = resource_manager[i]\n",
    "    return 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb469bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(job_id, algo, model, fct, batch_size, Nrun, done_flag, exit_time, first_gpu, final_gpu ): \n",
    "    \n",
    "\n",
    "    avg_gpu_time = run_train(model, batch_size, Nrun, inp_size_single, opt_size, \\\n",
    "              first_gpu, final_gpu, repetable)\n",
    "    #del model\n",
    "    #gc.collect()              ## To clean any circular references\n",
    "    #torch.cuda.empty_cache()\n",
    "          \n",
    "    done_flag[0] = avg_gpu_time\n",
    "    exit_time[0] = time.time()\n",
    "    print(\"Mean time taken:\", avg_gpu_time)\n",
    "\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9beaade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_arrivals(rate, T_exp):\n",
    "    exp_start_time  = time.time()\n",
    "    t = exp_start_time \n",
    "    job_id = 0\n",
    "    \n",
    "    while t < exp_start_time + T_exp:\n",
    "        job_id = job_id+1\n",
    "        job_queue[job_id] = {'gpu':None, 'status_flag':[0], \\\n",
    "                             'arrival_time':[time.time()], 'entry_time':[0], 'exit_time':[0]}\n",
    "        time.sleep(expovariate(rate))\n",
    "        t = time.time()\n",
    "        \n",
    "    end_exp_flag[0] = 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a4be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 5\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 5\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 6\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 6\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 6\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 18.936107898580616\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 29.512626549293255\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 32.207905012985755\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 34.838474207911\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 35.65606166576517\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  5\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  5\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 40.23744402260616\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 6\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 10\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 10\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.82815607662859\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.32080860795646\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.77522455412766\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.372405677006164\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 7\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.40713093198579\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 7\n",
      "Jobs Completed:  11\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 42.610712709098024\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.35907301409491\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 6\n",
      "Jobs Completed:  13\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.31286009426775\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 6\n",
      "Jobs Completed:  14\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 6\n",
      "Jobs Completed:  14\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 6\n",
      "Jobs Completed:  14\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.44780816703007\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 7\n",
      "Jobs Completed:  15\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  15\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  15\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.69044303894043\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.59533457920469\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  17\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.986816800873854\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  18\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.724415647572485\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 7\n",
      "Jobs Completed:  19\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  19\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.912167943757154\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 8\n",
      "Jobs Completed:  20\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.827534412515575\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  21\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.742883353397765\n",
      "Baseline:\n",
      "Gpu_alotted: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  22\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.66558311725485\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  23\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 9\n",
      "Jobs Completed:  23\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.913006650990454\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 11\n",
      "Jobs Completed:  24\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 12\n",
      "Jobs Completed:  24\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  24\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06],\n",
      "        [-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06],\n",
      "        [-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06],\n",
      "        ...,\n",
      "        [-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06],\n",
      "        [-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06],\n",
      "        [-2.7442e-06, -2.7442e-06, -2.7442e-06,  ..., -2.7442e-06,\n",
      "         -2.7442e-06, -2.7442e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 42.66405763297245\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 12\n",
      "Jobs Completed:  25\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.299009750629295\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  26\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.98530022851352\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 12\n",
      "Jobs Completed:  27\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.29930229844718\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 12\n",
      "Jobs Completed:  28\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 14\n",
      "Jobs Completed:  28\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.51155909176531\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  29\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.22342695038894\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 14\n",
      "Jobs Completed:  30\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.24787787733407\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.895445889440076\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  32\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 12\n",
      "Jobs Completed:  32\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  32\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.14023833439268\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 13\n",
      "Jobs Completed:  33\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 14\n",
      "Jobs Completed:  33\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.04015130010144\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 16\n",
      "Jobs Completed:  34\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 18\n",
      "Jobs Completed:  34\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.00945025476916\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 18\n",
      "Jobs Completed:  35\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.959788618416624\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 17\n",
      "Jobs Completed:  36\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.998256782005576\n",
      "Baseline:\n",
      "Gpu_alotted: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 16\n",
      "Jobs Completed:  37\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 18\n",
      "Jobs Completed:  37\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.84372372462832\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 19\n",
      "Jobs Completed:  38\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.12175925024624\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 21\n",
      "Jobs Completed:  39\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.14734074165081\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 22\n",
      "Jobs Completed:  40\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.619886365430105\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 21\n",
      "Jobs Completed:  41\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 22\n",
      "Jobs Completed:  41\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  41\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 47.545759431247056\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  42\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.478912189089016\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  43\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.312222250576674\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  44\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken: 44.24114227294922\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 25\n",
      "Jobs Completed:  45\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  45\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.88217653077224\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  46\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 25\n",
      "Jobs Completed:  46\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.38548252500337\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.247581218851025\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  48\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 25\n",
      "Jobs Completed:  48\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.9910170785312\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  49\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.218836850133435\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 24\n",
      "Jobs Completed:  50\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 25\n",
      "Jobs Completed:  50\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 27\n",
      "Jobs Completed:  50\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.68006170207057\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  51\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.016727217312514\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  52\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.01536550192997\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 27\n",
      "Jobs Completed:  53\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.66044738374907\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 26\n",
      "Jobs Completed:  54\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 28\n",
      "Jobs Completed:  54\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.59975150535847\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 2\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 28\n",
      "Jobs Completed:  55\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 29\n",
      "Jobs Completed:  55\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.942648657437026\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 0\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.62945214633284\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 28\n",
      "Jobs Completed:  57\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 9\n",
      "Jobs waiting: 30\n",
      "Jobs Completed:  57\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 44.05193493284028\n",
      "Baseline:\n",
      "Gpu_alotted: None\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.36578161963101\n",
      "Baseline:\n",
      "Gpu_alotted: 1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 8\n",
      "Jobs waiting: 31\n",
      "Jobs Completed:  59\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "############### MAIN #########################\n",
    "\n",
    "T_exp      = 100        # (in sec) Time for which the exp will run\n",
    "rate       = 1       # job arrival rate\n",
    "Nrun       = 300      \n",
    "batch_size = 32\n",
    "fct        = 1\n",
    "algo       = 'baseline'  # 'baseline', 'baechi'\n",
    "\n",
    "model_name = \"TallParallelModel\" #\"ParallelThreeLayer\"\n",
    "repetable = 1\n",
    "\n",
    "job_server = threading.Thread(target=job_arrivals, args=(rate, T_exp, ))\n",
    "job_server.start()\n",
    "\n",
    "job_served     = 0\n",
    "jobs_in_process = []\n",
    "jobs_completed = [] \n",
    "no_jobs_waiting = []\n",
    "\n",
    "t = time.time()\n",
    "while not end_exp_flag[0]:\n",
    "    try: \n",
    "        ## Check if a new job arrived. Will fail if no new job\n",
    "        new_job = job_queue[job_served+1] \n",
    "        \n",
    "        if (new_job['entry_time'][0]):\n",
    "            print(\"Something went wrong! New job already has entry time\")\n",
    "               \n",
    "        model, inp_size_single, opt_size = get_model(model_name, fct, repetable)\n",
    "\n",
    "        inp_size = (batch_size,) + inp_size_single\n",
    "        out_size = (batch_size, opt_size)\n",
    "\n",
    "        args.batch_size = str(batch_size) # args is defined in baechi_units_bigbrain\n",
    "        \n",
    "        ## get a resource allocation for new job #######################\n",
    "        success = 0\n",
    "        if algo == 'baseline':\n",
    "            print(\"Baseline:\")\n",
    "            gpu_allotted = get_baseline_gpu()\n",
    "            print(\"Gpu_alotted:\", gpu_allotted )\n",
    "            if gpu_allotted is not None:\n",
    "                resource_usage = {gpu_id:0.0 for gpu_id in available_gpus}\n",
    "                resource_usage[gpu_allotted] = (1/baseline_packing_number)*available_mem\n",
    "                success = update_resource(resource_usage, 'acquire')\n",
    "                model_final = model.to(gpu_allotted)\n",
    "                first_gpu = gpu_allotted\n",
    "                final_gpu = gpu_allotted\n",
    "            \n",
    "        elif  algo == 'baechi':\n",
    "            print(\"*--*\"*20); print(\"*--*\"*20)\n",
    "            available_device_list = {}\n",
    "            net_available_resource = 0\n",
    "            print(\"Device Memories:\")\n",
    "            for k in available_gpus:\n",
    "                print(\"Device;\", k, \" - Memory:\",b2mb(device_list[k]['memory_size']))\n",
    "                if b2mb(device_list[k]['memory_size']) > 500:#500MB\n",
    "                    available_device_list[k] = device_list[k]\n",
    "                    net_available_resource += b2mb(available_device_list[k]['memory_size'])\n",
    "                    #print(net_available_resource, \"*\"*20)\n",
    "            print(\"Net Available resources:\", net_available_resource)\n",
    "            print(\"Chosen Devices: \", [k for k in available_device_list] )\n",
    "            \n",
    "            if (net_available_resource > 1000):\n",
    "                DEVICE_GRAPH_MULTIPLE = create_device_graph(available_device_list)\n",
    "                ################################################################################\n",
    "                return_graph, tester = build_graph(model, batch_size,args.prof_gpu_id, args.prof_rounds, inp_size = inp_size_single)\n",
    "                placed_op_graph = m_sct(return_graph, DEVICE_GRAPH_MULTIPLE)\n",
    "                copy_p(return_graph, tester)\n",
    "                #########################################################\n",
    "                resource_usage = {gpu_id:0.0 for gpu_id in available_gpus}\n",
    "                first_gpu = -1\n",
    "                for node_id in tester.sub_module_nodes:\n",
    "                    node = tester.sub_module_nodes[node_id]\n",
    "                    curr_gpu_id    = node.p\n",
    "                    if first_gpu < 0:\n",
    "                        first_gpu = curr_gpu_id\n",
    "                    curr_res_usage = node.input_memory + node.persistent_memory \\\n",
    "                                    + node.temporary_memory\n",
    "                    resource_usage[curr_gpu_id] += curr_res_usage\n",
    "\n",
    "                final_gpu = curr_gpu_id\n",
    "                print(\"Resource Usage: \",[b2mb(resource_usage[k]) for k in resource_usage] )\n",
    "                print(\"Available resources:\",[b2mb(resource_manager[k]) for k in resource_manager ])\n",
    "                print(\"*\"*20); print(\"Allotment:\")\n",
    "                for node_id in tester.sub_module_nodes:\n",
    "                    print(tester.sub_module_nodes[node_id].module)\n",
    "                    curr_gpu_id = tester.sub_module_nodes[node_id].p\n",
    "                    print(curr_gpu_id)\n",
    "                print(\"*\"*20)\n",
    "                \n",
    "                success = update_resource(resource_usage, 'acquire')\n",
    "                print(\"Success:\", success)\n",
    "                #print([round(resource_usage[gpu_id]/1024**2,8) for gpu_id in available_gpus])\n",
    "                print(\"-*-\"*20)\n",
    "                \n",
    "                if success:\n",
    "                    Assign(tester)\n",
    "                    model_final =  copy.deepcopy(tester.model)\n",
    "                    #model_final = model\n",
    "\n",
    "                del tester\n",
    "                del placed_op_graph\n",
    "                del return_graph\n",
    "                gc.collect()              ## To clean any circular references\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.synchronize(3);\n",
    "                #print(\"|-|\"*10);print_gpu_memory();print(\"|-|\"*10)\n",
    "        else:\n",
    "            print(\"Error. Invalid Algo\")\n",
    "            os.exit(1)\n",
    "         \n",
    "        ## If resource is available then a success is returned \n",
    "        ## Else just wait\n",
    "        if success:   \n",
    "            new_job['gpu'] = resource_usage\n",
    "\n",
    "            ### Spawn a thread to start the new job\n",
    "            new_job['entry_time'][0]  = time.time()\n",
    "\n",
    "            job_submit = threading.Thread(target=run_job, args=(job_served+1, algo, model_final, fct, \\\n",
    "                                                                  batch_size, Nrun, new_job['status_flag'], \\\n",
    "                                                                  new_job['exit_time'], first_gpu, final_gpu, ))\n",
    "            job_submit.start()\n",
    "            job_served = job_served+1\n",
    "            jobs_in_process.append(job_served)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "         \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    completed = []\n",
    "    for inprocess_job_id in jobs_in_process:\n",
    "        if job_queue[inprocess_job_id]['status_flag'][0]:\n",
    "            completed.append(inprocess_job_id)   \n",
    "            ## Release resources\n",
    "            update_resource(job_queue[inprocess_job_id]['gpu'], 'release')\n",
    "    \n",
    "    jobs_completed = jobs_completed +  completed \n",
    "    for i in completed:\n",
    "        jobs_in_process.remove(i)\n",
    "        \n",
    "    t_now = time.time()\n",
    "    if t_now-t>1:\n",
    "        ## Check for completed jobs \n",
    "        no_waiting = len(job_queue)-job_served\n",
    "        no_jobs_waiting.append(no_waiting)\n",
    "        print('*-'*20)\n",
    "        print(\"Jobs in process:\", len(jobs_in_process))\n",
    "        print(\"Jobs waiting:\",no_waiting )\n",
    "        print(\"Jobs Completed: \", len(jobs_completed))\n",
    "        print('*-'*20)\n",
    "        t = t_now\n",
    "        \n",
    "\n",
    "    time.sleep(0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1001c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApd0lEQVR4nO3deXxU9b3/8dc3O0lIIAsQgRCWQEAUxAjKriCCttdWW6u1Xu2it9W2bnXrdnvv/bXFaq1VW3u1rbW3VmurVtsKogiSKILsiwQmBBJ2MglZyJ6Z7++PGSIhCdlmJpmZ9/Px4JHMmXPOfHKAN1++53u+X2OtRUREgk9EXxcgIiI9owAXEQlSCnARkSClABcRCVIKcBGRIBUVyA9LS0uzWVlZgfxIEZGgt3HjRqe1Nv3M7QEN8KysLDZs2BDIjxQRCXrGmOL2tqsLRUQkSCnARUSClAJcRCRIKcBFRIKUAlxEJEgpwEVEgpQCXEQkSCnARUT8qL7JxY/e2Mnhijqfn1sBLiLiR8+9v58/fLCfkvJan59bAS4i4icnahr59epCLssZwsVjUn1+fgW4iIif/GpVITUNzTywOMcv5+80wI0xccaY9caYrcaYncaY//JuTzHGvG2McXi/DvZLhSIiQejgiVr+uLaYa6eNYMKwgX75jK60wBuAy6y1U4CpwGJjzMXAg8BKa202sNL7WkREgMdW7MEYuGfReL99RqcBbj1Oel9Ge39Z4Grgee/254HP+KNAEZFg8/HhKl7bcogvzxpNRvIAv31Ol/rAjTGRxpgtwHHgbWvtOmCotfYIgPfrEL9VKSISRH69upCkuGi+MW+sXz+nSwFurXVZa6cCI4DpxpjJXf0AY8xtxpgNxpgNpaWlPSxTRCQ4NLvcrNlTyuJzh5EcH+3Xz+rWKBRrbQWwGlgMHDPGZAB4vx7v4JhnrLW51trc9PQ2C0qIiISUbYcqqapvZnZ2mt8/qyujUNKNMYO83w8AFgIFwBvAzd7dbgZe91ONIiJBI9/hxBiYNc7/Ad6VJdUygOeNMZF4Av9la+0/jTFrgZeNMV8FSoDP+7FOEZGgkOcoZfI5yaQkxPj9szoNcGvtNuCCdraXAQv8UZSISDCqrm9ic0kFt84dE5DP05OYIiI98G7BMR59azfW2pZtHxaV0+y2zAlA/zcEeFV6EZFQUF3fxHf+uo3ymkZyswYzf4JnFHW+o5QB0ZFcOCowD6arBS4i0k3/+14R5TWNpCXGsnRZAS63pxWeV+hk+ugUYqMiA1KHAlxEpBuOVdXz2/wiPj3lHH746UkUHK3m9S2HOFRRR1FpTcC6T0ABLiLSLY+/sweX23Lfogl86rwMzhuezM9X7GHlrmMAzMkO3PMuCnARkS4qPF7NXz46wI0zRpGZGk9EhOGhJTkcqqjjZ8t3M2RgLOOHJgasHt3EFBHpwImaRt4tOI7bO9Lk1U2HiI+J4luXjWvZZ+a4NOaNT+e9PaUsOncoxpiA1acAFxHpwC9XOvjDB/tbbfv+VRNJTYxtte3BJTmsLSrjinOHBbA6BbiISIfW7Cll1rhUll5zPgAxUREMTYprs9/EjCS2/PBy4mMCG6kKcBGRdhw8UUuRs4YbLx7FyJT4TvcPdHiDbmKKiLQr3+EECOiwwO5SgIuItCOv0MnQpFiyhwRuVEl3KcBFRM7gclveL3Qye1x6QEeVdJcCXERC0h1/3sSDr2zrdL83th5m4WPvUVrd0LJt5+FKKmqb+nX3CSjARSQEVdc3sXzHUV766ABbDlR0uF9tYzP/88+PKTx+kidWOlq253n7vwOxKENvKMBFJOSs3VuGy22JjjT89M1draZ8Pd1v8/ZRWt3A9KwUXlxfwj5nDeBZlGFiRhLpA2PbPa6/UICLSMjJL3QSHxPJA4tzWLevnFW72y7Z6zzZwP++t5dFk4by1I0XEBMVwSNvFVDb2MzG4hPM7efdJ6AAF5EQlOdwMmN0CjfPzCIrNZ6Hl+1umfL1lCdXOqhvdnP/4hyGDIzja3PG8Ob2o/zmvSKaXDYgixL3lgJcRELKgfJa9jlrmJOdTnRkBN+5YgK7j1Xz6qaDLfsUl9XwwroSrssdyTjvMMHb5o4hLTGGJ1Y6iI2K4KKslL76EbpMAS4iPnO4oo7H3t5Dk8vd43M0udw8vXovhyrq2rxX1+ji0bd2U17T2OHx+YWtH8C56rwMpoxI5uHlu7n35a3c+/JWvvGnTURHRnD3wuyW4xJjo/j2As/r6aNTiIsOzKIMvaEAFxGf+dOHxTyx0sFL60t6fI6/fHSAh5cX8P3Xtrd579m8Ip5aVdiqNX2mfIeTYUlxLS1rYwz/ffVkUhKi+bCojA+Lyqiqb+IHn5rEkDPmNblheiYLcoZww/TMHtcfSJoLRUR85tTwu1+udHDNtBEkxHYvYmoamnn8HQfxMZGs2l3K2r1lXDI2FfjkpiPAGoeTr81pu/K7y23JL3Ry+aTW07pOGTmIFXfP6/TzoyMj+N0tF3Wr5r6kFriI+ER5TSM7DleyIGcIzpONPJtX1O1z/DZvH86TDfz25lwykuNYuuyTIYCnbjrOn5DO+n1l1De52hy/41AllXX9/wEcX+k0wI0xI40xq4wxu4wxO40xd3q3/8gYc8gYs8X760r/lysi/dX7hU6shdsvHceV5w3jmTVFrZ5u7IzzZAPPrNnL4nOHMXNsGvdcPp6tByv51/Yj7Hd6bjp+4aKR3HTxKOqb3GwsPtHmHHmOUqD/P4DjK11pgTcD91prJwIXA3cYYyZ53/uFtXaq99ebfqtSRPq9fIeTgXFRTBmRzH1X5NDY7G71dGNnnvC2sO9bPAGAa6aNIGfYQB55azdLlxUQHRnBXQuyuXhMKtGRpqW75nR5DifnnpNEWmL/fgDHVzoNcGvtEWvtJu/31cAuYLi/CxOR4GGtJc9RysyxqURFRjA6LYEbpme2errxbPY7a/jzuhKuv2gkY9M9Nx8jIwwPLM6huKyW5TuPcuuc0QxJiiMhNooLMge3tLZPqWloZlPJiaAYv+0r3eoDN8ZkARcA67ybvmmM2WaM+b0xZrCvixOR4FDkrOFwZX2rFdm/vSC75enGzjyyYjcxURHcedqwPoD5E9KZOTaV9IGx3DZvbMv2udlp7DxcRdnJT7po3tx+hCaXZV4AV4Xva10OcGNMIvAKcJe1tgp4GhgLTAWOAD/v4LjbjDEbjDEbSktL29tFRIJce4sfpA+M5Vbv042bS9r2V5+y9UAF/9p2hK/NGcOQga2H9Rlj+P0tF/HWXXNJPG1Ey2xvSL+/twyA+iYXj7/j4PwRyVw8JtVnP1d/16UAN8ZE4wnvF6y1rwJYa49Za13WWjfwLDC9vWOttc9Ya3Ottbnp6eHzL6NIOMlzlJKZEs+o1IRW22/1Pt3402UF7U4oZa3lp8t2kZoQw21z2w4LBIiLjiQlIabVtvOGJ5M8IJq8PZ5G4R/X7udQRR0PLskhIqL/zt/ta10ZhWKA3wG7rLWPnbY947TdPgvs8H15ItLfNbncrN1b1m7fc2JsFHcuyGb9vnLeLWg7odTq3aV8WFTOtxdkt2phdyYywjBrXCr5hU4qa5v41aq9zBufzsyx4dP/DV1rgc8CbgIuO2PI4M+MMduNMduAS4G7/VmoiPRPm0sqqGl0MaeDoXvXT89kdFoCDy8vaDWhlMttWbqsgFGp8T168nH2uHSOVNZz71+3UlXfxINLcnr8MwSrTv/Js9bmA+39n0TDBkWEfEcpEYYOW7/RkRHcd8UEbn9hE69sPMh1F40E4NVNB9l9rJqnvuiZyrW7TvW3v7PrGNdMG87EjKSe/xBBSo/Si0inli4r4J/bDrf7XtnJRs4fMYjk+OgOj18yeRhTRg7ih2/s4Il3PWPDnScbmDIimavOy+jwuLMZmRJPVmo8hyvruXfRhB6dI9gpwEXkrJpcbv5v7X5GpsQz6Zz2W7nXXDDirOcwxvDYdVN45r0imtyemQqjIyK4de6YXi0a/INPTaKm0cXwQQN6fI5gpgAXkbM61cd918LxLJ48rMfnGZueyMOfO9+HlcGCiUN9er5go8msROSsTvVxn5oVUPoPBbiInNUah5OpIweRPKDjPm7pGwpwEelQZW0T2w5WtDz5KP2LAlxEOrS2yInbEjbzawcbBbiIdGiNw0libBRTRw7q61KkHQpwEelQvsPpnX9bUdEf6XdFRNpVXFZDSXktc8er+6S/UoCLSLtOrXgzO0yWJwtGCnARaVe+w8nwQQMYnZbQ+c7SJxTgImGssdnd7vZml5v39zqZk53Wq0fdxb8U4CJhaufhSi78n7d5bfPBNu+9v7eM6vrmsFpfMhgpwEXC1NJlBVQ3NLN0WQF1ja6W7W635dG3djN80AAWhvlcI/2dAlwkDOU7nOQ5nFx1fgbHqhr4/fv7Wt775/YjbD9Uyb2LxhMXHdmHVUpnFOAiYcbt9qxDOXzQAB67bgoLJw7hN6v3Ul7TSGOzm0ff2s3EjCQ+M3V4X5cqnVCAi4SZf2w7zM7DVXznivHERkXywOIcahqbeerdQl5YV0xJeW3YLQ4crDQfuEgYaWh28egKTwv76imeFnb20IF8/sKR/N+H+0mIjWLWuFTm6uZlUFALXCSMvLT+AAfK69q0sO++fDwRxlBR28SDiydq6GCQUAtcJIy8sfUwk4cntWlhD0uOY+m153G8qoHzRiT3UXXSXQpwkTBRVd/ElgMVfH1e++tQfraTdS2l/1EXikiY+HBvGS63ZY4WZwgZnQa4MWakMWaVMWaXMWanMeZO7/YUY8zbxhiH9+tg/5crIj2V53ASHxPJtEz9VQ0VXWmBNwP3WmsnAhcDdxhjJgEPAiuttdnASu9rEemn8gudzBidQkyU/uMdKjr9nbTWHrHWbvJ+Xw3sAoYDVwPPe3d7HviMn2oUkV46UF7LPmeNuk9CTLf+KTbGZAEXAOuAodbaI+AJeWBIB8fcZozZYIzZUFpa2styRaQn8gs9c3trbcvQ0uUAN8YkAq8Ad1lrq7p6nLX2GWttrrU2Nz1d//qL9IV8h5NhSXGMG5LY16WID3UpwI0x0XjC+wVr7avezceMMRne9zOA4/4pUUR6w+W25Bc6ma25vUNOV0ahGOB3wC5r7WOnvfUGcLP3+5uB131fnoj01o5DlVTWNan7JAR15UGeWcBNwHZjzBbvtu8CS4GXjTFfBUqAz/ulQhHplVP937O0tmXI6TTArbX5QEf/71rg23JExNfW7CllUkYSaYmxfV2K+JgGhIqEsLKTDWwqOaHukxClABcJYU++W4jbwudzR/Z1KeIHCnCREFVcVsML64q5Lnekhg+GKAW4SIh6dMUeoiIiuHthdl+XIn6iABcJQdsOVvCPrYf52pzRDEmK6+tyxE8U4CIhxlrL0mUFpCTEcNvcMX1djviRFnQQ6aeOV9Xzy5UOmlxuAAyGL87IZMrIQWc9bo3DyQd7y/jPT09iYFx0ACqVvqIAF+mn/vLRAV5YV0JGsqcLpLKuifxCJyvvnUdcdGSHx72y8SBpiTHcOGNUoEqVPqIuFJF+Kq/QyeThSax9aAFrH1rAMzflcqiijj99WNzhMW635f1CJ3Oy0zXvdxjQ77BIP3SyoZnNJSeYPe6TGTxnZ6cxJzuNp1YVUlnX1O5xu45WUVbTqAd3woQCXKQfWldURpPLtlk9/sElOVTWNfH06r3tHpfn8Mx7MlvznoQFBbhIP5TncBIXHcGFWa3Xrzz3nGQ+M3U4z72/j8MVdW2Oy3c4mTB0oIYOhgkFuEg/lOcoZfroVGKj2t6svOfy8VgLv3h7T6vt9U0u1u8vV/dJGFGAi/QzRyrr2Fta06b75JSRKfH8+yWj+Numg+w+Wt2yff2+chqb3cxWgIcNBbhIP9PSj32WIL7j0nEkxkbx8PKC044rJSYyghmjU/1eo/QPCnCRfibP4SR9YCwThg7scJ/BCTF8Y/5Y3i04zodFZS3H5WYNZkBMx2PEJbQowEX6kZZx3OM6X7/yK7NGMywpjqXLCjheXU/B0Wp1n4QZBbhIP/LxkSrKaxq7FMRx0ZHcc/l4thyo4Ad/3wHA3Oz0To6SUKIAF+lHujuO+9oLRzB+aCJv7TxGSkIMkzKS/Fme9DMKcJF+JL+wlJxhXR/HHRlheGBxDgAzx6YSEXH2bhcJLZrMSqSfqGt08dG+E/z7Jd2bhOqynCHcv3iCuk/CkAJcpJ9Yv7+cRpebOeO7F8TGGG6fP85PVUl/pi4UkX4ib49nHPf0rJS+LkWCRKcBboz5vTHmuDFmx2nbfmSMOWSM2eL9daV/yxQJffmFTi4arXHc0nVdaYH/AVjczvZfWGunen+96duyRMLL8SrvOO5x6seWrus0wK21a4DyANQiErbyCz3DBzURlXRHb/rAv2mM2ebtYhnc0U7GmNuMMRuMMRtKS0t78XEioSvf4SRV47ilm3oa4E8DY4GpwBHg5x3taK19xlqba63NTU/Xfw9FzmStJa/QyaxxaRrHLd3SowC31h6z1rqstW7gWWC6b8sSCR+7j1VTWt2geUyk23oU4MaYjNNefhbY0dG+InJ2eXvU/y090+mDPMaYF4H5QJox5iDwn8B8Y8xUwAL7gf/wX4kioS2v0Mm4IYlkJA/o61IkyHQa4NbaG9rZ/Ds/1CLS71hraXS5213aDKDJ5SY6sudjAeqbXKwrKuOG6Zk9PoeELz2JKXIWf1xbzMU/WUlpdUOb937y5i4W/Pw9TjY09/j8q3eX0tDsZu54dZ9I9ynARc5i2Y4jnKht4omVjlbb95ae5Hf5+ygpr+XZNUU9Onezy83PV+xmdFoCczQRlfSAAlykA7WNzWwsPkF8TCQvri9hn7Om5b1Hlu8mLiqCOdlpPJtXxPHq+m6f/5VNB3EcP8n9V0zoVTeMhC/9qRHpwLqicppclh9/djIxURE88pZnAeGNxSdYvvMo/zFvLP999WQam91tWuidqWt08Yu3HUwdOYjFk4f5o3wJAwpwkQ7kOZzERkWwZHIGt84Zw5vbj7K55ARLl+0iLTGWr80Zzei0BG6YnsmL6w9QVHqyy+d+7oN9HK2q56ElOZ2ufSnSEQW4SAfyC0uZPjqFuOhIbp07hrTEGL7xp018tP8Edy3MJj7GM4jr2wuyiYuK4NEVu7t03hM1jTy9ei8LcoYwY0yqP38ECXFa0EFC1gvrihkQHck100a0ee837+1lTFoCi85tv/viaGU9e46d5HMXeo5NjI3izgXZ/OD1nYxJS+ALF41s2Td9YCy3zh3D4+842FxyggsyW08NVFHbyH/94+OWkSzHq+upaWjmgSU5vvpRJUypBS4hqfD4SX74+k4efHU7hyrqWr23YX85S5cV8J2/bqWitrHd40/NDnj69K7XT8/kxhmZ/Oxz57e56XjrnDGkJcby02UFWGtbvffku4W8vuUQtY3N1DW5GBgXzfevmsT4oQN98aNKGFMLXELSz5YXMCA6kkbvUL3HrpsKeB7M+emyAgbHR1NR18SvVhXyvasmtTk+z1FKWmIsOcM+CdnoyAh+/Nnz2v28hNgo7lyYzQ/+voN3C46zYOJQAA6U1/J/a4v5/IUjefhz5/v+B5Wwpha4hJwN+8tZ8fExvj5vDF+emcVrmw/x8eEqAN7++Bgbi09w3xU5XDttBM9/UMzBE7Wtjne7Le8XOpk9rnurvF9/0UhGpyXw8PICXG5PK/znK3ZjDNx1ebbvfkARLwW4hJRTLewhA2P5yuzR3D5/HElx0Ty8vIBml5uHlxcwJj2B63JHcM/l4zEGHluxp9U5dh2twnmykdndfLgmOjKC+66YwJ5jJ3ll40F2HKrk71sO85XZozXPifiFAlxCygpvC/uuheOJj4kiOT6aOy4dy3t7Srn/b9vYW1rD/VfkEBUZwTmDBnDLrCxe2/JJCx08iytAz2YHXDJ5GFNHDuKxt/fw//71MYPio/n6vLE++/lETqcAl5DR7HLzs+UFjPW2sE/590uyGD5oAK9uPsSFowZzxblDW967fZ6nhf6jf+zk9S2HeH3LIf61/QjjhyYyNCmu2zUYY3hoSQ5Hq+r5sKicb146juQB0T75+UTOpACXkPHyhoOeFvZiTwv7lLjoSB5YkkNcdATfvbL1gzPJ8dHcu2g86/eVc+dLW7jzpS1sO1jZchOyJ2aMSeWq8zIYm57ATZeM6tXPJHI25swhT/6Um5trN2zYELDPk/BR29jMvEdWk5kSz9++fkm7TzfWNboYENP+tLCHKupoaHIBnlZ0Zko8kb1Y3szt9kxDGxfd/ueJdIcxZqO1NvfM7RpGKCHh9/n7KK1u4Okbp3X4aHpH4Q0wfJBvbzJGRBjiIhTe4l/qQpGgV3aygd+8V8Tlk4aSm5XS1+WIBIwCXILek+8WUtvYzAOLJ/R1KSIBpQCXoFZSVssL64r5wkUjGTdEj6ZLeFGAS1B7apWDyAjDXQvH93UpIgGnAJeg5XZb3tl1nCWTM3o0Zlsk2CnAJWh9fKSK8prGHj0xKRIKFOAStPIcp6Z8VYBLeOo0wI0xvzfGHDfG7DhtW4ox5m1jjMP7dfDZziHiD/mFpeQMG8gQdZ9ImOpKC/wPwOIztj0IrLTWZgMrva9FAqau0cVH+06o9S1hrdMnMa21a4wxWWdsvhqY7/3+eWA18IAvCwtleY5S3tx+tOX1oPhobp8/loFxmvSoq9bvL6fR5WbO+O5N+SoSSnr6KP1Qa+0RAGvtEWPMkI52NMbcBtwGkJmZ2cOPCy1Prixky4EKkuM9ge082UBTs5vvf6rtyjDSvnxHKTGREUzXk5cSxvx+E9Na+4y1Ntdam5uertYSQHF5Df829Rw++t5CPvreQj43bQR/XFvMgfLazg8WwHMDMzdr8FnnNxEJdT0N8GPGmAwA79fjvisptNU3uThW1cColPiWbXefWhnm7T1nOVJOOV5VT8HRauZ0c8UckVDT0wB/A7jZ+/3NwOu+KSf0lXhb2ZmpnwT4qZVh/r7lEDsPV/ZVaUHj1IrxGv8t4a4rwwhfBNYCE4wxB40xXwWWApcbYxzA5d7X0gUlZd4AP60FDp+sDLN0WUFflBVU8h1OUhJimJSR1NeliPSproxCuaGDtxb4uJawUOxtgY9KTWi1PTk+mm9eOo4fv7mLlz86wNghiQCkJca02bc/cJ5sIC0x1mfnc7st2w5VtqzmfjZ5hU5mjUvr1orxIqFICzoEWElZDYmxUQyObztk8KZLRvH82v3c/8q2lm0RBv701RnM7Efjnf+++RB3v7yFZ2/KZeGkni89drrvvradlz460OX952v4oIgCPNCKy2vJTIlvd9WYuOhI3vjmbLYf8vSDW2v53ms7+MmyXbxxx+x+0eKsb3Lxs+UFWAs/XbaL+RPSW60/2RMFR6v4y4YDfO7CEXx6yjmd7h8TGcFFWXr4V0QBHmAl5bVMGNrxvNUpCTHMO611ee+i8dzz8lb+se0wV08dHogSz+r5D/ZzuLKeW2Zm8YcP9vPXjQe5YXrvxvc/vKyAgbFRfP+qiQyKj/FRpSKhT5NZBZDLbTlYXtdqBEpnPjN1OBMzknh0xW4aml1+rK5zFbWN/GpVIfMnpPOfn57EtMxB/OLtPdQ2Nvf4nGv3lrFqdym3XzpO4S3STQrwADpaVU+jy91mBMrZREQYHlySw4HyOv68rsSP1XXu16v3Ut3QzAOLczDG8NCVEzle3cBz7+/v0fmstSxdtouM5DhumZnl01pFwoECPIBODSEcldK9USVzs9OYOTaVJ98tpLq+yR+ldepQRR1/+GA/11wwgone4XsXZaWwcOJQfrN6L+U1jd0+55vbj7L1YCV3Xz6euGg9USnSXeoDD6CS8hoARnWjCwXwtHaXTOTTT+Wz8LH3SIjx/LaNSInnqS9eQNIZk2C9/fEx/rrhAL/50oU+u/H52ArPU6L3LGq9dNkDiydwxeNrWPz4GhJjPXUNS47jqS9OIyWhdZfIB4VO/vufH9PY7AbgWFU9E4YO5NppI3xSo0i4UQs8gIrLaomKMGQkd3/+6vNGJPOTz57H9NGpnDs8mYkZSazZU8oz7xW12q++ycUPX9/Bio+PsfNwlU/q3nWkilc3H+SWmVkMHzSg1XvZQwfyyOemMGOMp65J5yTxYVEZT77raLVfk8vNd1/bTlVdE+cOT+bc4cksOncYv/jCVCL7wegakWCkFngAFZfXMnzwgB4Pu/vijEy+OOOTER+RL27mt/lF3HTJqJY1If/wwX6OVNYDkFdYynkjkntd98PLPaNEbp8/tt33r71wBNde+Ekr+qFXt/GnD4v58szRLTdsX1xfwv6yWp675SIuzelw8koR6Qa1wAPogHcMuK98Z9EEXG7L4+94ujcqahv59apCLssZQs6wgeTtcfb6Mz7Y62T17lLu6MYokbsWjicywvDoit0AnGxo5pfvOLh4TArzJ+gBHBFfUYAHUHFZbbf7v88mMzWeG2eM4i8fHaDweDW/WlVIdUMz9y+ewNzx6WwsPtGrIX5ut2XpsgLOSY7j5m6MEhmaFMdXZ4/mja2H2X6wkmfXFFFW08iDSya2+wCTiPSMAjxAKmubqKxr8mkLHOBbl40jPiaKh17dzvMfFHPttBHkDEti9rg0Gl1u1u0r7/G5/7X9CNsOVnLPogndHiXyH/PGMjg+mh++sYNn84q46rwMpo4c1ONaRKQtBXiAFHtHoGR2cwhhZ1ITY/n6vDF8tP8ExsA9l3tGiUwfnUJMVAT5jp51ozQ2u3l0xW5yhg3ksxd0/wnQpLhovnVZNptLKmhsdnPfFRN6VIeIdEwBHiAlLbMQ+rYFDvCV2aPJGTaQOxdmc453lEhcdCTTs1J6HOAvri+huKyWB5bk9HiUyI0XZzJlRDK3zx9LVlr/m1FRJNhpFEqAFHcwD7gvxMdEsezOOW36l2dnp7F0WQHHqupbRql0RXV9E0+sdHDJmNRezfoXGxXJ3++YpX5vET9RCzxASspqSUuMISHWP/9mtheSs71T0Ha3Ff7JTcecXoevwlvEfxTgAVLi4yGEXTEpI4nUhBjyHKVdPuZ4VT3P5u3jqvMzmKKbjiL9mgI8QErKawO+sk5EhGHWuDTyC8twd2GlG4DHVzpocrm5b5FuOor0d+oDD4CGZheHK+sYGeAWOHj6wd/Yeph1+8oZO+Ts/4AcrqjnLx8d4EszMnXTUSQIKMADoLisFmthVB8E+KmV22949sMu7Z8QE8m3FmT7syQR8REFeACs3VsGQG4fLAOWkTyA5265iEMVdV3a/8JRg326WLGI+I8CPADyHE4yU+L7bHV5TR4lEpp0E9PPmlxuPiwqY3Z2/1lVXkRCQ69a4MaY/UA14AKarbW5vigqlGw5UMHJhmbmjFOAi4hv+aIL5VJrbe/nLQ1ReQ4nEQZmjlWAi4hvqQvFz/IcpZw/YhDJ8dGd7ywi0g29DXALrDDGbDTG3NbeDsaY24wxG4wxG0pLu/5EYCiorGti64EK5qr/W0T8oLcBPstaOw1YAtxhjJl75g7W2mestbnW2tz09PBajWXtXiduC7Ozw+vnFpHA6FWAW2sPe78eB14DpvuiqFCR53CSEBPJBZmD+roUEQlBPQ5wY0yCMWbgqe+BRcAOXxUWCvILnVwyNpXoHi5iLCJyNr1JlqFAvjFmK7Ae+Je1drlvygp+JWW1FJfVtkzpKiLiaz0eRmitLQKm+LCWkJJX6Llhq/5vEfEX/d/eT/L2ODknOY6x6ZrVT0T8QwHuBy635YO9TmZnp2lFGhHxGwW4H2w7WEFVfTNz1H0iIn6kAPeDPIcTY2CWbmCKiB8pwP0g3+Fk8jnJpCTE9HUpIhLCFOA+drKhmU0lJzR9rIj4nQLcxz7cW0az27YsZSYi4i8KcB/LL3QyIDqSC0cFfvk0EQkvCnAfW+MoZcaYFGKjIvu6FBEJcQpwHzpcUUdRaY0enxeRgFCA+1C+w7Mw0dzxGv8tIv6nAPehNY5ShibFkj0ksa9LEZEwoABvx983H+Ljw1XdOsbttrxf6GT2uHQ9Pi8iAaEAP8PWAxXc9Zct3P7CRppc7i4ft/NwFSdqmzR8UEQCRgF+GmstS5cVEBsVwf6yWl5aX9LlY09NH6vH50UkUBTgp1m9p5S1RWV898qJTB+dwi9XOjjZ0NylY/P2OJmYkUT6wFg/Vyki4qEA93K5LQ8vK2BUajw3TM/koSU5OE828uyaok6PrWt0sbH4hLpPRCSgFOBer20+RMHRau67YgIxURFckDmYK88bxrN5RRyvrj/rsev2ldHocivARSSgwjbAq+ub2HKggi0HKthUcoLHVuzm/BHJXDk5o2Wf+67IobHZzRMrHWc9V57DSUxUBBdlpfi7bBGRFj1eEzOY1Te5uOqJfErKa1ttf/S6KUREfDIEcHRaAjdMz+TP60v4yqzRjElvf3x3vsPJ9KwU4qL1+LyIBE5YBvjzH+ynpLyW/7n6XEYMjgdgaFIck85JarPvtxdk88qmgzzy1m6e/tKFbd4/VlXP7mPVXDNtuN/rFhE5XdgFeEVtI79aVcj8CencdElWp/unD4zl1jlj+OVKB5tKTjAts/Usg6cen9f83yISaGHXB/706r1UNzTzwOKcLh9z69wxpCXGsPTNAqy1rd7Lc5SSmhDDxGFtW+8iIv7UqwA3xiw2xuw2xhQaYx70VVH+cqiijuc+2M81F4xgYkbXAzcxNoo7F2Szfn857xYcb9lurSW/sIzZ2Wmt+s5FRAKhxwFujIkEfgUsASYBNxhjJvmqMH94bMUeAO5ZNL7bx14/PZPRaQk8vLwAl9vTCi84Wo3zZIOmjxWRPtGbPvDpQKG1tgjAGPMScDXwsS8KO92TKx28sfVwr89TWHqS2+aMYfigAd0+NjoygvuumMDtL2zisp+vJiYygup6z1Oac7I1fayIBF5vAnw4cOC01weBGWfuZIy5DbgNIDMzs0cflD4wluyhvZ+i9eIxqdxx2bgeH79k8jDuWpjNnmPVLduyhwxkWHJcr2sTEemu3gR4e52+ts0Ga58BngHIzc1t835XXD89k+un9yz8fckYw10Lu9/9IiLiD725iXkQGHna6xFA7/s5RESkS3oT4B8B2caY0caYGOB64A3flCUiIp3pcReKtbbZGPNN4C0gEvi9tXanzyoTEZGz6tWTmNbaN4E3fVSLiIh0Q9g9iSkiEioU4CIiQUoBLiISpBTgIiJBypw5u55fP8yYUqC4h4enAU4flhMKdE3ap+vSlq5JW8F0TUZZa9vM2RHQAO8NY8wGa21uX9fRn+iatE/XpS1dk7ZC4ZqoC0VEJEgpwEVEglQwBfgzfV1AP6Rr0j5dl7Z0TdoK+msSNH3gIiLSWjC1wEVE5DQKcBGRIBUUAR5siyf7gzFmpDFmlTFmlzFmpzHmTu/2FGPM28YYh/fr4L6uNdCMMZHGmM3GmH96X4f1NTHGDDLG/M0YU+D983KJrom52/v3Zocx5kVjTFwoXJN+H+DBuHiynzQD91prJwIXA3d4r8ODwEprbTaw0vs63NwJ7Drtdbhfk18Cy621OcAUPNcmbK+JMWY48G0g11o7Gc/019cTAtek3wc4py2ebK1tBE4tnhxWrLVHrLWbvN9X4/lLORzPtXjeu9vzwGf6pMA+YowZAVwF/Pa0zWF7TYwxScBc4HcA1tpGa20FYXxNvKKAAcaYKCAez+phQX9NgiHA21s8eXgf1dIvGGOygAuAdcBQa+0R8IQ8MKQPS+sLjwP3A+7TtoXzNRkDlALPebuVfmuMSSCMr4m19hDwKFACHAEqrbUrCIFrEgwB3qXFk8OFMSYReAW4y1pb1df19CVjzKeA49bajX1dSz8SBUwDnrbWXgDUEIRdA77k7du+GhgNnAMkGGO+1LdV+UYwBLgWT/YyxkTjCe8XrLWvejcfM8ZkeN/PAI73VX19YBbwb8aY/Xi61i4zxvyJ8L4mB4GD1tp13td/wxPo4XxNFgL7rLWl1tom4FVgJiFwTYIhwLV4MmCMMXj6NXdZax877a03gJu9398MvB7o2vqKtfYha+0Ia20Wnj8X71prv0R4X5OjwAFjzATvpgXAx4TxNcHTdXKxMSbe+/doAZ57SEF/TYLiSUxjzJV4+jpPLZ78476tKPCMMbOBPGA7n/T3fhdPP/jLQCaeP6ift9aW90mRfcgYMx/4jrX2U8aYVML4mhhjpuK5qRsDFAFfxtNYC+dr8l/AF/CM5toMfA1IJMivSVAEuIiItBUMXSgiItIOBbiISJBSgIuIBCkFuIhIkFKAi4gEKQW4iEiQUoCLiASp/w/dF760r9moDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(no_jobs_waiting)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9261957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Waiting Time:  11.586952577203007 sec\n",
      "Mean Process Time:  13.824381064560454 sec\n",
      "Mean Net Time:  25.41133364176346 sec\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 46.11022472381592\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.973996458382445\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 45.370600141327955\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 43.98199689799342\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:2', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 41.48154012088118\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 37.291404296611915\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 37.331425732579724\n",
      "tensor([[-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        ...,\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06],\n",
      "        [-2.7446e-06, -2.7446e-06, -2.7446e-06,  ..., -2.7446e-06,\n",
      "         -2.7446e-06, -2.7446e-06]], device='cuda:1', grad_fn=<AddmmBackward>)\n",
      "Mean time taken: 31.838055314688848\n"
     ]
    }
   ],
   "source": [
    "process_time  = []\n",
    "waiting_time = []\n",
    "net_time = []\n",
    "for job in job_queue:\n",
    "    if job_queue[job]['status_flag'][0]:\n",
    "        waiting_time.append(job_queue[job]['entry_time'][0] - job_queue[job]['arrival_time'][0])\n",
    "        process_time.append(job_queue[job]['exit_time'][0] - job_queue[job]['entry_time'][0])\n",
    "        net_time.append(job_queue[job]['exit_time'][0] - job_queue[job]['arrival_time'][0])\n",
    "\n",
    "print(\"Mean Waiting Time: \", np.mean(waiting_time), \"sec\")\n",
    "print(\"Mean Process Time: \", np.mean(process_time), \"sec\")\n",
    "print(\"Mean Net Time: \", np.mean(net_time), \"sec\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ee22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e8ee7f0c",
   "metadata": {},
   "source": [
    "T_exp      = 60        # (in sec) Time for which the exp will run\n",
    "rate       = 0.7         # job arrival rate\n",
    "Nrun       = 30      \n",
    "batch_size = 32\n",
    "fct        = 10\n",
    "\n",
    "job_queue[0] ={}\n",
    "job_queue[0]['model_split']=[1,1]\n",
    "\n",
    "#start1 = time.time()\n",
    "#run_job(0, 'baseline', \"ParallelThreeLayer\", fct, batch_size, Nrun, [0], [0] )\n",
    "#print(\"Done\", time.time()-start1)\n",
    "start2 = time.time()\n",
    "run_job(0, 'baechi', \"ParallelThreeLayer\", fct, batch_size, Nrun, [0], [0] )\n",
    "print(\"Done\", time.time()-start2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275203c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
