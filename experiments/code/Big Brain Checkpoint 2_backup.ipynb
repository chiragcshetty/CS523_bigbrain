{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d25bceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "from torch import optim, nn\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0,'..')\n",
    "\n",
    "#############################################\n",
    "## Copy of Inceptionv3, slightly modified for recording intermeridates\n",
    "#sys.path.append('/home/cshetty2/sct/pytorch')\n",
    "#import reformated_models.inception_modified as inception_modified\n",
    "\n",
    "## Modified Alexnet, with a'factor' by which it can be made 'fat' \n",
    "#import simple_model as sm\n",
    "\n",
    "## Placer libs of baechi\n",
    "#sys.path.append('/home/cshetty2/sct')\n",
    "#from placer.placer_lib import *\n",
    "##############################################\n",
    "\n",
    "#import dummyModels as dm\n",
    "import baechiTest_dummyModels as dm\n",
    "\n",
    "\n",
    "######## For profiler (some experiments. Not required) #################\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######## For debug purposes ONLY ########\n",
    "import ctypes, gc\n",
    "import psutil, os\n",
    "\n",
    "###############################Utilities#################################\n",
    "### From https://discuss.pytorch.org/t/how-pytorch-releases-variable-garbage/7277\n",
    "def memReport():\n",
    "    for obj in gc.get_objects():\n",
    "        if torch.is_tensor(obj):\n",
    "            print(type(obj), obj.size())\n",
    "    \n",
    "def cpuStats():\n",
    "        print(sys.version)\n",
    "        print(psutil.cpu_percent())\n",
    "        print(psutil.virtual_memory())  # physical memory usage\n",
    "        pid = os.getpid()\n",
    "        py = psutil.Process(pid)\n",
    "        memoryUse = py.memory_info()[0] / 2. ** 30  # memory use in GB...I think\n",
    "        print('memory GB:', memoryUse)\n",
    "        \n",
    "## Print memory of all available GPU's\n",
    "def print_gpu_memory():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        #print(torch.cuda.get_device_name(i))\n",
    "        print(\"GPU:\", i)\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,8), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,8), 'GB')\n",
    "        #print(\"-----------------\")\n",
    "        #GPUtil.showUtilization()\n",
    "        print(\"-----------\")\n",
    "        \n",
    "# Disable\n",
    "def blockPrint():\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    sys._jupyter_stdout = sys.stdout\n",
    "\n",
    "# Restore\n",
    "def enablePrint():\n",
    "    sys.stdout = sys.__stdout__\n",
    "#########################################\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff1ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from random import expovariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0073f78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from baechi_units_bigbrain import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968cda29",
   "metadata": {},
   "source": [
    "Experiment aims to demonstrate the advantage of packing training jobs on GPU (based on the resource requirements) rather than allotting integer number of GPUs per job (as container based approach would do)\n",
    "\n",
    "Measure: Throughput for these two cases and compare:\n",
    "- (1) one GPU allocation for each incoming jobs on FCFS basis\n",
    "- (2) decide a split of the incoming model among the two GPUs and run on best effort basis (the entire model maybe placed on one GPUs)\n",
    "\n",
    "Expectation: (2) should be more than (1) for two reasons:\n",
    "- granualr GPU allocation is more efficient\n",
    "- the model choosen itself runs faster when split across 2 gpus than 1 as described in next section\n",
    "\n",
    "Primitives:\n",
    "\n",
    "- GPUs : Setup consists of only 2 GPUs on one node\n",
    "- Jobs : All incoming jobs will be of same kind - to train a model dm.parallelModelThreeLayerSplit as described below\n",
    "- Training Script: run_train() is the main training routine. When a job arrives, a split for the model among two GPU's is \n",
    "- Job queue: jobs arrive as poisson process. Job queue maintains the cluster state and allots jobs with appropriate split while preventing OOMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a818dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_name, fct, repetable): \n",
    "    if model_name == \"inception_v3\":\n",
    "        model = inception_modified.inception_v3(pretrained=True)\n",
    "        inp_size_single = (3, 299, 299)\n",
    "        opt_size = 1000\n",
    "\n",
    "    if model_name == \"TallParallelModel\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, 512*factor)\n",
    "        model = dm.tallParallelModel(factor, repetable)\n",
    "        opt_size = 1000\n",
    "\n",
    "\n",
    "    if model_name == \"ParallelTwoLayer\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, int(512*factor))\n",
    "        model = dm.parallelTwoLayer(factor, repetable)\n",
    "        opt_size = 512*fct\n",
    "\n",
    "    if model_name == \"ParallelThreeLayer\":\n",
    "        factor = fct\n",
    "        inp_size_single = (1, int(512*factor))\n",
    "        model = dm.parallelThreeLayer(factor, repetable)\n",
    "        opt_size = 512*fct\n",
    "        \n",
    "    return model, inp_size_single, opt_size\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0319b0a",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5835308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, batch_size, Nrun, inp_size_single, opt_size, \\\n",
    "              first_gpu, final_gpu ):     \n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 0.0001); \n",
    "    criterion = nn.MSELoss()\n",
    "    dataset = torchvision.datasets.FakeData(\n",
    "        size= Nrun * batch_size,\n",
    "        image_size=inp_size_single,\n",
    "        num_classes=opt_size,\n",
    "        transform=torchvision.transforms.ToTensor())\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "    result = []\n",
    "\n",
    "    times = []\n",
    "    for batch_idx, (inp, oup) in enumerate(data_loader):\n",
    "        ### TODO: Remove this all-device sync by running each job in a stream\n",
    "        #torch.cuda.synchronize(0);torch.cuda.synchronize(1);torch.cuda.synchronize(2);torch.cuda.synchronize(3)\n",
    "        labels = torch.randn((batch_size,opt_size)).to(final_gpu)\n",
    "        start = time.time()\n",
    "        inp = inp.to(first_gpu); \n",
    "        optimizer.zero_grad()\n",
    "        output = model(inp)\n",
    "        #torch.cuda.synchronize(0);torch.cuda.synchronize(1);torch.cuda.synchronize(2);torch.cuda.synchronize(3)\n",
    "        ######################### loss compute ################################################\n",
    "        loss = criterion(output, labels )\n",
    "        ##################################################################################\n",
    "        loss.backward(loss)\n",
    "        optimizer.step()\n",
    "        #torch.cuda.synchronize(0);torch.cuda.synchronize(1);torch.cuda.synchronize(2);torch.cuda.synchronize(3)\n",
    "        end = time.time()\n",
    "        times.append(1000*(end-start))\n",
    "    if len(times)>10:\n",
    "        gpu_time = np.mean(times[10:])\n",
    "    else:\n",
    "        gpu_time = True\n",
    "    \n",
    "    #### Release memory\n",
    "    del inp\n",
    "    del output\n",
    "    try:\n",
    "        del labels\n",
    "        del optimizer\n",
    "        del loss\n",
    "    except: pass\n",
    "\n",
    "    return gpu_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2be865bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b1e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f48fd945",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### GLOBALS #####################################3\n",
    "\n",
    "### dict of (gpu_id, fraction of gpu available)\n",
    "resource_manager   = {}  \n",
    "resource_manager[1]= 1\n",
    "resource_manager[2]= 1\n",
    "\n",
    "### dict of job_id -> dict{model_split, status_flag, arrival_time, entry_time, exit_time}\n",
    "job_queue          = {}  \n",
    "\n",
    "end_exp_flag = [0] #flag to indicate end of experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "439d3cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_algo_1():\n",
    "    if resource_manager[1] == 1:\n",
    "        return [1,1]\n",
    "    elif resource_manager[2] == 1:\n",
    "        return [2,2]\n",
    "    else:\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3811cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_algo_2():\n",
    "    if resource_manager[1] > 0.5:\n",
    "        return [1,1]\n",
    "    elif resource_manager[2] > 0.5:\n",
    "        return [2,2]\n",
    "    elif (resource_manager[1] > 0.2 and resource_manager[2] > 0.2):\n",
    "        return [1,2]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "989006c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_resource(split, update_type):\n",
    "    if update_type == \"release\":\n",
    "        change =  1.0\n",
    "    elif update_type == \"acquire\":\n",
    "        change = -1.0\n",
    "     \n",
    "    if split == [1,1]:\n",
    "        resource_manager[1] = resource_manager[1] + 0.7*change\n",
    "    elif split == [2,2]:\n",
    "        resource_manager[2] = resource_manager[2] + 0.7*change\n",
    "    elif split == [1,2]:\n",
    "        resource_manager[1] = resource_manager[1] + 0.3*change\n",
    "        resource_manager[2] = resource_manager[2] + 0.3*change\n",
    "    else:\n",
    "        print(\"Error! split is invalid\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fb469bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_job(job_id, algo, model_name, fct, batch_size, Nrun, done_flag, exit_time ): \n",
    "    \n",
    "    repetable = 0\n",
    "    model, inp_size_single, opt_size = get_model(model_name, fct, repetable)\n",
    "    \n",
    "    inp_size = (batch_size,) + inp_size_single\n",
    "    out_size = (batch_size, opt_size)\n",
    "    \n",
    "    available_gpus = [1,2]\n",
    "    args.batch_size = str(batch_size)\n",
    "    \n",
    "    if algo == 'baseline':\n",
    "        gpu_id = job_queue[job_id]['model_split'][0]\n",
    "        model = model.to(gpu_id)\n",
    "        avg_gpu_time = run_train(model, batch_size, Nrun, inp_size_single, opt_size, \\\n",
    "                  gpu_id, gpu_id)\n",
    "        del model\n",
    "        gc.collect()              ## To clean any circular references\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    \n",
    "    if algo == 'baechi':\n",
    "        ################################################################################\n",
    "        return_graph, tester = build_graph(model, batch_size,args.prof_gpu_id, args.prof_rounds, inp_size = inp_size_single)\n",
    "        available_device_list = {k:device_list[k] for k in available_gpus}\n",
    "        DEVICE_GRAPH_MULTIPLE = create_device_graph(available_device_list)\n",
    "\n",
    "        placed_op_graph = m_topo(return_graph, DEVICE_GRAPH_MULTIPLE)\n",
    "        copy_p(return_graph, tester)\n",
    "        #########################################################\n",
    "        resource_usage = {gpu_id:0 for gpu_id in available_gpus}\n",
    "        first_gpu = -1\n",
    "        for node_id in tester.sub_module_nodes:\n",
    "            node = tester.sub_module_nodes[node_id]\n",
    "            curr_gpu_id    = node.p\n",
    "            if first_gpu < 0:\n",
    "                first_gpu = curr_gpu_id\n",
    "            curr_res_usage = node.input_memory + node.persistent_memory \\\n",
    "                            + node.temporary_memory\n",
    "            resource_usage[curr_gpu_id] += curr_res_usage\n",
    "            #print(\"layer:\", node.module)\n",
    "            #print(\"gpu:\", curr_gpu_id, \", resource:\", curr_res_usage)\n",
    "        final_gpu = curr_gpu_id\n",
    "        #print()\n",
    "        print(\"Net Resource:\", resource_usage)\n",
    "        #print([resource_usage[gpu_id]/device_list[gpu_id]['memory_size'] for gpu_id in available_gpus])\n",
    "        #print('-'*30)\n",
    "        #[resource_usage[gpu_id]/device_list[gpu_id]['memory_size'] for gpu_id in available_gpus]\n",
    "        \n",
    "        ######################################################\n",
    "\n",
    "        Assign(tester)\n",
    "\n",
    "        avg_gpu_time = run_train(tester.model, batch_size, Nrun, inp_size_single, opt_size, \\\n",
    "                  first_gpu, final_gpu )\n",
    "        ################################################################################\n",
    "        del tester\n",
    "        del placed_op_graph\n",
    "        del return_graph\n",
    "        gc.collect()              ## To clean any circular references\n",
    "        torch.cuda.empty_cache() ## Empty cache used by Pytorch (does so across all threads)\n",
    "\n",
    "    done_flag[0] = avg_gpu_time\n",
    "    exit_time[0] = time.time()\n",
    "    #print_gpu_memory()\n",
    "    print(\"Mean time taken:\", avg_gpu_time)\n",
    "\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9beaade0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_arrivals(rate, T_exp):\n",
    "    exp_start_time  = time.time()\n",
    "    t = exp_start_time \n",
    "    job_id = 0\n",
    "    \n",
    "    while t < exp_start_time + T_exp:\n",
    "        time.sleep(expovariate(rate))\n",
    "        job_id = job_id+1\n",
    "        job_queue[job_id] = {'model_split':None, 'status_flag':[0], \\\n",
    "                             'arrival_time':[time.time()], 'entry_time':[0], 'exit_time':[0]}\n",
    "        t = time.time()\n",
    "        \n",
    "    end_exp_flag[0] = 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4a4be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 0\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 1\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32, 32])) that is different to the input size (torch.Size([32, 3072])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/cuda/memory.py:263: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:30,128 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:30,129 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:30,131 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:30,132 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 4 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:41:30,132 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:30,704 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:30,705 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:30,706 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:30,707 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:41:30,708 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:37,979 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:37,980 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:37,982 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:37,983 - placer_utils:380 - INFO - device: 1, # ops: 4, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 432.07MB\n",
      "2021-12-14 20:41:37,984 - placer_utils:380 - INFO - device: 2, # ops: 7, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 396.07MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 456990720.0, 2: 420814848.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  0\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 6.914373923992288\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  1\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 10.227775573730469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:46,804 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:46,806 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:46,806 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:46,807 - placer_utils:380 - INFO - device: 1, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 504.09MB\n",
      "2021-12-14 20:41:46,808 - placer_utils:380 - INFO - device: 2, # ops: 5, # groups: 1, computation time: 1 us, temp memory: 0B, persistent memory: 324.05MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 533299200.0, 2: 344506368.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:53,297 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:53,299 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:53,300 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:53,301 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:41:53,303 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  2\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 13.50250244140625\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:41:56,369 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:41:56,371 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:41:56,372 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:41:56,373 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:41:56,374 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  3\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 11.958298189886685\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:05,505 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:05,508 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:05,509 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:05,510 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:05,511 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process:Mean time taken: 11.096054110033759\n",
      " 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  4\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  5\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:13,780 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:13,783 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:13,784 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:13,785 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:13,786 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  5\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 11.146137632172683\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:16,759 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:16,761 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:16,763 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:16,764 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:16,765 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  6\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 11.709699137457486\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:25,447 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:25,449 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:25,450 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:25,451 - placer_utils:380 - INFO - device: 1, # ops: 4, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 432.07MB\n",
      "2021-12-14 20:42:25,452 - placer_utils:380 - INFO - device: 2, # ops: 7, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 396.07MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 456990720.0, 2: 420814848.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 1\n",
      "Jobs Completed:  7\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 13.726336380531048\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  8\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:33,630 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:33,631 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:33,632 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:33,633 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:33,634 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  8\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  Mean time taken:8\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      " 13.58115919705095\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:37,840 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:37,842 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:37,843 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:37,844 - placer_utils:380 - INFO - device: 1, # ops: 4, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 432.07MB\n",
      "2021-12-14 20:42:37,846 - placer_utils:380 - INFO - device: 2, # ops: 7, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 396.07MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 456990720.0, 2: 420814848.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  9\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 14.1479072899654\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  10\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 9.671737407815867\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 1\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  11\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  11\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:50,804 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:50,805 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:50,805 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:50,805 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:50,806 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 1 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken: 9.792539991181473\n",
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 1\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 2\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 0\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:55,226 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:55,228 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:55,230 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:55,232 - placer_utils:380 - INFO - device: 1, # ops: 4, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 432.07MB\n",
      "2021-12-14 20:42:55,234 - placer_utils:380 - INFO - device: 2, # ops: 7, # groups: 1, computation time: 3 us, temp memory: 36.39MB, persistent memory: 396.07MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 456990720.0, 2: 458969088.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:42:55,459 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:42:55,460 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:42:55,461 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:42:55,462 - placer_utils:380 - INFO - device: 1, # ops: 5, # groups: 1, computation time: 3 us, temp memory: 0B, persistent memory: 468.08MB\n",
      "2021-12-14 20:42:55,462 - placer_utils:380 - INFO - device: 2, # ops: 6, # groups: 1, computation time: 3 us, temp memory: 0B, persistent memory: 360.06MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 495144960.0, 2: 382660608.0}\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 2\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 4\n",
      "Jobs Completed:  12\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Mean time taken: 9.26459575521535\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n",
      "Jobs in process: 3\n",
      "Jobs waiting: 3\n",
      "Jobs Completed:  13\n",
      "*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-\n"
     ]
    }
   ],
   "source": [
    "############### MAIN #########################\n",
    "\n",
    "T_exp      = 100        # (in sec) Time for which the exp will run\n",
    "rate       = 0.2         # job arrival rate\n",
    "Nrun       = 300      \n",
    "batch_size = 32\n",
    "fct        = 6\n",
    "\n",
    "job_server = threading.Thread(target=job_arrivals, args=(rate, T_exp, ))\n",
    "job_server.start()\n",
    "\n",
    "job_served     = 0\n",
    "jobs_in_process = []\n",
    "jobs_completed = [] \n",
    "no_jobs_waiting = []\n",
    "\n",
    "t = time.time()\n",
    "while not end_exp_flag[0]:\n",
    "    try: \n",
    "        ## Check if a new job arrived. Will fail if no new job\n",
    "        new_job = job_queue[job_served+1] \n",
    "        \n",
    "        #print(job_served+1)\n",
    "        #print(job_queue)\n",
    "        \n",
    "        if (new_job['entry_time'][0]):\n",
    "            print(\"Something went wrong! New job already has entry time\")\n",
    "        \n",
    "        ## get a resource allocation for new job\n",
    "        \n",
    "        #split = get_split_algo_1()\n",
    "        #algo = 'baseline'\n",
    "        \n",
    "        split = get_split_algo_2()\n",
    "        algo = 'baechi'\n",
    "        \n",
    "        model_name = \"ParallelThreeLayer\"\n",
    "        \n",
    "        \n",
    "        ## If resource is available then a split is returned \n",
    "        ## Else just wait\n",
    "        if split:   \n",
    "            new_job['model_split'] = split\n",
    "            ### Update resources\n",
    "            update_resource(split, 'acquire')\n",
    "            if resource_manager[1]<0 or resource_manager[2]<0:\n",
    "                print(\"Error! There's nothing like negative resources!\")\n",
    "            \n",
    "            ### Spawn a thread to start the new job\n",
    "            new_job['entry_time'][0]  = time.time()\n",
    "\n",
    "            job_submit = threading.Thread(target=run_job, args=(job_served+1, algo, model_name, fct, \\\n",
    "                                                                  batch_size, Nrun, new_job['status_flag'], \\\n",
    "                                                                  new_job['exit_time'], ))\n",
    "            job_submit.start()\n",
    "            job_served = job_served+1\n",
    "            jobs_in_process.append(job_served)\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    completed = []\n",
    "    for inprocess_job_id in jobs_in_process:\n",
    "        if job_queue[inprocess_job_id]['status_flag'][0]:\n",
    "            completed.append(inprocess_job_id)   \n",
    "            ## Release resources\n",
    "            update_resource(job_queue[inprocess_job_id]['model_split'], 'release')\n",
    "    \n",
    "    jobs_completed = jobs_completed +  completed \n",
    "    for i in completed:\n",
    "        jobs_in_process.remove(i)\n",
    "        \n",
    "    t_now = time.time()\n",
    "    if t_now-t>1:\n",
    "        ## Check for completed jobs \n",
    "        no_waiting = len(job_queue)-job_served\n",
    "        no_jobs_waiting.append(no_waiting)\n",
    "        print('*-'*20)\n",
    "        print(\"Jobs in process:\", len(jobs_in_process))\n",
    "        print(\"Jobs waiting:\",no_waiting )\n",
    "        print(\"Jobs Completed: \", len(jobs_completed))\n",
    "        print('*-'*20)\n",
    "        t = t_now\n",
    "        \n",
    "\n",
    "    time.sleep(0.1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca1001c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 20:43:08,717 - m_topo:80 - INFO - required memory=834.14MB, max op memory=145.55MB\n",
      "2021-12-14 20:43:08,718 - m_topo:94 - INFO - Max memory per device: 562.62MB\n",
      "2021-12-14 20:43:08,720 - m_topo:65 - INFO - Topo placement stats\n",
      "2021-12-14 20:43:08,721 - placer_utils:380 - INFO - device: 1, # ops: 6, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 504.09MB\n",
      "2021-12-14 20:43:08,722 - placer_utils:380 - INFO - device: 2, # ops: 5, # groups: 1, computation time: 2 us, temp memory: 0B, persistent memory: 324.05MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Resource: {1: 533299200.0, 2: 344506368.0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(no_jobs_waiting)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9261957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Waiting Time:  4.276781100493211\n",
      "Mean Process Time:  18.407396958424496\n",
      "Mean time taken: 13.889653107215619\n",
      "Mean time taken: 17.191648483276367\n",
      "Mean time taken: 12.28213228028396\n"
     ]
    }
   ],
   "source": [
    "process_time  = []\n",
    "waiting_time = []\n",
    "for job in job_queue:\n",
    "    if job_queue[job]['status_flag'][0]:\n",
    "        waiting_time.append(job_queue[job]['entry_time'][0] - job_queue[job]['arrival_time'][0])\n",
    "        process_time.append(job_queue[job]['exit_time'][0] - job_queue[job]['entry_time'][0])\n",
    "\n",
    "print(\"Mean Waiting Time: \", np.mean(waiting_time))\n",
    "print(\"Mean Process Time: \", np.mean(process_time))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ee22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e8ee7f0c",
   "metadata": {},
   "source": [
    "T_exp      = 60        # (in sec) Time for which the exp will run\n",
    "rate       = 0.7         # job arrival rate\n",
    "Nrun       = 30      \n",
    "batch_size = 32\n",
    "fct        = 10\n",
    "\n",
    "job_queue[0] ={}\n",
    "job_queue[0]['model_split']=[1,1]\n",
    "\n",
    "#start1 = time.time()\n",
    "#run_job(0, 'baseline', \"ParallelThreeLayer\", fct, batch_size, Nrun, [0], [0] )\n",
    "#print(\"Done\", time.time()-start1)\n",
    "start2 = time.time()\n",
    "run_job(0, 'baechi', \"ParallelThreeLayer\", fct, batch_size, Nrun, [0], [0] )\n",
    "print(\"Done\", time.time()-start2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf2e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
