{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baechi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "import time\n",
    "import networkx as nx\n",
    "from torch import optim, nn\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "## Copy of Inceptionv3, slightly modified for recording intermeridates\n",
    "sys.path.append('/home/cshetty2/sct/pytorch')\n",
    "import reformated_models.inception_modified as inception_modified\n",
    "\n",
    "## Modified Alexnet, with a'factor' by which it can be made 'fat' \n",
    "import simple_model as sm\n",
    "\n",
    "######## For profiler (some experiments. Not required) #################\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "## Placer libs of baechi\n",
    "sys.path.append('/home/cshetty2/sct')\n",
    "from placer.placer_lib import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments passed (usually from the command line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defined in this round about way (instead of just directly assigning) to keep it compatibble with summarize.py\n",
    "class Args:\n",
    "     def __init__(self,itype, prof_rounds, prof_gpu_id, batch_size, gpu_num, sch):\n",
    "         self.type = itype\n",
    "         self.prof_rounds = prof_rounds\n",
    "         self.prof_gpu_id = prof_gpu_id\n",
    "         self.batch_size = batch_size\n",
    "         self.gpu_num = gpu_num\n",
    "         self.sch = sch\n",
    "            \n",
    "itype       = 'forward'  # help: forward/all -> Conside forward path only or both\n",
    "prof_rounds = 40      # help: 'rounds for profiler'\n",
    "prof_gpu_id = 3      # help: 'which gpu to place the profiler'\n",
    "batch_size  = '128'   # help: 'batch_size'\n",
    "gpu_num     = 3      # help: 'number of gpu to use'\n",
    "sch         = 'sct'  # help: 'sct/etf/topo'\n",
    "\n",
    "args = Args(itype, prof_rounds, prof_gpu_id, batch_size, gpu_num, sch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device (4 GPU) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Function: placer_lib.create_device_graph\n",
    "    -> Creates a graph with devices as nodes and unit weight edges between them\n",
    "    -> Each node: graph.add_node(device_id,\n",
    "                                 id=device_id,\n",
    "                                 name=device_info[\"name\"],\n",
    "                                 size=0,\n",
    "                                 memory_limit=device_info[\"memory_size\"])\n",
    "\"\"\"\n",
    "DEVICE_GRAPH_SINGLE = create_device_graph({0: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:0', 'memory_size':  17179869184, 'type': ''}})\n",
    "DEVICE_GRAPH_MULTIPLE = create_device_graph({0: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:0', 'memory_size': 8000000000, 'type': ''}, \n",
    "                                             1: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:1', 'memory_size': 8000000000, 'type': ''}, \n",
    "                                             2: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:2', 'memory_size': 8000000000, 'type': ''}, \n",
    "                                             3: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:3', 'memory_size': 8000000000, 'type': ''}})\n",
    "\n",
    "\n",
    "device_list = {0: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:0', 'memory_size': 8000000000, 'type': ''}, \n",
    "               1: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:1', 'memory_size': 8000000000, 'type': ''}, \n",
    "               2: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:2', 'memory_size': 8000000000, 'type': ''}, \n",
    "               3: {'name': '/job:localhost/replica:0/task:0/device:XLA_GPU:3', 'memory_size': 8000000000, 'type': ''}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    we are going to use streams to allow parallel processing\n",
    "\"\"\"\n",
    "COMPUTE0 = torch.cuda.Stream(device=0)\n",
    "COMPUTE1 = torch.cuda.Stream(device=1)\n",
    "COMPUTE2 = torch.cuda.Stream(device=2)\n",
    "COMPUTE3 = torch.cuda.Stream(device=3)\n",
    "COMPUTE_STREAM = {0:COMPUTE0,1:COMPUTE1,2:COMPUTE2,3:COMPUTE3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print memory of all available GPU's\n",
    "def print_gpu_memory():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        #print(torch.cuda.get_device_name(i))\n",
    "        print(\"GPU:\", i)\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,8), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,8), 'GB')\n",
    "        #print(\"-----------------\")\n",
    "        #GPUtil.showUtilization()\n",
    "        print(\"-----------\")\n",
    "\n",
    "# print memory of given GPU. ex: gpu_no = 0\n",
    "def print_mem(gpu_id, cached=2, unit='GB'):\n",
    "    if unit=='GB':\n",
    "        mem_allocated = round(torch.cuda.memory_allocated(gpu_id)/1024**3,8)\n",
    "        mem_cached    = round(torch.cuda.memory_reserved(gpu_id)/1024**3,8)\n",
    "    else:\n",
    "        mem_allocated = torch.cuda.memory_allocated(gpu_id)\n",
    "        mem_cached    = torch.cuda.memory_reserved(gpu_id)\n",
    "        \n",
    "    if cached>0:\n",
    "        print('Allocated:', mem_allocated , 'GB')\n",
    "    if cached>1:\n",
    "        print('Cached:   ', mem_cached    , 'GB')\n",
    "    return mem_allocated, mem_cached\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the leaf operations in a model. model.modules() gives not just the leaves, bbut higher levels as well\n",
    "# Ref: https://stackoverflow.com/questions/54846905/pytorch-get-all-layers-of-model\n",
    "# More explanation: https://discuss.pytorch.org/t/module-children-vs-module-modules/4551/4\n",
    "def get_children(model: torch.nn.Module):\n",
    "    # get children form model!\n",
    "    children = list(model.children())\n",
    "    flatt_children = {}\n",
    "    if children == []:\n",
    "        # if model has no children; model is last child! :O\n",
    "        return {id(model): model}\n",
    "    else:\n",
    "       # look for children from children... to the last child!\n",
    "       for child in children:\n",
    "            try:\n",
    "                flatt_children.update(get_children(child))\n",
    "            except TypeError:\n",
    "                flatt_children.update(get_children(child))\n",
    "    return flatt_children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b2gb(x): return round(x/2**30,8)\n",
    "class TorchTracemalloc():\n",
    "    def __init__(self, gpu_id):\n",
    "        self.gpu_id = gpu_id\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.begin = torch.cuda.memory_allocated(self.gpu_id)\n",
    "        torch.cuda.reset_max_memory_allocated(self.gpu_id) # reset the peak gauge to zero\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        self.end  = torch.cuda.memory_allocated(self.gpu_id)\n",
    "        self.peak = torch.cuda.max_memory_allocated(self.gpu_id)\n",
    "        self.used   = (self.end-self.begin)\n",
    "        self.peaked = (self.peak-self.begin)\n",
    "\n",
    "#### Estimate size of the model (in GB or MB or )\n",
    "\n",
    "def estimate_model_size(model, unit='MB', to_print = True): \n",
    "    persistent_memory = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        persistent_memory += param.element_size() * param.nelement()\n",
    "    if unit == 'GB':\n",
    "        gb_mem = round(persistent_memory/1024**3,8)\n",
    "        if to_print:\n",
    "            print(\"Estimated Model Memory:\",gb_mem, \"GB\")\n",
    "        return gb_mem\n",
    "    elif unit == 'B':\n",
    "        gb_mem = persistent_memory\n",
    "        if to_print:\n",
    "            print(\"Estimated Model Memory:\",gb_mem, \"Bytes\")\n",
    "        return gb_mem\n",
    "    else:\n",
    "        mb_mem = round(persistent_memory/1024**2,8)\n",
    "        if to_print:\n",
    "            print(\"Estimated Model Memory:\", mb_mem, \"MB\")\n",
    "        return mb_mem\n",
    "    \n",
    "def estimate_tensor_size(inp, unit='B'):\n",
    "    input_size = 0\n",
    "    if isinstance(inp, torch.Tensor): \n",
    "        input_size += float(torch.prod(torch.tensor(inp.size())))\n",
    "    if isinstance(inp, list): \n",
    "        for sub_inp in inp:\n",
    "            if isinstance(sub_inp, torch.Tensor): input_size += float(torch.prod(torch.tensor(sub_inp.size())))\n",
    "\n",
    "    input_size = input_size*torch.rand((1,1)).element_size() # multiply by 4\n",
    "    if unit == 'GB':\n",
    "        gb_mem = round(input_size/1024**3,8)\n",
    "        #print(\"Estimated Input/Output Memory:\",gb_mem, \"GB\")\n",
    "        return gb_mem\n",
    "    if unit == 'B':\n",
    "        gb_mem = input_size\n",
    "        #print(\"Estimated Input/Output Memory:\",gb_mem, \"B\")\n",
    "        return gb_mem\n",
    "    else:\n",
    "        mb_mem = round(input_size/1024**2,8)\n",
    "        #print(\"Estimated Input/Output Memory:\", mb_mem, \"MB\")\n",
    "        return mb_mem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SubModuleNode - Represent a node (layer) \\\n",
    "A layer here means the most basic units used to build a network in pytorch. Eg: Linear, Relu, Conv2d, maxpool etc \n",
    "\n",
    "Attributes: \\\n",
    "    - name \\\n",
    "    - parent \\\n",
    "    - children \\\n",
    "    - weight_forward =====> Forward runtime of the layer (in ms) \\\n",
    "    - weight_backward =====> Backward runtime of the layer (in ms) \\\n",
    "    - id_hash ====> Layers python id \\\n",
    "    - persistent_memory ====> Memory occupied by layer parameters \\\n",
    "    - input_memory ====> Size of input to the layer (in bytes) \\\n",
    "    - output_memory ====> Size of output of the layer (in bytes) \\\n",
    "    - temporary_memory ====> temporary memory used by the layers forward run \\\n",
    "    - p ====> GPU to which the layer is finally assigned \n",
    "    \n",
    "To do:   \n",
    "- Add temporary_memory for backward run\n",
    "- Compute backward runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubModuleNode:\n",
    "    \"\"\"\n",
    "    This class represents a submodel (ex. conv2d layer) in the given model (ex. inception_v3). \n",
    "    It is represented as a node in the return graph\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # store the entire submodel\n",
    "        self.module = None\n",
    "        # submodel name\n",
    "        self.name = None\n",
    "\n",
    "        # nodes that must finish processing before this node (direct dependencies)\n",
    "        self.parent = set()\n",
    "        # nodes that depends on this node\n",
    "        self.children = set()\n",
    "\n",
    "        # forward function's estimated runtime\n",
    "        self.weight_forward = 0\n",
    "        # backward function's estimated runtime\n",
    "        self.weight_backward = 0\n",
    "        # id represented by the model's location (python's id function)\n",
    "        self.id_hash = None\n",
    "        # sudo id used, for one model, this sudo id starts from 0 and add 1 for each new node\n",
    "        # -- self.id = None\n",
    "        # storage used by submodel's parameters (weight, bias)\n",
    "        self.persistent_memory = 0\n",
    "        # submodel's input's size\n",
    "        self.input_memory = 0\n",
    "        # submodel's output's size\n",
    "        self.output_memory = 0\n",
    "        # temporary memory used in forward run\n",
    "        self.temporary_memory = 0\n",
    "        \n",
    "        # gpu assigned to the submodule\n",
    "        self.p = None\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling - class that creates SubModuleNode nodes (one per layer) complete with all thhe profiling data\n",
    "\n",
    "- run() method runs a dummy run of training loop and profiles each layer. First it calls recur_function() and then does training runs (first few iterations are ignored)\n",
    "- Given a model, recur_function breaks it down to individual layers and replaces their forward function with forward wrapper which creates a SubModuleNode node containing:\n",
    "    - average forward time\n",
    "    - model, input, output and temporary memory requirements\n",
    "- recur_function also adds to each layer:\n",
    "    - backward hook which are later used to compute backward time\n",
    "    - forward hook which modifies layer's output metadata to include the layer-name that created the output \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profiling:\n",
    "    \"\"\"\n",
    "    This class produce the profile, this class referenced \"https://github.com/msr-fiddle/pipedream\"\n",
    "    \"\"\"\n",
    "    def __init__(self, model, gpu=0, rounds=20, input_size=(3, 299, 299)):\n",
    "        \"\"\"\n",
    "        model: ex. inception_v3 model, alexnet model, etc\n",
    "        gpu: choose in between {0,1,2,3}\n",
    "        rounds: number of rounds to run the profiling\n",
    "        \"\"\"\n",
    "        self.gpu = gpu\n",
    "        self.model = model.to(self.gpu)\n",
    "        self.input_size = input_size\n",
    "\n",
    "        self.rounds = rounds\n",
    "        # first few rounds are inaccurate, so I choose to discard the results from the first 1/4 rounds\n",
    "        self.ignore_rounds = int(self.rounds/4)\n",
    "        # counting variable, runs from 0 - self.rounds\n",
    "        self.cur_round = 0\n",
    "\n",
    "        # used to calculate backward runtime for each submodule\n",
    "        self.back_record = []\n",
    "        # all submodules record of the form {id of the layer(submodule) : SubModuleNode created out of tha layer}\n",
    "        self.sub_module_nodes = {}\n",
    "        # use id_hash to record the order of submodules's execution\n",
    "        self.submodule_order = []\n",
    "\n",
    "        # internal use only, record the original forward functions for submodules\n",
    "        self.forward_original_methods = {}\n",
    "        # internal use only, switch back to the original forward functions after profiling\n",
    "        self.detach_record = set()\n",
    "        # Collect handles to all hooks added, so as to remove them in detach()\n",
    "        self.hook_handles = []\n",
    "\n",
    "\n",
    "    def recur_function(self, module):\n",
    "        \"\"\"\n",
    "        modify self.model: adding forward timing, backward timing, input output sizes, etc\n",
    "        :param module: the model to recursively add forward/backward wrappers to\n",
    "        \"\"\"\n",
    "        this_profiler = self\n",
    "        sub_modules = module.__dict__['_modules']\n",
    "        for name, sub_module in sub_modules.items():\n",
    "            # sub modules of sub_module, if there are more than 1, we need further recursion\n",
    "            sub_sub_modules = sub_module.__dict__['_modules']\n",
    "            if len(sub_sub_modules) > 0:\n",
    "                self.recur_function(sub_module)\n",
    "                continue\n",
    "            \n",
    "            def _calculate_time_and_memory(function, *input):\n",
    "                \"\"\"\n",
    "                - Helper function in forward wrapper\n",
    "                - Calculates forward runtime, peak memory used and static memory used\n",
    "                - Verified: Memory measurement context doesn't add overhead to\n",
    "                  time measurement\n",
    "                \"\"\"\n",
    "                with TorchTracemalloc(self.gpu) as tt:\n",
    "                    torch.cuda.synchronize(self.gpu)\n",
    "                    start_time = time.time()\n",
    "                    result = function(*input)\n",
    "                    torch.cuda.synchronize(self.gpu)\n",
    "                    stop_time = time.time()\n",
    "                return (stop_time - start_time) * 1000, tt.used, tt.peaked , result\n",
    "\n",
    "            def forward_wrapper(cur_module, *input):\n",
    "                \"\"\"\n",
    "                use this wrapper to replace the original forward function in submodules\n",
    "                :param cur_module: the input submodule\n",
    "                \"\"\"\n",
    "                # original forward function\n",
    "                \n",
    "                function = this_profiler.forward_original_methods[cur_module]\n",
    "                if this_profiler.cur_round < this_profiler.ignore_rounds:\n",
    "                    if this_profiler.cur_round == 0:\n",
    "                        # record submodule execution order only in the first round\n",
    "                        print('-->', \"Module name: \",cur_module)\n",
    "                        this_profiler.submodule_order.append(id(cur_module))\n",
    "                    # do not record first few rounds\n",
    "                    result = function(*input)\n",
    "                    return result\n",
    "                \n",
    "                ## collect relevant information of cur module\n",
    "                forward_time, used_mem, peak_mem, result = _calculate_time_and_memory(function, *input)\n",
    "                \n",
    "                ## Input size in bytes\n",
    "                input_size = 0\n",
    "                for inp in input:\n",
    "                    input_size = input_size + estimate_tensor_size(inp, 'B')\n",
    "                \n",
    "                ## Model size in bytes\n",
    "                persistent_memory = estimate_model_size(cur_module,'B', False)\n",
    "\n",
    "                output_memory = estimate_tensor_size(result, 'B')\n",
    "                \n",
    "                '''\n",
    "                if not(used_mem==512*np.ceil(output_memory/512)):\n",
    "                    print('*'*50)\n",
    "                    print(\"In sumodule \", cur_module , ':' )\n",
    "                    print(\"Output memory is: \", output_memory)\n",
    "                    print(\"But used memory is: \", used_mem)\n",
    "                    print(\"They dont match upto a factor of 512 (since mem bolcks are alotted in 512 byte locks) as expected\")\n",
    "                    print('*'*50)\n",
    "                '''\n",
    "                    \n",
    "                temporary_memory = peak_mem - used_mem\n",
    "\n",
    "                # record a SubModuleNode for each model layer\n",
    "                if id(cur_module) not in this_profiler.sub_module_nodes:\n",
    "                    cur_node = SubModuleNode()\n",
    "                    cur_node.id_hash = id(cur_module)\n",
    "                    cur_node.module = cur_module\n",
    "                    cur_node.name = cur_module.__class__.__name__\n",
    "                    \n",
    "                    #***********?????????????????????????????????????????***************************\n",
    "                    ########## REMOVE THIS ######################\n",
    "                    cur_node.persistent_memory = persistent_memory\n",
    "                    cur_node.temporary_memory = temporary_memory\n",
    "                    cur_node.output_memory = output_memory\n",
    "                    cur_node.input_memory = input_size\n",
    "                    #############################################\n",
    "                    #***********?????????????????????????????????????????***************************\n",
    "                    \n",
    "                    ### And Uncomment this\n",
    "                    #cur_node.persistent_memory = persistent_memory\n",
    "                    #cur_node.temporary_memory = temporary_memory\n",
    "                    #cur_node.output_memory = output_memory\n",
    "                    #cur_node.input_memory = input_size\n",
    "                    \n",
    "                else:\n",
    "                    cur_node = this_profiler.sub_module_nodes[id(cur_module)]\n",
    "                # we want weight_forward as the average forward runtime of the relevent rounds\n",
    "                cur_node.weight_forward += forward_time / (this_profiler.rounds - this_profiler.ignore_rounds)\n",
    "                this_profiler.sub_module_nodes[id(cur_module)] = cur_node\n",
    "\n",
    "                return result\n",
    "\n",
    "            def hook(cur_module, inputs, output):\n",
    "                # this is for retriving the module inside make dot function\n",
    "                output.grad_fn.metadata['module'] = cur_module\n",
    "\n",
    "            def backward_post_hook(cur_module, input, output):\n",
    "                \"\"\"\n",
    "                add backward hook to record backward runtime\n",
    "                :param cur_module: the input submodule\n",
    "                \"\"\"\n",
    "                if this_profiler.cur_round < this_profiler.ignore_rounds:\n",
    "                    # do not record first few rounds\n",
    "                    return\n",
    "                torch.cuda.synchronize(0)\n",
    "                cur_time = time.time() * 1000\n",
    "                this_profiler.back_record.append((id(cur_module), cur_time))\n",
    "\n",
    "            if sub_module in self.forward_original_methods:\n",
    "                # only record the original forward functions once\n",
    "                continue\n",
    "\n",
    "            self.forward_original_methods[sub_module] = sub_module.forward\n",
    "            sub_module.forward = forward_wrapper.__get__(sub_module, sub_module.__class__)\n",
    "            fhook_handle = sub_module.register_forward_hook(hook)\n",
    "            bhook_handle =  sub_module.register_backward_hook(backward_post_hook)\n",
    "            this_profiler.hook_handles.append(fhook_handle)\n",
    "            this_profiler.hook_handles.append(bhook_handle)\n",
    "            \n",
    "            \n",
    "    def detach(self, module):\n",
    "        \"\"\"\n",
    "        use this helper function to detach all forward wrappers\n",
    "        \"\"\"\n",
    "        this_profiler = self\n",
    "        sub_modules = module.__dict__['_modules']\n",
    "        for name, sub_module in sub_modules.items():\n",
    "            sub_sub_modules = sub_module.__dict__['_modules']\n",
    "            if len(sub_sub_modules) > 0:\n",
    "                self.detach(sub_module)\n",
    "                continue\n",
    "            if sub_module in self.detach_record:\n",
    "                continue\n",
    "\n",
    "            self.detach_record.add(sub_module)\n",
    "            sub_module.forward = self.forward_original_methods[sub_module]\n",
    "        ## Remove all the hooks that were added\n",
    "        for handle in this_profiler.hook_handles:\n",
    "            handle.remove()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        :return: the model's output of the final round\n",
    "        \"\"\"\n",
    "        self.sub_module_nodes = {}\n",
    "        self.recur_function(self.model)\n",
    "\n",
    "        # create a fake dataset, we don't care about accuracy.\n",
    "        dataset = torchvision.datasets.FakeData(\n",
    "            size=self.rounds * int(args.batch_size),\n",
    "            #image_size=(3, 299, 299),\n",
    "            image_size = self.input_size,\n",
    "            num_classes=1000,\n",
    "            transform=torchvision.transforms.ToTensor())\n",
    "        data_loader = torch.utils.data.DataLoader(dataset, batch_size=int(args.batch_size))\n",
    "\n",
    "        # this is the output of the final round\n",
    "        last_output = None\n",
    "        for batch_idx, (inp, oup) in enumerate(data_loader):\n",
    "            self.cur_round = batch_idx\n",
    "            # clear the record list\n",
    "            self.back_record = []\n",
    "\n",
    "            inp = inp.to(self.gpu); inp.requires_grad = True\n",
    "            optimizer = optim.SGD(self.model.parameters(), lr = 0.0001); optimizer.zero_grad()\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            torch.cuda.synchronize(self.gpu)\n",
    "            output = self.model(inp)\n",
    "            torch.cuda.synchronize(self.gpu)\n",
    "             \n",
    "            \n",
    "            ######################### loss compute ################################################\n",
    "            try:\n",
    "                loss = criterion(output, torch.randn(int(args.batch_size), len(output)).to(self.gpu))\n",
    "            except:\n",
    "                loss = criterion(output, torch.randn(int(args.batch_size), len(output[0])).to(self.gpu))\n",
    "            ##################################################################################\n",
    "\n",
    "            # add the start time of backward \n",
    "            self.back_record.append(('start', time.time() * 1000))\n",
    "            if batch_idx == self.rounds - 1:\n",
    "                #loss.backward(loss, retain_graph=True)\n",
    "                loss.backward(loss)\n",
    "                last_output = output\n",
    "            else:\n",
    "                loss.backward(loss)\n",
    "            #print_mem(0,1)\n",
    "            #print('*'*50)\n",
    "\n",
    "            if batch_idx < self.ignore_rounds:\n",
    "                continue\n",
    "            else:\n",
    "                # calculate the backward runtime for each layer by calculating the time differences between each timestamp\n",
    "                for i in range(len(self.back_record) - 1, 0, -1):\n",
    "                    now = self.back_record[i]\n",
    "                    prev = self.back_record[i - 1]\n",
    "                    cur_node = self.sub_module_nodes[now[0]]\n",
    "                    cur_node.weight_backward += (now[1] - prev[1]) / (self.rounds - self.ignore_rounds)\n",
    "                    self.sub_module_nodes[now[0]] = cur_node\n",
    "        self.detach(self.model)\n",
    "        return last_output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip - Local Test ** ** ** ** ***** *** *** ***** ** **** ***** ***** ***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = sm.toyToyModel(factor=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tester = Profiling(model, args.prof_gpu_id, args.prof_rounds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "final_output = tester.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## probe the profiler object\n",
    "\n",
    "'''\n",
    "cur_node = SubModuleNode()\n",
    "cur_node.id_hash = id(cur_module)\n",
    "cur_node.module = cur_module\n",
    "cur_node.name = cur_module.__class__.__name__\n",
    "cur_node.persistent_memory = persistent_memory\n",
    "cur_node.temporary_memory = temporary_memory\n",
    "cur_node.output_memory = output_memory\n",
    "cur_node.input_memory = input_size\n",
    "cur_node.weight_forward\n",
    "'''\n",
    "sumi = 0\n",
    "for idx, node in tester.sub_module_nodes.items():\n",
    "    sumi = sumi+node.temporary_memory \n",
    "    print(node.name, node.temporary_memory )\n",
    "print(sumi)\n",
    "\n",
    "assert (estimate_model_size(model, 'B') == sum([node.persistent_memory for _,node in tester.sub_module_nodes.items()]) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ** ** *** *** *** ****** ******** ******* ****** ***** ******* ***** ***** ********"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_dot - create DiGraph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dot_original(var, cur_model):\n",
    "    \"\"\"\n",
    "    this function build a DiGraph for the model, by tracing the grad function of each layer's output\n",
    "    :return: the DiGraph\n",
    "    \"\"\"\n",
    "    dot = nx.DiGraph()\n",
    "    seen = set()\n",
    "    output_nodes = (var.grad_fn,) if not isinstance(var, tuple) else tuple(v.grad_fn for v in var)\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            cur_id = None\n",
    "            if var.metadata != {}:\n",
    "                # this submodule has a forward function, so it's information is previously recorded in Profiling\n",
    "                cur_id = id(var.metadata['module'])\n",
    "                # retrieve the node representing this submodule\n",
    "                cur_node = cur_model.sub_module_nodes[id(var.metadata['module'])]\n",
    "                dot.add_node(id(var.metadata['module']), \n",
    "                             model = str(cur_node.module), \n",
    "                             name = str(cur_node.name), \n",
    "                             weight=cur_node.weight_forward,\n",
    "                             reverse_weight=cur_node.weight_backward,\n",
    "                             id=id(var.metadata['module']), \n",
    "                             topo_order=id(var.metadata['module']), \n",
    "                             temporary_memory=cur_node.temporary_memory, \n",
    "                             persistent_memory=cur_node.persistent_memory,\n",
    "                             output_memory=[cur_node.output_memory], \n",
    "                             output_tensors=cur_node.output_memory, \n",
    "                             colocation_group=\"\")\n",
    "            else:\n",
    "                # this 'submodule' has no forward function, we assume that the forward runtime & backward runtime can be ignored\n",
    "                cur_id = id(var)\n",
    "                dot.add_node(id(var), \n",
    "                             model = None, \n",
    "                             name = str(type(var).__name__),\n",
    "                             weight=0.000000001, \n",
    "                             reverse_weight=0.000000001,\n",
    "                             id=id(var), \n",
    "                             topo_order=id(var),\n",
    "                             temporary_memory=0, \n",
    "                             persistent_memory=0, \n",
    "                             output_memory=[0], \n",
    "                             output_tensors=0, \n",
    "                             colocation_group=\"\")\n",
    "                if cur_id not in cur_model.sub_module_nodes:\n",
    "                    # should only occur once for the final output\n",
    "                    represent_node = SubModuleNode()\n",
    "                    represent_node.name = str(type(var).__name__)\n",
    "                    represent_node.id_hash = cur_id\n",
    "                    cur_model.sub_module_nodes[cur_id] = represent_node\n",
    "\n",
    "            seen.add(var)\n",
    "\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None and torch.is_tensor(u[0]) is False and hasattr(u[0], 'variable') is False:\n",
    "                        next_id = id(u[0])\n",
    "                        if u[0].metadata != {}: \n",
    "                            next_id = id(u[0].metadata['module'])\n",
    "                        else:\n",
    "                            # append a new node to model's record if not seen before\n",
    "                            represent_node = SubModuleNode()\n",
    "                            represent_node.name = str(type(u[0]).__name__)\n",
    "                            represent_node.id_hash = id(u[0])\n",
    "                            cur_model.sub_module_nodes[id(u[0])] = represent_node\n",
    "                        cur_model.sub_module_nodes[next_id].children.add(cur_id)\n",
    "                        cur_model.sub_module_nodes[cur_id].parent.add(next_id)\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    if torch.is_tensor(t) or hasattr(t, 'variable'): continue\n",
    "                    next_id = id(t)\n",
    "                    if t.metadata != {}:\n",
    "                        next_id = id(t.metadata['module'])\n",
    "                    else:\n",
    "                        # append a new node to model's record if not seen before\n",
    "                        represent_node = SubModuleNode()\n",
    "                        represent_node.name = str(type(t).__name__)\n",
    "                        represent_node.id_hash = id(t)\n",
    "                        cur_model.sub_module_nodes[id(t)] = represent_node\n",
    "                    cur_model.sub_module_nodes[next_id].children.add(cur_id)\n",
    "                    cur_model.sub_module_nodes[cur_id].parent.add(next_id)\n",
    "                    add_nodes(t)\n",
    "\n",
    "    if isinstance(var, tuple):\n",
    "        # handle multiple outputs\n",
    "        for v in var:\n",
    "            add_nodes(v.grad_fn)\n",
    "    else:\n",
    "        add_nodes(var.grad_fn)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "make_dot is modified to add nodes for only the autograd corresponding to layers\n",
    "'''\n",
    "\n",
    "def make_dot(var, cur_model):\n",
    "    \"\"\"\n",
    "    this function build a DiGraph for the model, by tracing the grad function of each layer's output\n",
    "    :return: the DiGraph\n",
    "    \"\"\"\n",
    "    dot = nx.DiGraph()\n",
    "    seen = set()\n",
    "    output_nodes = (var.grad_fn,) if not isinstance(var, tuple) else tuple(v.grad_fn for v in var)\n",
    "\n",
    "    def add_nodes(var):\n",
    "        print(\"Dealing with this variable:\", var)\n",
    "        if var not in seen:\n",
    "            cur_id = None\n",
    "            if var.metadata != {}:\n",
    "                if ('module' in var.metadata):\n",
    "                    # this submodule has a forward function, so it's information is previously recorded in Profiling\n",
    "                    cur_id = id(var.metadata['module'])\n",
    "                    # retrieve the node representing this submodule\n",
    "                    cur_node = cur_model.sub_module_nodes[id(var.metadata['module'])]\n",
    "                    dot.add_node(id(var.metadata['module']), \n",
    "                                 model = str(cur_node.module), \n",
    "                                 name = str(cur_node.name), \n",
    "                                 weight=cur_node.weight_forward,\n",
    "                                 reverse_weight=cur_node.weight_backward,\n",
    "                                 id=id(var.metadata['module']), \n",
    "                                 topo_order=id(var.metadata['module']), \n",
    "                                 temporary_memory=cur_node.temporary_memory, \n",
    "                                 persistent_memory=cur_node.persistent_memory,\n",
    "                                 output_memory=[cur_node.output_memory], \n",
    "                                 output_tensors=cur_node.output_memory, \n",
    "                                 colocation_group=\"\")\n",
    "                    \n",
    "                    if hasattr(var, 'next_functions'):\n",
    "                        for u in var.next_functions:\n",
    "                            if u[0] is not None and torch.is_tensor(u[0]) is False and hasattr(u[0], 'variable') is False:\n",
    "                                if u[0].metadata != {}:\n",
    "                                    if ('module' in u[0].metadata):\n",
    "                                        next_id = id(u[0].metadata['module'])\n",
    "                                        cur_model.sub_module_nodes[next_id].children.add(cur_id)\n",
    "                                        cur_model.sub_module_nodes[cur_id].parent.add(next_id)\n",
    "                                    elif ('parent' in u[0].metadata):\n",
    "                                        u[0].metadata['parent'].add(cur_id)\n",
    "                                    else:\n",
    "                                        print(\"Error:\", u[0], \" has metadata that is neither module nor parent!\")\n",
    "                                        return 0\n",
    "                                else:\n",
    "                                    u[0].metadata['parent'] = set()\n",
    "                                    u[0].metadata['parent'].add(cur_id)\n",
    "                                    \n",
    "                                add_nodes(u[0])\n",
    "                                \n",
    "                elif ('parent' in var.metadata):\n",
    "                    cur_id_list = []\n",
    "                    for parent in var.metadata['parent']:\n",
    "                        cur_id_list.append(parent)\n",
    "                    if hasattr(var, 'next_functions'):\n",
    "                        for u in var.next_functions:\n",
    "                            if u[0] is not None and torch.is_tensor(u[0]) is False and hasattr(u[0], 'variable') is False:\n",
    "                                if u[0].metadata != {}:\n",
    "                                    if ('module' in u[0].metadata):\n",
    "                                        next_id = id(u[0].metadata['module'])\n",
    "                                        for cur_id in cur_id_list:\n",
    "                                            cur_model.sub_module_nodes[next_id].children.add(cur_id)\n",
    "                                            cur_model.sub_module_nodes[cur_id].parent.add(next_id)\n",
    "                                    elif ('parent' in u[0].metadata):\n",
    "                                        for cur_id in cur_id_list:\n",
    "                                            u[0].metadata['parent'].add(cur_id)\n",
    "                                    else:\n",
    "                                        print(\"Error:\", u[0], \" has metadata that is neither module nor parent!\")\n",
    "                                        return 0\n",
    "                                else:\n",
    "                                    u[0].metadata['parent'] = set()\n",
    "                                    for cur_id in cur_id_list:\n",
    "                                        u[0].metadata['parent'].add(cur_id)\n",
    "                                add_nodes(u[0])\n",
    "                \n",
    "            else:\n",
    "                ## All functions will have either 'module' or 'parent' metadata\n",
    "                print('*'*100)\n",
    "                print(\"Error:\", var, \" does not have any metadata!\")\n",
    "                print(var.__dict__)\n",
    "                print('*'*100)\n",
    "                return 0\n",
    "\n",
    "            seen.add(var)\n",
    "\n",
    "    if isinstance(var, tuple):\n",
    "        # handle multiple outputs\n",
    "        for v in var:\n",
    "            add_nodes(v.grad_fn)\n",
    "    else:\n",
    "        add_nodes(var.grad_fn)\n",
    "    \n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities required to build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(model):\n",
    "    \"\"\"\n",
    "    this helper function helps to generate the execution order based on dependecies\n",
    "    \"\"\"\n",
    "    record = set()\n",
    "    while len(record) < len(model.sub_module_nodes):\n",
    "        root_helper = set(model.sub_module_nodes.keys()) - record\n",
    "        reordered_root_helper = []\n",
    "        for elem in model.submodule_order:\n",
    "            if elem in root_helper:\n",
    "                reordered_root_helper.append(elem)\n",
    "        reordered_root_helper += list(root_helper - set(reordered_root_helper))\n",
    "        for elem in root_helper:\n",
    "            parents = model.sub_module_nodes[elem].parent\n",
    "            if parents is None or len(parents - record) == 0:\n",
    "                model.sub_module_nodes[elem].id = len(record)\n",
    "                record.add(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def copy_p(assigned_graph, model):\n",
    "    \"\"\"\n",
    "    helper function to add .p field based on the assigned DiGraph \n",
    "    \"\"\"\n",
    "    for node_id in model.sub_module_nodes:\n",
    "        model.sub_module_nodes[node_id].p = assigned_graph.nodes[model.sub_module_nodes[node_id].id][\"p\"]\n",
    "\n",
    "        \n",
    "def recursively_assign(Input, Device):\n",
    "    \"\"\"\n",
    "    helper function to assign Input recursively to a gpu Device\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    if isinstance(Input, list):\n",
    "        result = []\n",
    "        for elem in Input:\n",
    "            result.append(recursively_assign(elem, Device))\n",
    "    else:\n",
    "        if Input.device.index != Device:\n",
    "            result = Input.cuda(Device)\n",
    "        else:\n",
    "            result = Input\n",
    "    return result\n",
    "\n",
    "\n",
    "def print_assigned_graph(return_graph):\n",
    "    \"\"\"\n",
    "    helper function to print where each layer is assigned to\n",
    "    :param return_graph: assigned DiGraph\n",
    "    \"\"\"\n",
    "    my_record = {}\n",
    "    for node in return_graph.nodes(data=True):\n",
    "        my_record[node[1]['topo_order']] = (node[1]['name'], node[1]['persistent_memory'], node[1]['weight'], node[1]['p'])\n",
    "\n",
    "    for i in range(len(return_graph.nodes)):\n",
    "        print(i, my_record[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test make_dot"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = sm.linearModel(factor=1)\n",
    "tester = Profiling(model, args.prof_gpu_id, args.prof_rounds, input_size=(1,10000))\n",
    "\n",
    "#model = sm.toyToyModel(factor=1)\n",
    "#tester = Profiling(model, args.prof_gpu_id, args.prof_rounds)\n",
    "\n",
    "final_output = tester.run()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "return_graph = make_dot(final_output, tester)\n",
    "tester.sub_module_nodes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for curid in list(return_graph.nodes):\n",
    "    #print(return_graph.nodes[curid])\n",
    "    print(\"Children: \", tester.sub_module_nodes[curid].children)\n",
    "    print(\"My id: \", curid)\n",
    "    print(\"Parents: \",tester.sub_module_nodes[curid].parent)\n",
    "    print('*'*50)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Sanity Check: Check sum of persistent memory = model size\n",
    "\n",
    "netsum = 0\n",
    "for curid in list(return_graph.nodes):\n",
    "    net_mem = return_graph.nodes[curid]['persistent_memory']\n",
    "    netsum = netsum + net_mem\n",
    "netsum/1024**2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "estimate_model_size(model, unit='MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect the DiGraph nodes created by make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(model, gpu=0, rounds=1, inp_size = (3,299,299)):\n",
    "    \"\"\"\n",
    "    this is the main function to call for building the graph, it calls profiling and make dot, and made further improvements\n",
    "    :param model: input model (ex. inception_v3)\n",
    "    :param gpu: which gpu to place the profiler\n",
    "    :param rounds: number of rounds to run the profiling\n",
    "    :return: the DiGraph, and the Profiling object\n",
    "    \"\"\"\n",
    "    print(\"Profiling started\", '*'*20)\n",
    "    tester = Profiling(model, gpu, rounds, input_size = inp_size)\n",
    "    final_output = tester.run()\n",
    "    \n",
    "    print(\"make_dot started\", '*'*20)\n",
    "    return_graph = make_dot(final_output, tester)\n",
    "\n",
    "    print(\"Sort topologically\", '*'*20)\n",
    "    topological_sort(tester)\n",
    "    \n",
    "    # use the sudo id instead of hash_id, this is for scheduler purpose\n",
    "    print(\"Replacing sub module id\", '*'*20)\n",
    "    for node_id in tester.sub_module_nodes.keys():\n",
    "        model_node = tester.sub_module_nodes[node_id]\n",
    "        #if len(model_node.parent)==0 and len(model_node.children)==0:\n",
    "        #    print('*'*50)\n",
    "        #    print(\"Module defined but not used:\")\n",
    "        #    print(model_node.__dict__)\n",
    "        #    print('*'*50)\n",
    "        #else:\n",
    "        graph_node = return_graph.nodes[node_id]\n",
    "        graph_node[\"id\"] = model_node.id\n",
    "        graph_node[\"topo_order\"] = model_node.id\n",
    "        return_graph.add_nodes_from([(model_node.id, graph_node)])\n",
    "        return_graph.remove_node(node_id)\n",
    "\n",
    "    # since some 'sub module' have no forward function, we have limited data on them. So we assume their output's size to be their parent's output's size\n",
    "    for new_id in range(len(return_graph.nodes(data=True))):\n",
    "        for node_id in tester.sub_module_nodes.keys():\n",
    "            if tester.sub_module_nodes[node_id].id == new_id:\n",
    "                old_id = node_id\n",
    "        for child_old_id in tester.sub_module_nodes[old_id].children:\n",
    "            child_new_id = tester.sub_module_nodes[child_old_id].id\n",
    "            if return_graph.nodes[child_new_id]['weight'] < 0.001:\n",
    "                tester.sub_module_nodes[child_old_id].output_memory = return_graph.nodes[new_id]['output_tensors']\n",
    "                tester.sub_module_nodes[child_old_id].input_memory = return_graph.nodes[new_id]['output_tensors']\n",
    "                return_graph.nodes[child_new_id]['output_tensors'] = return_graph.nodes[new_id]['output_tensors']\n",
    "                return_graph.nodes[child_new_id]['output_memory'] = return_graph.nodes[new_id]['output_memory'].copy()\n",
    "\n",
    "    # change the id of edges\n",
    "    print(\"Filling in the edges\", '*'*20)\n",
    "    edge_count = 0\n",
    "    for node in tester.sub_module_nodes.keys():\n",
    "        children = tester.sub_module_nodes[node].children\n",
    "        node_new_id = tester.sub_module_nodes[node].id\n",
    "        for kid in children:\n",
    "            kid_new_id = tester.sub_module_nodes[kid].id\n",
    "            edge_data = {\n",
    "                \"weight\": 0, \"id\": edge_count, \"tensor\": [],\n",
    "                # the requested bytes <= min(from_node's output size, to_node's input size)\n",
    "                \"requested_bytes\": min(tester.sub_module_nodes[node].output_memory, tester.sub_module_nodes[kid].input_memory),\n",
    "            }\n",
    "            if edge_data['requested_bytes'] != 0:\n",
    "                # set the weight of the data base on 7.3 * (10 ^ (-7)) * x \n",
    "                edge_data['weight'] = 7.3 * (edge_data['requested_bytes'] / (10 ** 7))\n",
    "            edge_data['tensor'] = [{\"name\": str(edge_count), \"recv_end_ts\": 0, \"weight\": edge_data['weight']}]\n",
    "            return_graph.add_edge(node_new_id, kid_new_id, **edge_data)\n",
    "            #return_graph.add_edge(kid_new_id, node_new_id, **edge_data)\n",
    "            edge_count += 1\n",
    "            \n",
    "    if args.type == \"all\":\n",
    "        print(\"Yet to implement\")\n",
    "        return 0, 0\n",
    "\n",
    "    return return_graph, tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = sm.toyToyModel(factor=3)\n",
    "#inp_size = (3, 299, 299)\n",
    "\n",
    "#model = sm.linearModel(factor=3)\n",
    "#inp_size = (1, 10000)\n",
    "\n",
    "#model = sm.parallelToyModel(factor=3)\n",
    "#inp_size = (3, 299, 299)\n",
    "\n",
    "#model = sm.toyModel(factor=1)\n",
    "#inp_size = (3, 299, 299)\n",
    "\n",
    "model = inception_modified.inception_v3(pretrained=True)\n",
    "inp_size = (3, 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal2): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal3): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal3): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal3): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal3): _concatenateLayer()\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal4): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal5): _concatenateLayer()\n",
       "    (concatenateFinal6): _concatenateLayer()\n",
       "    (concatenateFinal7): _concatenateLayer()\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (concatenateFinal5): _concatenateLayer()\n",
       "    (concatenateFinal6): _concatenateLayer()\n",
       "    (concatenateFinal7): _concatenateLayer()\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  (addLayer): _addLayer()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling started ********************\n",
      "--> Module name:  Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "--> Module name:  Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "--> Module name:  Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([32, 1000])) that is different to the input size (torch.Size([1000])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Linear(in_features=768, out_features=1000, bias=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "--> Module name:  BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "--> Module name:  BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "--> Module name:  Dropout(p=0.5, inplace=False)\n",
      "--> Module name:  Linear(in_features=2048, out_features=1000, bias=True)\n",
      "--> Module name:  _addLayer()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/cuda/memory.py:263: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_dot started ********************\n",
      "Dealing with this variable: <AddBackward0 object at 0x7f6af4fd4860>\n",
      "Dealing with this variable: <SelectBackward object at 0x7f6af4f3a8d0>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7f6a92d6c710>\n",
      "Dealing with this variable: <ViewBackward object at 0x7f6a92d6c668>\n",
      "Dealing with this variable: <FusedDropoutBackward object at 0x7f6a92b67390>\n",
      "Dealing with this variable: <MeanBackward1 object at 0x7f6a92b675f8>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67518>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b675c0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b67f98>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b67c88>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b679b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67a20>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b67a90>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b67be0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67438>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67550>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa048>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa0b8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa198>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa240>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa2b0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa390>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa438>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa550>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa5c0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa6a0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa748>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa860>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa8d0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa9b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caaa58>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caab70>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caabe0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caacc0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caad68>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caae80>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caaef0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caafd0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f0b8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f198>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f208>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f2e8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f390>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f4a8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f518>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f5f8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f6a0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f7b8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f828>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f908>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f9b0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fac8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fb38>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92d3fc18>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fcc0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fd30>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fda0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fe80>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3ff28>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3ff98>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92b760b8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76160>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b761d0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76240>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76320>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b763c8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76438>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76518>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b765c0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76630>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b76710>\n",
      "Dealing with this variable: <AddBackward0 object at 0x7f6a92b767b8>\n",
      "Dealing with this variable: <MulBackward0 object at 0x7f6a92b76898>\n",
      "Dealing with this variable: <UnsqueezeBackward0 object at 0x7f6a92b76908>\n",
      "Dealing with this variable: <SelectBackward object at 0x7f6a92b76978>\n",
      "Dealing with this variable: <SliceBackward object at 0x7f6a92b769e8>\n",
      "Dealing with this variable: <AddBackward0 object at 0x7f6a92b767f0>\n",
      "Dealing with this variable: <MulBackward0 object at 0x7f6a92b768d0>\n",
      "Dealing with this variable: <UnsqueezeBackward0 object at 0x7f6a92b769b0>\n",
      "Dealing with this variable: <SelectBackward object at 0x7f6a92b76a58>\n",
      "Dealing with this variable: <SliceBackward object at 0x7f6a92b76ac8>\n",
      "Dealing with this variable: <AddBackward0 object at 0x7f6a92b76828>\n",
      "Dealing with this variable: <MulBackward0 object at 0x7f6a92b76940>\n",
      "Dealing with this variable: <UnsqueezeBackward0 object at 0x7f6a92b76a90>\n",
      "Dealing with this variable: <SelectBackward object at 0x7f6a92b76b38>\n",
      "Dealing with this variable: <SliceBackward object at 0x7f6a92b76ba8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f9e8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fb00>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fbe0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fcf8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fe48>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3feb8>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92d3fc18>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fa20>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fba8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fc88>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fdd8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fef0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76080>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76208>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76278>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76390>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92d3fc18>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fa58>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3fc50>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fe10>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92b76048>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92d3fc18>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f6d8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f7f0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f8d0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fa90>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3ffd0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76128>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f908>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f710>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f898>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f978>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3fb70>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76198>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76358>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76470>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b765f8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b766d8>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f908>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f748>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f940>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3ff60>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92b762e8>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f908>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f3c8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f4e0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f5c0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f780>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b760f0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b764e0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f5f8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f400>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f588>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f668>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b762b0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76400>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b766a0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76860>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76b70>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76c18>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f5f8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f438>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f630>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f860>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92b76588>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f5f8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f0f0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f1d0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f2b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f470>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b764a8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76780>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76b00>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76cc0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76cf8>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f2e8>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92d3f128>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92d3f2e8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caada0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caaeb8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caaf98>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f160>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f358>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3fd68>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76a20>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76c88>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76d68>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caafd0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caadd8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caaf60>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f048>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92d3f240>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76748>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76be0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76da0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76e80>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76ef0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76fd0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa30b8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3128>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3208>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa32b0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3320>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caafd0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caae10>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caaf28>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92d3f320>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92b76668>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caafd0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caaa90>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caaba8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caac88>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caae48>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f080>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76d30>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76e48>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76f98>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3048>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caacc0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caaac8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caac50>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caad30>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76550>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76dd8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76f60>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3080>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3240>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa32e8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3400>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa34a8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3518>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa35f8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa36a0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3710>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caacc0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caab00>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f278>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caacf8>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92b76eb8>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caacc0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa780>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92d3f550>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa940>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caaa20>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b76c50>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b76f28>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3160>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3358>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3438>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa9b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa7b8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa898>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa9e8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b76e10>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa30f0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa33c8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3470>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3630>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa36d8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa37f0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3898>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3908>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa39e8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3a90>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3b00>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa9b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa7f0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa908>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caac18>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92aa3278>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa9b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa470>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa588>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa668>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa828>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3198>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa34e0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3550>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3748>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3828>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa6a0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa4a8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa630>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa710>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa31d0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3588>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa37b8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3860>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3a20>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3ac8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3be0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3c88>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3cf8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3dd8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3e80>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3ef0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa6a0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa4e0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa6d8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa978>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92aa3668>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa6a0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b678d0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa080>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa160>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa278>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa2e8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa400>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3390>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3978>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa39b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3b38>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3c50>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3d68>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa390>\n",
      "Dealing with this variable: <MaxPool2DWithIndicesBackward object at 0x7f6a92b67668>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa390>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b677b8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67470>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b67e48>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b67780>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa208>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa358>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caab38>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67438>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b676a0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b67a58>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa128>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92caa208>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67898>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67940>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa320>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa3c8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa38d0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3ba8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3b70>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3e10>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3eb8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3f98>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67438>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67278>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa1d0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92caa518>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa38d0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67860>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa0f0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3780>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92aa3cc0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67438>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67da0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b677f0>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92b676d8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b67240>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3940>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3c18>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3e48>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b679b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67ba8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92caa5f8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92b67358>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa3940>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b67320>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67828>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3d30>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3da0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa4048>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa40f0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa4160>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa4240>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa42e8>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa4358>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b679b0>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67ac8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa35c0>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3f60>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa4048>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92b67e80>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa3a58>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa3fd0>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92aa41d0>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92b679b0>\n",
      "Dealing with this variable: <TBackward object at 0x7f6a92d6c9b0>\n",
      "Dealing with this variable: <SelectBackward object at 0x7f6af4f3ad30>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7f6a92d6c6a0>\n",
      "Dealing with this variable: <ViewBackward object at 0x7f6a92b67d68>\n",
      "Dealing with this variable: <MeanBackward1 object at 0x7f6a92b670b8>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa40b8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa4080>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa4198>\n",
      "Dealing with this variable: <ReluBackward1 object at 0x7f6a92aa43c8>\n",
      "Dealing with this variable: <CudnnBatchNormBackward object at 0x7f6a92aa4438>\n",
      "Dealing with this variable: <CudnnConvolutionBackward object at 0x7f6a92aa44a8>\n",
      "Dealing with this variable: <AvgPool2DBackward object at 0x7f6a92aa4588>\n",
      "Dealing with this variable: <CatBackward object at 0x7f6a92caa390>\n",
      "Dealing with this variable: <TBackward object at 0x7f6a92b67208>\n",
      "Sort topologically ********************\n",
      "Replacing sub module id ********************\n",
      "Filling in the edges ********************\n"
     ]
    }
   ],
   "source": [
    "return_graph, tester = build_graph(model, args.prof_gpu_id, args.prof_rounds, inp_size = inp_size)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##### Testing code\n",
    "tester = Profiling(model, args.prof_gpu_id, args.prof_rounds, input_size = inp_size)\n",
    "final_output = tester.run()\n",
    "#print(tester.sub_module_nodes)\n",
    "return_graph = make_dot(final_output, tester)\n",
    "\n",
    "print ('*'*50)\n",
    "print ('*'*50)\n",
    "for node_id in tester.sub_module_nodes.keys():\n",
    "    model_node = tester.sub_module_nodes[node_id]\n",
    "    if len(model_node.parent)==0 and len(model_node.children)==0:\n",
    "        print(model_node.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(return_graph, node_size=10, font_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.4935900370279948, 'reverse_weight': 0.08889973958333332, 'id': 3, 'topo_order': 3, 'temporary_memory': 133632, 'persistent_memory': 3456, 'output_memory': [90935296.0], 'output_tensors': 90935296.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.874010721842448, 'reverse_weight': 0.06598307291666666, 'id': 8, 'topo_order': 8, 'temporary_memory': 0, 'persistent_memory': 256, 'output_memory': [90935296.0], 'output_tensors': 90935296.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 1.5896002451578775, 'reverse_weight': 0.09422200520833332, 'id': 10, 'topo_order': 10, 'temporary_memory': 130048, 'persistent_memory': 36864, 'output_memory': [88510464.0], 'output_tensors': 88510464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.8066972096761067, 'reverse_weight': 0.06661783854166667, 'id': 11, 'topo_order': 11, 'temporary_memory': 0, 'persistent_memory': 256, 'output_memory': [88510464.0], 'output_tensors': 88510464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 2.720340092976888, 'reverse_weight': 0.11271158854166666, 'id': 12, 'topo_order': 12, 'temporary_memory': 130048, 'persistent_memory': 73728, 'output_memory': [177020928.0], 'output_tensors': 177020928.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 1.5632947285970054, 'reverse_weight': 0.05694986979166667, 'id': 13, 'topo_order': 13, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [177020928.0], 'output_tensors': 177020928.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)', 'name': 'MaxPool2d', 'weight': 0.8214632670084636, 'reverse_weight': 0.047314453125, 'id': 14, 'topo_order': 14, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [43655168.0], 'output_tensors': 43655168.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.471337636311849, 'reverse_weight': 0.09606119791666666, 'id': 15, 'topo_order': 15, 'temporary_memory': 32256, 'persistent_memory': 20480, 'output_memory': [54568960.0], 'output_tensors': 54568960.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.5457083384195963, 'reverse_weight': 0.064208984375, 'id': 16, 'topo_order': 16, 'temporary_memory': 0, 'persistent_memory': 640, 'output_memory': [54568960.0], 'output_tensors': 54568960.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 3.4972349802652993, 'reverse_weight': 0.09021809895833334, 'id': 17, 'topo_order': 17, 'temporary_memory': 408305664, 'persistent_memory': 552960, 'output_memory': [123887616.0], 'output_tensors': 123887616.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 1.1566480000813801, 'reverse_weight': 0.056494140624999994, 'id': 18, 'topo_order': 18, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [123887616.0], 'output_tensors': 123887616.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)', 'name': 'MaxPool2d', 'weight': 0.5801677703857422, 'reverse_weight': 0.05830078124999999, 'id': 19, 'topo_order': 19, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [30105600.0], 'output_tensors': 30105600.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.1803398132324219, 'reverse_weight': 0.09689127604166665, 'id': 22, 'topo_order': 22, 'temporary_memory': 7680, 'persistent_memory': 49152, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16083717346191403, 'reverse_weight': 0.08264973958333333, 'id': 25, 'topo_order': 25, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.17217000325520834, 'reverse_weight': 0.09737955729166665, 'id': 20, 'topo_order': 20, 'temporary_memory': 7680, 'persistent_memory': 36864, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.14368693033854166, 'reverse_weight': 0.06673177083333334, 'id': 24, 'topo_order': 24, 'temporary_memory': 0, 'persistent_memory': 384, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.47200520833333326, 'reverse_weight': 0.09137369791666668, 'id': 27, 'topo_order': 27, 'temporary_memory': 40841216, 'persistent_memory': 307200, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16104380289713544, 'reverse_weight': 0.08123372395833334, 'id': 28, 'topo_order': 28, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.17862319946289065, 'reverse_weight': 0.09890950520833335, 'id': 21, 'topo_order': 21, 'temporary_memory': 7680, 'persistent_memory': 49152, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1657962799072266, 'reverse_weight': 0.06652018229166666, 'id': 26, 'topo_order': 26, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.5082130432128906, 'reverse_weight': 0.08728841145833333, 'id': 30, 'topo_order': 30, 'temporary_memory': 60817408, 'persistent_memory': 221184, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.22007624308268228, 'reverse_weight': 0.06629231770833334, 'id': 31, 'topo_order': 31, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.626977284749349, 'reverse_weight': 0.09226888020833332, 'id': 32, 'topo_order': 32, 'temporary_memory': 73400320, 'persistent_memory': 331776, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.22099812825520834, 'reverse_weight': 0.095947265625, 'id': 33, 'topo_order': 33, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.14276504516601562, 'reverse_weight': 0.09794921875000001, 'id': 23, 'topo_order': 23, 'temporary_memory': 7680, 'persistent_memory': 24576, 'output_memory': [5017600.0], 'output_tensors': 5017600.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11518796284993489, 'reverse_weight': 0.06057942708333333, 'id': 29, 'topo_order': 29, 'temporary_memory': 0, 'persistent_memory': 256, 'output_memory': [5017600.0], 'output_tensors': 5017600.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.24814605712890622, 'reverse_weight': 0.04697265625, 'id': 34, 'topo_order': 34, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [40140800.0], 'output_tensors': 40140800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.21419525146484378, 'reverse_weight': 0.09558919270833333, 'id': 36, 'topo_order': 36, 'temporary_memory': 7680, 'persistent_memory': 65536, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16042391459147134, 'reverse_weight': 0.07957356770833335, 'id': 38, 'topo_order': 38, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.20454724629720053, 'reverse_weight': 0.09890950520833333, 'id': 37, 'topo_order': 37, 'temporary_memory': 7680, 'persistent_memory': 49152, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.14163653055826825, 'reverse_weight': 0.06495768229166665, 'id': 42, 'topo_order': 42, 'temporary_memory': 0, 'persistent_memory': 384, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.46947797139485675, 'reverse_weight': 0.09251302083333335, 'id': 45, 'topo_order': 45, 'temporary_memory': 40841216, 'persistent_memory': 307200, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1605351765950521, 'reverse_weight': 0.08055013020833333, 'id': 47, 'topo_order': 47, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.21122296651204428, 'reverse_weight': 0.09874674479166666, 'id': 35, 'topo_order': 35, 'temporary_memory': 7680, 'persistent_memory': 65536, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.159152348836263, 'reverse_weight': 0.06459960937499999, 'id': 39, 'topo_order': 39, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.5066553751627605, 'reverse_weight': 0.08924153645833334, 'id': 43, 'topo_order': 43, 'temporary_memory': 60817408, 'persistent_memory': 221184, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.2199014027913411, 'reverse_weight': 0.06796875000000001, 'id': 44, 'topo_order': 44, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.6251176198323568, 'reverse_weight': 0.09550781249999998, 'id': 46, 'topo_order': 46, 'temporary_memory': 73400320, 'persistent_memory': 331776, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.22234916687011713, 'reverse_weight': 0.09941406249999998, 'id': 48, 'topo_order': 48, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.207821528116862, 'reverse_weight': 0.09993489583333333, 'id': 40, 'topo_order': 40, 'temporary_memory': 7680, 'persistent_memory': 65536, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16132990519205728, 'reverse_weight': 0.063427734375, 'id': 41, 'topo_order': 41, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.27586619059244794, 'reverse_weight': 0.04871419270833333, 'id': 49, 'topo_order': 49, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [45158400.0], 'output_tensors': 45158400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.23067792256673175, 'reverse_weight': 0.09746093750000001, 'id': 52, 'topo_order': 52, 'temporary_memory': 7680, 'persistent_memory': 73728, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16202926635742188, 'reverse_weight': 0.08401692708333335, 'id': 55, 'topo_order': 55, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.2211888631184896, 'reverse_weight': 0.10340169270833333, 'id': 50, 'topo_order': 50, 'temporary_memory': 7680, 'persistent_memory': 55296, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.14408429463704428, 'reverse_weight': 0.066796875, 'id': 54, 'topo_order': 54, 'temporary_memory': 0, 'persistent_memory': 384, 'output_memory': [7526400.0], 'output_tensors': 7526400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.4691918690999348, 'reverse_weight': 0.09607747395833333, 'id': 56, 'topo_order': 56, 'temporary_memory': 40841216, 'persistent_memory': 307200, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16276041666666666, 'reverse_weight': 0.08240559895833334, 'id': 59, 'topo_order': 59, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.22959709167480466, 'reverse_weight': 0.10250651041666667, 'id': 51, 'topo_order': 51, 'temporary_memory': 7680, 'persistent_memory': 73728, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16061464945475262, 'reverse_weight': 0.06728515625, 'id': 58, 'topo_order': 58, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.5046526590983073, 'reverse_weight': 0.09251302083333333, 'id': 60, 'topo_order': 60, 'temporary_memory': 60817408, 'persistent_memory': 221184, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.22023518880208331, 'reverse_weight': 0.06971028645833334, 'id': 61, 'topo_order': 61, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.6241480509440103, 'reverse_weight': 0.10385742187500001, 'id': 62, 'topo_order': 62, 'temporary_memory': 73400320, 'persistent_memory': 331776, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.22063255310058594, 'reverse_weight': 0.11305338541666665, 'id': 63, 'topo_order': 63, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.22532145182291669, 'reverse_weight': 0.10431315104166666, 'id': 53, 'topo_order': 53, 'temporary_memory': 7680, 'persistent_memory': 73728, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.162204106648763, 'reverse_weight': 0.06668294270833335, 'id': 57, 'topo_order': 57, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.274499257405599, 'reverse_weight': 0.05091145833333333, 'id': 64, 'topo_order': 64, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [45158400.0], 'output_tensors': 45158400.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 1.9549051920572915, 'reverse_weight': 0.11868489583333332, 'id': 66, 'topo_order': 66, 'temporary_memory': 2048, 'persistent_memory': 3981312, 'output_memory': [14204928.0], 'output_tensors': 14204928.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.18583933512369794, 'reverse_weight': 0.09249674479166665, 'id': 68, 'topo_order': 68, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [14204928.0], 'output_tensors': 14204928.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.22843678792317706, 'reverse_weight': 0.11736653645833334, 'id': 65, 'topo_order': 65, 'temporary_memory': 7680, 'persistent_memory': 73728, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.16069412231445312, 'reverse_weight': 0.082177734375, 'id': 67, 'topo_order': 67, 'temporary_memory': 0, 'persistent_memory': 512, 'output_memory': [10035200.0], 'output_tensors': 10035200.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.4984378814697266, 'reverse_weight': 0.10991210937500001, 'id': 69, 'topo_order': 69, 'temporary_memory': 60817408, 'persistent_memory': 221184, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.2213478088378906, 'reverse_weight': 0.08190104166666667, 'id': 70, 'topo_order': 70, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [15052800.0], 'output_tensors': 15052800.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.30412673950195307, 'reverse_weight': 0.13178710937500002, 'id': 71, 'topo_order': 71, 'temporary_memory': 2048, 'persistent_memory': 331776, 'output_memory': [3551232.0], 'output_tensors': 3551232.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1044909159342448, 'reverse_weight': 0.11608072916666667, 'id': 72, 'topo_order': 72, 'temporary_memory': 0, 'persistent_memory': 768, 'output_memory': [3551232.0], 'output_tensors': 3551232.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.1811504364013672, 'reverse_weight': 0.05498046875, 'id': 73, 'topo_order': 73, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [28409856.0], 'output_tensors': 28409856.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.365146001180013, 'reverse_weight': 0.11528320312500001, 'id': 75, 'topo_order': 75, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13081232706705728, 'reverse_weight': 0.09690755208333335, 'id': 79, 'topo_order': 79, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.2933502197265625, 'reverse_weight': 0.13017578125, 'id': 77, 'topo_order': 77, 'temporary_memory': 2048, 'persistent_memory': 393216, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.10670026143391928, 'reverse_weight': 0.08383789062500001, 'id': 78, 'topo_order': 78, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.3256956736246745, 'reverse_weight': 0.14736328125, 'id': 80, 'topo_order': 80, 'temporary_memory': 21168640, 'persistent_memory': 458752, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1129309336344401, 'reverse_weight': 0.08704427083333333, 'id': 81, 'topo_order': 81, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.4023551940917969, 'reverse_weight': 0.15208333333333332, 'id': 86, 'topo_order': 86, 'temporary_memory': 27017728, 'persistent_memory': 688128, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13214747111002606, 'reverse_weight': 0.10076497395833331, 'id': 87, 'topo_order': 87, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.29557545979817706, 'reverse_weight': 0.13167317708333331, 'id': 74, 'topo_order': 74, 'temporary_memory': 2048, 'persistent_memory': 393216, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.10846455891927083, 'reverse_weight': 0.08951822916666666, 'id': 76, 'topo_order': 76, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.30449231465657556, 'reverse_weight': 0.15239257812499998, 'id': 83, 'topo_order': 83, 'temporary_memory': 21168640, 'persistent_memory': 458752, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11353492736816406, 'reverse_weight': 0.087109375, 'id': 84, 'topo_order': 84, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.3172556559244792, 'reverse_weight': 0.14866536458333332, 'id': 88, 'topo_order': 88, 'temporary_memory': 21168640, 'persistent_memory': 458752, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.10968844095865887, 'reverse_weight': 0.08663736979166667, 'id': 89, 'topo_order': 89, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.3078778584798177, 'reverse_weight': 0.1511393229166667, 'id': 90, 'topo_order': 90, 'temporary_memory': 21168640, 'persistent_memory': 458752, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.10911623636881511, 'reverse_weight': 0.08938802083333333, 'id': 91, 'topo_order': 91, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [4734976.0], 'output_tensors': 4734976.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.4155953725179035, 'reverse_weight': 0.16767578125000002, 'id': 92, 'topo_order': 92, 'temporary_memory': 27017728, 'persistent_memory': 688128, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13128916422526038, 'reverse_weight': 0.12371419270833334, 'id': 93, 'topo_order': 93, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3616491953531901, 'reverse_weight': 0.12602539062499998, 'id': 82, 'topo_order': 82, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13138453165690103, 'reverse_weight': 0.077294921875, 'id': 85, 'topo_order': 85, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.17954508463541669, 'reverse_weight': 0.0623046875, 'id': 94, 'topo_order': 94, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [28409856.0], 'output_tensors': 28409856.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3654638926188151, 'reverse_weight': 0.12371419270833334, 'id': 97, 'topo_order': 97, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12796719868977866, 'reverse_weight': 0.105029296875, 'id': 99, 'topo_order': 99, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3569285074869792, 'reverse_weight': 0.12740885416666667, 'id': 95, 'topo_order': 95, 'temporary_memory': 2048, 'persistent_memory': 491520, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11375745137532553, 'reverse_weight': 0.09109700520833333, 'id': 96, 'topo_order': 96, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.4328250885009765, 'reverse_weight': 0.15641276041666666, 'id': 103, 'topo_order': 103, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11952718098958334, 'reverse_weight': 0.09112955729166668, 'id': 105, 'topo_order': 105, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.47240257263183594, 'reverse_weight': 0.16142578125, 'id': 106, 'topo_order': 106, 'temporary_memory': 30220800, 'persistent_memory': 860160, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13149579366048178, 'reverse_weight': 0.10564778645833331, 'id': 107, 'topo_order': 107, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3577232360839844, 'reverse_weight': 0.1279296875, 'id': 98, 'topo_order': 98, 'temporary_memory': 2048, 'persistent_memory': 491520, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11363029479980472, 'reverse_weight': 0.09031575520833335, 'id': 101, 'topo_order': 101, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.42090415954589844, 'reverse_weight': 0.156787109375, 'id': 104, 'topo_order': 104, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11971791585286456, 'reverse_weight': 0.08945312500000001, 'id': 108, 'topo_order': 108, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.43344497680664057, 'reverse_weight': 0.15568033854166669, 'id': 109, 'topo_order': 109, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11962254842122397, 'reverse_weight': 0.09005533854166668, 'id': 110, 'topo_order': 110, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.419918696085612, 'reverse_weight': 0.15525716145833335, 'id': 111, 'topo_order': 111, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12083053588867189, 'reverse_weight': 0.09080403645833332, 'id': 112, 'topo_order': 112, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.48588116963704436, 'reverse_weight': 0.16669921875000002, 'id': 113, 'topo_order': 113, 'temporary_memory': 30220800, 'persistent_memory': 860160, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1306851704915365, 'reverse_weight': 0.12443033854166669, 'id': 114, 'topo_order': 114, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.357659657796224, 'reverse_weight': 0.13155924479166664, 'id': 100, 'topo_order': 100, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13024012247721356, 'reverse_weight': 0.08131510416666667, 'id': 102, 'topo_order': 102, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.18145243326822916, 'reverse_weight': 0.066552734375, 'id': 115, 'topo_order': 115, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [28409856.0], 'output_tensors': 28409856.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3670692443847656, 'reverse_weight': 0.12755533854166667, 'id': 120, 'topo_order': 120, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12852350870768228, 'reverse_weight': 0.11012369791666668, 'id': 127, 'topo_order': 127, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.355831782023112, 'reverse_weight': 0.13253580729166667, 'id': 116, 'topo_order': 116, 'temporary_memory': 2048, 'persistent_memory': 491520, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11529922485351562, 'reverse_weight': 0.09539388020833334, 'id': 122, 'topo_order': 122, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.43578147888183594, 'reverse_weight': 0.16638997395833333, 'id': 124, 'topo_order': 124, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.119781494140625, 'reverse_weight': 0.09653320312500001, 'id': 126, 'topo_order': 126, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.4699230194091797, 'reverse_weight': 0.17263997395833333, 'id': 129, 'topo_order': 129, 'temporary_memory': 30220800, 'persistent_memory': 860160, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1307328542073568, 'reverse_weight': 0.11321614583333332, 'id': 131, 'topo_order': 131, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3559271494547526, 'reverse_weight': 0.13740234375000002, 'id': 117, 'topo_order': 117, 'temporary_memory': 2048, 'persistent_memory': 491520, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.11498133341471352, 'reverse_weight': 0.09578450520833334, 'id': 118, 'topo_order': 118, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.41864713033040357, 'reverse_weight': 0.16494140624999998, 'id': 123, 'topo_order': 123, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12029012044270831, 'reverse_weight': 0.09703776041666669, 'id': 125, 'topo_order': 125, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.43099721272786456, 'reverse_weight': 0.16743164062500002, 'id': 128, 'topo_order': 128, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12005170186360677, 'reverse_weight': 0.09900716145833333, 'id': 130, 'topo_order': 130, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.4207293192545572, 'reverse_weight': 0.16608072916666666, 'id': 132, 'topo_order': 132, 'temporary_memory': 27156992, 'persistent_memory': 716800, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12164115905761719, 'reverse_weight': 0.09684244791666664, 'id': 133, 'topo_order': 133, 'temporary_memory': 0, 'persistent_memory': 1280, 'output_memory': [5918720.0], 'output_tensors': 5918720.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.48492749532063795, 'reverse_weight': 0.17700195312499997, 'id': 134, 'topo_order': 134, 'temporary_memory': 30220800, 'persistent_memory': 860160, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13224283854166669, 'reverse_weight': 0.13395182291666666, 'id': 135, 'topo_order': 135, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3604888916015625, 'reverse_weight': 0.13766276041666667, 'id': 119, 'topo_order': 119, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1277605692545573, 'reverse_weight': 0.08372395833333332, 'id': 121, 'topo_order': 121, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.17987887064615884, 'reverse_weight': 0.07086588541666666, 'id': 136, 'topo_order': 136, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [28409856.0], 'output_tensors': 28409856.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3628730773925781, 'reverse_weight': 0.13377278645833332, 'id': 143, 'topo_order': 143, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13033548990885416, 'reverse_weight': 0.11287434895833334, 'id': 149, 'topo_order': 149, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3609021504720052, 'reverse_weight': 0.1341796875, 'id': 137, 'topo_order': 137, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12909571329752606, 'reverse_weight': 0.09752604166666667, 'id': 139, 'topo_order': 139, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.5556583404541015, 'reverse_weight': 0.18551432291666667, 'id': 141, 'topo_order': 141, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13303756713867188, 'reverse_weight': 0.11295572916666669, 'id': 146, 'topo_order': 146, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.5379199981689453, 'reverse_weight': 0.19687500000000002, 'id': 147, 'topo_order': 147, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1301765441894531, 'reverse_weight': 0.13243815104166665, 'id': 150, 'topo_order': 150, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.36129951477050787, 'reverse_weight': 0.15709635416666665, 'id': 140, 'topo_order': 140, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12756983439127606, 'reverse_weight': 0.11197916666666666, 'id': 144, 'topo_order': 144, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.5448182423909506, 'reverse_weight': 0.19381510416666667, 'id': 145, 'topo_order': 145, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13049443562825522, 'reverse_weight': 0.11009114583333333, 'id': 148, 'topo_order': 148, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.5544503529866537, 'reverse_weight': 0.20021158854166665, 'id': 151, 'topo_order': 151, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13111432393391925, 'reverse_weight': 0.114892578125, 'id': 152, 'topo_order': 152, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.542147954305013, 'reverse_weight': 0.20633138020833333, 'id': 153, 'topo_order': 153, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13446807861328125, 'reverse_weight': 0.12091471354166668, 'id': 154, 'topo_order': 154, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.5589803059895834, 'reverse_weight': 0.2240885416666667, 'id': 155, 'topo_order': 155, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13024012247721356, 'reverse_weight': 0.16531575520833333, 'id': 156, 'topo_order': 156, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.35775502522786456, 'reverse_weight': 0.17757161458333331, 'id': 138, 'topo_order': 138, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12744267781575522, 'reverse_weight': 0.11149088541666669, 'id': 142, 'topo_order': 142, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.18038749694824222, 'reverse_weight': 0.12916666666666668, 'id': 157, 'topo_order': 157, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [28409856.0], 'output_tensors': 28409856.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.12213389078776041, 'reverse_weight': 0.19430338541666667, 'id': 158, 'topo_order': 158, 'temporary_memory': 0, 'persistent_memory': 393216, 'output_memory': [409600.0], 'output_tensors': 409600.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08573532104492188, 'reverse_weight': 0.13136393229166665, 'id': 160, 'topo_order': 160, 'temporary_memory': 0, 'persistent_memory': 1024, 'output_memory': [409600.0], 'output_tensors': 409600.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3095944722493489, 'reverse_weight': 0.252880859375, 'id': 164, 'topo_order': 164, 'temporary_memory': 0, 'persistent_memory': 9830400, 'output_memory': [98304.0], 'output_tensors': 98304.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09167989095052083, 'reverse_weight': 0.21300455729166665, 'id': 166, 'topo_order': 166, 'temporary_memory': 0, 'persistent_memory': 6144, 'output_memory': [98304.0], 'output_tensors': 98304.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Linear(in_features=768, out_features=1000, bias=True)', 'name': 'Linear', 'weight': 0.0937938690185547, 'reverse_weight': 0.1943359375, 'id': 169, 'topo_order': 169, 'temporary_memory': 0, 'persistent_memory': 3076000, 'output_memory': [128000.0], 'output_tensors': 128000.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.36274592081705725, 'reverse_weight': 0.17950846354166666, 'id': 161, 'topo_order': 161, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.12892087300618488, 'reverse_weight': 0.13043619791666666, 'id': 163, 'topo_order': 163, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.5510330200195312, 'reverse_weight': 0.20239257812499997, 'id': 167, 'topo_order': 167, 'temporary_memory': 512, 'persistent_memory': 2211840, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09016990661621094, 'reverse_weight': 0.15457356770833336, 'id': 170, 'topo_order': 170, 'temporary_memory': 0, 'persistent_memory': 2560, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.35939216613769537, 'reverse_weight': 0.19104817708333335, 'id': 159, 'topo_order': 159, 'temporary_memory': 2048, 'persistent_memory': 589824, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1308600107828776, 'reverse_weight': 0.12843424479166668, 'id': 162, 'topo_order': 162, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)', 'name': 'Conv2d', 'weight': 0.5596637725830078, 'reverse_weight': 0.22740885416666665, 'id': 165, 'topo_order': 165, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.13086001078287762, 'reverse_weight': 0.13450520833333335, 'id': 168, 'topo_order': 168, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.5450089772542317, 'reverse_weight': 0.24222005208333333, 'id': 171, 'topo_order': 171, 'temporary_memory': 33423872, 'persistent_memory': 1032192, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.1297473907470703, 'reverse_weight': 0.1296875, 'id': 172, 'topo_order': 172, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [7102464.0], 'output_tensors': 7102464.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)', 'name': 'Conv2d', 'weight': 0.3168582916259765, 'reverse_weight': 0.20320638020833334, 'id': 173, 'topo_order': 173, 'temporary_memory': 512, 'persistent_memory': 1327104, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08298556009928386, 'reverse_weight': 0.18180338541666666, 'id': 174, 'topo_order': 174, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.0820318857828776, 'reverse_weight': 0.08434244791666666, 'id': 175, 'topo_order': 175, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [10485760.0], 'output_tensors': 10485760.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.2525488535563151, 'reverse_weight': 0.18870442708333335, 'id': 176, 'topo_order': 176, 'temporary_memory': 512, 'persistent_memory': 1638400, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09053548177083333, 'reverse_weight': 0.1456217447916667, 'id': 179, 'topo_order': 179, 'temporary_memory': 0, 'persistent_memory': 2560, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3410657246907552, 'reverse_weight': 0.18583984375, 'id': 178, 'topo_order': 178, 'temporary_memory': 512, 'persistent_memory': 1966080, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09546279907226562, 'reverse_weight': 0.14259440104166668, 'id': 182, 'topo_order': 182, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.38619041442871105, 'reverse_weight': 0.188525390625, 'id': 185, 'topo_order': 185, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09056727091471355, 'reverse_weight': 0.12726236979166666, 'id': 187, 'topo_order': 187, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.38668314615885413, 'reverse_weight': 0.1912923177083333, 'id': 0, 'topo_order': 0, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09295145670572917, 'reverse_weight': 0.10901692708333334, 'id': 1, 'topo_order': 1, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.0629107157389323, 'reverse_weight': 0.08282877604166666, 'id': 188, 'topo_order': 188, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [6291456.0], 'output_tensors': 6291456.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3478368123372395, 'reverse_weight': 0.19596354166666669, 'id': 177, 'topo_order': 177, 'temporary_memory': 512, 'persistent_memory': 2293760, 'output_memory': [3670016.0], 'output_tensors': 3670016.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09717941284179688, 'reverse_weight': 0.12667643229166667, 'id': 181, 'topo_order': 181, 'temporary_memory': 0, 'persistent_memory': 3584, 'output_memory': [3670016.0], 'output_tensors': 3670016.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3976980845133463, 'reverse_weight': 0.16816406250000002, 'id': 184, 'topo_order': 184, 'temporary_memory': 40108032, 'persistent_memory': 6193152, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09899139404296874, 'reverse_weight': 0.14016927083333333, 'id': 186, 'topo_order': 186, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3870646158854167, 'reverse_weight': 0.18595377604166666, 'id': 189, 'topo_order': 189, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09218851725260419, 'reverse_weight': 0.1288411458333333, 'id': 190, 'topo_order': 190, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.386508305867513, 'reverse_weight': 0.19345703125000002, 'id': 4, 'topo_order': 4, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09328524271647134, 'reverse_weight': 0.10883789062499999, 'id': 5, 'topo_order': 5, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.061861673990885414, 'reverse_weight': 0.10768229166666665, 'id': 191, 'topo_order': 191, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [6291456.0], 'output_tensors': 6291456.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.24600028991699216, 'reverse_weight': 0.17991536458333335, 'id': 180, 'topo_order': 180, 'temporary_memory': 512, 'persistent_memory': 983040, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08282661437988281, 'reverse_weight': 0.10784505208333334, 'id': 183, 'topo_order': 183, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.11568069458007812, 'reverse_weight': 0.08733723958333335, 'id': 192, 'topo_order': 192, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [16777216.0], 'output_tensors': 16777216.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.6416956583658854, 'reverse_weight': 0.18159179687500002, 'id': 193, 'topo_order': 193, 'temporary_memory': 512, 'persistent_memory': 2621440, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08912086486816406, 'reverse_weight': 0.14163411458333333, 'id': 196, 'topo_order': 196, 'temporary_memory': 0, 'persistent_memory': 2560, 'output_memory': [2621440.0], 'output_tensors': 2621440.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.6399472554524739, 'reverse_weight': 0.18133138020833336, 'id': 197, 'topo_order': 197, 'temporary_memory': 512, 'persistent_memory': 3145728, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09217262268066408, 'reverse_weight': 0.13714192708333334, 'id': 200, 'topo_order': 200, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.38655598958333337, 'reverse_weight': 0.18486328125, 'id': 202, 'topo_order': 202, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09175936381022137, 'reverse_weight': 0.12190755208333333, 'id': 204, 'topo_order': 204, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.39002100626627595, 'reverse_weight': 0.18816731770833334, 'id': 6, 'topo_order': 6, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09150505065917969, 'reverse_weight': 0.10397135416666667, 'id': 7, 'topo_order': 7, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.06322860717773438, 'reverse_weight': 0.07972005208333334, 'id': 205, 'topo_order': 205, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [6291456.0], 'output_tensors': 6291456.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.6425221761067708, 'reverse_weight': 0.185302734375, 'id': 194, 'topo_order': 194, 'temporary_memory': 512, 'persistent_memory': 3670016, 'output_memory': [3670016.0], 'output_tensors': 3670016.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09624163309733072, 'reverse_weight': 0.12081705729166668, 'id': 199, 'topo_order': 199, 'temporary_memory': 0, 'persistent_memory': 3584, 'output_memory': [3670016.0], 'output_tensors': 3670016.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.38962364196777355, 'reverse_weight': 0.16860351562500006, 'id': 201, 'topo_order': 201, 'temporary_memory': 40108032, 'persistent_memory': 6193152, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09975433349609376, 'reverse_weight': 0.13787434895833336, 'id': 203, 'topo_order': 203, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.38652420043945307, 'reverse_weight': 0.18191731770833333, 'id': 206, 'topo_order': 206, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.09061495463053386, 'reverse_weight': 0.12589518229166669, 'id': 207, 'topo_order': 207, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)', 'name': 'Conv2d', 'weight': 0.3875732421875, 'reverse_weight': 0.1978515625, 'id': 2, 'topo_order': 2, 'temporary_memory': 512, 'persistent_memory': 1769472, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08993148803710938, 'reverse_weight': 0.11399739583333335, 'id': 9, 'topo_order': 9, 'temporary_memory': 0, 'persistent_memory': 3072, 'output_memory': [3145728.0], 'output_tensors': 3145728.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.061464309692382806, 'reverse_weight': 0.11333007812500001, 'id': 208, 'topo_order': 208, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [6291456.0], 'output_tensors': 6291456.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)', 'name': 'Conv2d', 'weight': 0.3563563028971354, 'reverse_weight': 0.22724609375, 'id': 195, 'topo_order': 195, 'temporary_memory': 512, 'persistent_memory': 1572864, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)', 'name': 'BatchNorm2d', 'weight': 0.08343060811360678, 'reverse_weight': 0.135107421875, 'id': 198, 'topo_order': 198, 'temporary_memory': 0, 'persistent_memory': 1536, 'output_memory': [1572864.0], 'output_tensors': 1572864.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_concatenateLayer()', 'name': '_concatenateLayer', 'weight': 0.11564890543619791, 'reverse_weight': 0.0431640625, 'id': 209, 'topo_order': 209, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [16777216.0], 'output_tensors': 16777216.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'AdaptiveAvgPool2d(output_size=(1, 1))', 'name': 'AdaptiveAvgPool2d', 'weight': 0.10681152343750001, 'reverse_weight': 0.07488606770833332, 'id': 210, 'topo_order': 210, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [262144.0], 'output_tensors': 262144.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Dropout(p=0.5, inplace=False)', 'name': 'Dropout', 'weight': 0.05307197570800781, 'reverse_weight': 0.13413085937500002, 'id': 211, 'topo_order': 211, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [262144.0], 'output_tensors': 262144.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': 'Linear(in_features=2048, out_features=1000, bias=True)', 'name': 'Linear', 'weight': 0.1068592071533203, 'reverse_weight': 0.25325520833333337, 'id': 212, 'topo_order': 212, 'temporary_memory': 0, 'persistent_memory': 8196000, 'output_memory': [128000.0], 'output_tensors': 128000.0, 'colocation_group': ''}\n",
      "**********************************************************************\n",
      "{'model': '_addLayer()', 'name': '_addLayer', 'weight': 0.030008951822916664, 'reverse_weight': 0.504345703125, 'id': 213, 'topo_order': 213, 'temporary_memory': 0, 'persistent_memory': 0, 'output_memory': [4000.0], 'output_tensors': 4000.0, 'colocation_group': ''}\n",
      "**********************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2821595744.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for curid in list(return_graph.nodes):\n",
    "    print(return_graph.nodes[curid])\n",
    "    print('*'*70)\n",
    "    \n",
    "netsum = 0\n",
    "for curid in list(return_graph.nodes):\n",
    "    net_mem = return_graph.nodes[curid]['persistent_memory'] + return_graph.nodes[curid]['output_memory'][0]\n",
    "    netsum = netsum + net_mem\n",
    "netsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_devices = range(args.gpu_num)\n",
    "available_device_list = {k:device_list[k] for k in available_devices}\n",
    "DEVICE_GRAPH_MULTIPLE = create_device_graph(available_device_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 15:25:27,037 - m_sct_v1:157 - INFO - Start LP solver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : min             \n",
      "  Type                   : LO (linear optimization problem)\n",
      "  Constraints            : 1585            \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 460             \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer started.\n",
      "Presolve started.\n",
      "Linear dependency checker started.\n",
      "Linear dependency checker terminated.\n",
      "Eliminator started.\n",
      "Freed constraints in eliminator : 159\n",
      "Eliminator terminated.\n",
      "Eliminator - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - number                 : 0               \n",
      "Presolve terminated. Time: 0.01    \n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : min             \n",
      "  Type                   : LO (linear optimization problem)\n",
      "  Constraints            : 1585            \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 460             \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer  - threads                : 16              \n",
      "Optimizer  - solved problem         : the dual        \n",
      "Optimizer  - Constraints            : 188\n",
      "Optimizer  - Cones                  : 0\n",
      "Optimizer  - Scalar variables       : 407               conic                  : 0               \n",
      "Optimizer  - Semi-definite variables: 0                 scalarized             : 0               \n",
      "Factor     - setup time             : 0.00              dense det. time        : 0.00            \n",
      "Factor     - ML order time          : 0.00              GP order time          : 0.00            \n",
      "Factor     - nonzeros before factor : 737               after factor           : 1043            \n",
      "Factor     - dense dim.             : 0                 flops                  : 1.51e+04        \n",
      "ITE PFEAS    DFEAS    GFEAS    PRSTATUS   POBJ              DOBJ              MU       TIME  \n",
      "0   7.1e+00  6.7e+01  2.8e+01  1.00e+00   1.512009303e+01   1.929431512e+02   1.0e+00  0.01  \n",
      "1   8.9e+00  6.8e+01  1.9e+01  0.00e+00   4.676142168e+01   -6.357016408e+01  2.3e+00  0.03  \n",
      "2   1.4e+00  1.0e+01  2.9e+00  -1.78e+00  8.158415395e+04   6.580735140e+04   3.6e-01  0.03  \n",
      "3   3.5e-01  2.6e+00  7.5e-01  5.68e+00   8.277547193e+02   7.275077463e+02   9.1e-02  0.03  \n",
      "4   2.0e-01  1.6e+00  4.4e-01  3.02e+00   6.051378032e+02   5.713184231e+02   5.3e-02  0.03  \n",
      "5   1.2e-02  3.2e-01  3.0e-01  2.21e+00   4.072581677e+02   4.204953531e+02   9.9e-03  0.03  \n",
      "6   2.6e-03  7.0e-02  6.6e-02  1.86e+00   2.682377664e+02   2.700065507e+02   2.2e-03  0.03  \n",
      "7   1.8e-03  4.8e-02  4.5e-02  1.30e+00   2.574358692e+02   2.585823046e+02   1.5e-03  0.03  \n",
      "8   9.1e-04  2.5e-02  2.3e-02  1.20e+00   2.461095855e+02   2.466760518e+02   7.6e-04  0.03  \n",
      "9   1.1e-04  3.1e-03  2.9e-03  1.10e+00   2.366593208e+02   2.367280802e+02   9.5e-05  0.03  \n",
      "10  6.0e-07  1.6e-05  1.5e-05  1.01e+00   2.354120937e+02   2.354124578e+02   5.0e-07  0.03  \n",
      "11  1.1e-08  3.1e-07  2.9e-07  1.00e+00   2.354047357e+02   2.354047427e+02   9.4e-09  0.03  \n",
      "12  1.1e-12  3.1e-11  3.6e-11  1.00e+00   2.354046137e+02   2.354046137e+02   9.4e-13  0.04  \n",
      "Basis identification started.\n",
      "Basis identification terminated. Time: 0.00\n",
      "Optimizer terminated. Time: 0.06    \n",
      "\n",
      "\n",
      "Interior-point solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 2.3540461366e+02    nrm: 2e+02    Viol.  con: 2e-11    var: 0e+00  \n",
      "  Dual.    obj: 2.3540461366e+02    nrm: 1e+02    Viol.  con: 2e-12    var: 1e-10  \n",
      "\n",
      "Basic solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 2.3540461366e+02    nrm: 2e+02    Viol.  con: 4e-09    var: 0e+00  \n",
      "  Dual.    obj: 2.3540461365e+02    nrm: 1e+02    Viol.  con: 0e+00    var: 4e-16  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 15:25:27,121 - m_sct_v1:162 - INFO - LP solver finished. Relaxed makespan soultion: 235.404614\n",
      "2021-09-21 15:25:27,123 - m_sct_v1:140 - INFO - Favorite child round threshold: 0.5\n",
      "2021-09-21 15:25:27,127 - m_sct:143 - INFO - # favorite child: 171\n",
      "2021-09-21 15:25:27,128 - m_sct:144 - INFO - # favorite child changes: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available mem:  8000000000\n",
      "Op memory: 91072384.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  8000000000\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  8000000000\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)  :  1769472\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7995084800.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7995084800.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7995081728.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7995081728.0\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)  :  1769472\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "True\n",
      "Available mem:  7990166528.0\n",
      "Op memory: 91072384.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7990166528.0\n",
      "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)  :  3456\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 90935552.0\n",
      "0\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7899227776.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7899227776.0\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)  :  1769472\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7894312576.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7894312576.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 90935552.0\n",
      "0\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7894309504.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7894309504.0\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)  :  1769472\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7889394304.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889394304.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 90935552.0\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 90935552.0\n",
      "0\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 90935552.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 90935552.0\n",
      "True\n",
      "Available mem:  7889391232.0\n",
      "Op memory: 90935552.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889391232.0\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  256\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 88677376.0\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 88677376.0\n",
      "0\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7889390976.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889390976.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7889387904.0\n",
      "Op memory: 88677376.0\n",
      "Available mem:  7889387904.0\n",
      "Op memory: 88677376.0\n",
      "0\n",
      "Available mem:  7889387904.0\n",
      "Op memory: 88677376.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889387904.0\n",
      "Op memory: 88677376.0\n",
      "True\n",
      "Available mem:  7889387904.0\n",
      "Op memory: 88677376.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889387904.0\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)  :  36864\n",
      "Available mem:  7891775872.0\n",
      "Op memory: 88510720.0\n",
      "Available mem:  7891775872.0\n",
      "Op memory: 88510720.0\n",
      "0\n",
      "Available mem:  7891775872.0\n",
      "Op memory: 88510720.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891775872.0\n",
      "Op memory: 88510720.0\n",
      "True\n",
      "Available mem:  7891775872.0\n",
      "Op memory: 88510720.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891775872.0\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  256\n",
      "Available mem:  7891775616.0\n",
      "Op memory: 177224704.0\n",
      "Available mem:  7891775616.0\n",
      "Op memory: 177224704.0\n",
      "0\n",
      "Available mem:  7891775616.0\n",
      "Op memory: 177224704.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891775616.0\n",
      "Op memory: 177224704.0\n",
      "True\n",
      "Available mem:  7891775616.0\n",
      "Op memory: 177224704.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891775616.0\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  73728\n",
      "Available mem:  7803191424.0\n",
      "Op memory: 177021440.0\n",
      "Available mem:  7803191424.0\n",
      "Op memory: 177021440.0\n",
      "0\n",
      "Available mem:  7803191424.0\n",
      "Op memory: 177021440.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7803191424.0\n",
      "Op memory: 177021440.0\n",
      "True\n",
      "Available mem:  7803191424.0\n",
      "Op memory: 177021440.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7803191424.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7803190912.0\n",
      "Op memory: 43655168.0\n",
      "Available mem:  7803190912.0\n",
      "Op memory: 43655168.0\n",
      "0\n",
      "Available mem:  7803190912.0\n",
      "Op memory: 43655168.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7803190912.0\n",
      "Op memory: 43655168.0\n",
      "True\n",
      "Available mem:  7803190912.0\n",
      "Op memory: 43655168.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7803190912.0\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  :  0\n",
      "Available mem:  7936556672.0\n",
      "Op memory: 54621696.0\n",
      "Available mem:  7936556672.0\n",
      "Op memory: 54621696.0\n",
      "0\n",
      "Available mem:  7936556672.0\n",
      "Op memory: 54621696.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936556672.0\n",
      "Op memory: 54621696.0\n",
      "True\n",
      "Available mem:  7936556672.0\n",
      "Op memory: 54621696.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936556672.0\n",
      "Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  20480\n",
      "Available mem:  7925622400.0\n",
      "Op memory: 54569600.0\n",
      "Available mem:  7925622400.0\n",
      "Op memory: 54569600.0\n",
      "0\n",
      "Available mem:  7925622400.0\n",
      "Op memory: 54569600.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7925622400.0\n",
      "Op memory: 54569600.0\n",
      "True\n",
      "Available mem:  7925622400.0\n",
      "Op memory: 54569600.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7925622400.0\n",
      "BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  640\n",
      "Available mem:  7925621760.0\n",
      "Op memory: 532746240.0\n",
      "Available mem:  7925621760.0\n",
      "Op memory: 532746240.0\n",
      "0\n",
      "Available mem:  7925621760.0\n",
      "Op memory: 532746240.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7925621760.0\n",
      "Op memory: 532746240.0\n",
      "True\n",
      "Available mem:  7925621760.0\n",
      "Op memory: 532746240.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7925621760.0\n",
      "Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)  :  552960\n",
      "Available mem:  7855750144.0\n",
      "Op memory: 123889152.0\n",
      "Available mem:  7855750144.0\n",
      "Op memory: 123889152.0\n",
      "0\n",
      "Available mem:  7855750144.0\n",
      "Op memory: 123889152.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7855750144.0\n",
      "Op memory: 123889152.0\n",
      "True\n",
      "Available mem:  7855750144.0\n",
      "Op memory: 123889152.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7855750144.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7855748608.0\n",
      "Op memory: 30105600.0\n",
      "Available mem:  7855748608.0\n",
      "Op memory: 30105600.0\n",
      "0\n",
      "Available mem:  7855748608.0\n",
      "Op memory: 30105600.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7855748608.0\n",
      "Op memory: 30105600.0\n",
      "True\n",
      "Available mem:  7855748608.0\n",
      "Op memory: 30105600.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7855748608.0\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)  :  0\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 7570944.0\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 10092032.0\n",
      "0\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 7570944.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 7570944.0\n",
      "True\n",
      "Available mem:  7949530624.0\n",
      "Op memory: 7570944.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7949530624.0\n",
      "Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  36864\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 7526784.0\n",
      "0\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "True\n",
      "Available mem:  7941967360.0\n",
      "Op memory: 10092032.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7941967360.0\n",
      "Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  49152\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "True\n",
      "Available mem:  7931883008.0\n",
      "Op memory: 10092032.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931883008.0\n",
      "Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  49152\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "True\n",
      "Available mem:  7921798656.0\n",
      "Op memory: 5049856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7921798656.0\n",
      "Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  24576\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 5017856.0\n",
      "0\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "True\n",
      "Available mem:  7946862080.0\n",
      "Op memory: 7526784.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7946862080.0\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  384\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 51183616.0\n",
      "0\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7946861696.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7946861696.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 51183616.0\n",
      "0\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7946861184.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7946861184.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "True\n",
      "Available mem:  7946860672.0\n",
      "Op memory: 51183616.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7946860672.0\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)  :  307200\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7944044672.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7944044672.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 5017856.0\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 5017856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 5017856.0\n",
      "True\n",
      "Available mem:  7944044160.0\n",
      "Op memory: 5017856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7944044160.0\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  256\n",
      "Available mem:  7944043904.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7944043904.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7944043904.0\n",
      "Op memory: 76091392.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7944043904.0\n",
      "Op memory: 76091392.0\n",
      "True\n",
      "Available mem:  7944043904.0\n",
      "Op memory: 76091392.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7944043904.0\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  221184\n",
      "Available mem:  7938805120.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7938805120.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7938805120.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938805120.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7938805120.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938805120.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7938804352.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7938804352.0\n",
      "Op memory: 88784896.0\n",
      "0\n",
      "Available mem:  7938804352.0\n",
      "Op memory: 88784896.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938804352.0\n",
      "Op memory: 88784896.0\n",
      "True\n",
      "Available mem:  7938804352.0\n",
      "Op memory: 88784896.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938804352.0\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  331776\n",
      "Available mem:  7938472576.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7938472576.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7938472576.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938472576.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7938472576.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938472576.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 40140800.0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 40140800.0\n",
      "0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 40140800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 40140800.0\n",
      "True\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 40140800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938471808.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "0\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "True\n",
      "Available mem:  7938471808.0\n",
      "Op memory: 10108416.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938471808.0\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  65536\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "True\n",
      "Available mem:  7928371072.0\n",
      "Op memory: 10108416.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7928371072.0\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  65536\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "True\n",
      "Available mem:  7918270336.0\n",
      "Op memory: 7583232.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7918270336.0\n",
      "Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  49152\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 7526784.0\n",
      "0\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7910694784.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7910694784.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 7526784.0\n",
      "0\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7910694272.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7910694272.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "True\n",
      "Available mem:  7910693760.0\n",
      "Op memory: 10108416.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7910693760.0\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  65536\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7940733824.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7940733824.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 7526784.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 7526784.0\n",
      "True\n",
      "Available mem:  7940733312.0\n",
      "Op memory: 7526784.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7940733312.0\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  384\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 51183616.0\n",
      "0\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "True\n",
      "Available mem:  7940732928.0\n",
      "Op memory: 76091392.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7940732928.0\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  221184\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7935494144.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7935494144.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 88784896.0\n",
      "0\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "True\n",
      "Available mem:  7935493376.0\n",
      "Op memory: 51183616.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7935493376.0\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)  :  307200\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "True\n",
      "Available mem:  7932677376.0\n",
      "Op memory: 88784896.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7932677376.0\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  331776\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7932345600.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7932345600.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7932345088.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7932345088.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7932345088.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7932345088.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7932345088.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Availale memory:  7932345088.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 45158400.0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 45158400.0\n",
      "0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 45158400.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 45158400.0\n",
      "True\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 45158400.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7932344320.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 7589376.0\n",
      "0\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 7589376.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 7589376.0\n",
      "True\n",
      "Available mem:  7932344320.0\n",
      "Op memory: 7589376.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7932344320.0\n",
      "Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  55296\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 7526784.0\n",
      "0\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "True\n",
      "Available mem:  7924762624.0\n",
      "Op memory: 10116608.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924762624.0\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  73728\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "True\n",
      "Available mem:  7914653696.0\n",
      "Op memory: 10116608.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7914653696.0\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  73728\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "True\n",
      "Available mem:  7904544768.0\n",
      "Op memory: 10116608.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7904544768.0\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  73728\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "True\n",
      "Available mem:  7939594240.0\n",
      "Op memory: 7526784.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7939594240.0\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  384\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 51183616.0\n",
      "0\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7939593856.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7939593856.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 51183616.0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 51183616.0\n",
      "0\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 51183616.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 51183616.0\n",
      "True\n",
      "Available mem:  7939593344.0\n",
      "Op memory: 51183616.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7939593344.0\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)  :  307200\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7936777344.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936777344.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7936776832.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936776832.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7936776320.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936776320.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7936775808.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7936775808.0\n",
      "Op memory: 76091392.0\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available mem:  7936775808.0\n",
      "Op memory: 76091392.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936775808.0\n",
      "Op memory: 76091392.0\n",
      "True\n",
      "Available mem:  7936775808.0\n",
      "Op memory: 76091392.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936775808.0\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  221184\n",
      "Available mem:  7931537024.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7931537024.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7931537024.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931537024.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7931537024.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931537024.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7931536256.0\n",
      "Op memory: 88784896.0\n",
      "Available mem:  7931536256.0\n",
      "Op memory: 88784896.0\n",
      "0\n",
      "Available mem:  7931536256.0\n",
      "Op memory: 88784896.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931536256.0\n",
      "Op memory: 88784896.0\n",
      "True\n",
      "Available mem:  7931536256.0\n",
      "Op memory: 88784896.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931536256.0\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  331776\n",
      "Available mem:  7931204480.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7931204480.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7931204480.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931204480.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7931204480.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931204480.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 45158400.0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 45158400.0\n",
      "0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 45158400.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 45158400.0\n",
      "True\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 45158400.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931203712.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 18188288.0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 10116608.0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 18188288.0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 10116608.0\n",
      "0\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 10116608.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 10116608.0\n",
      "True\n",
      "Available mem:  7931203712.0\n",
      "Op memory: 10116608.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931203712.0\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  73728\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 10035712.0\n",
      "0\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "True\n",
      "Available mem:  7921094784.0\n",
      "Op memory: 18188288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7921094784.0\n",
      "Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)  :  3981312\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 14208000.0\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 14208000.0\n",
      "0\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "True\n",
      "Available mem:  7902908544.0\n",
      "Op memory: 10035712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7902908544.0\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  512\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "True\n",
      "Available mem:  7902908032.0\n",
      "Op memory: 14208000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7902908032.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7902904960.0\n",
      "Op memory: 76091392.0\n",
      "Available mem:  7902904960.0\n",
      "Op memory: 76091392.0\n",
      "0\n",
      "Available mem:  7902904960.0\n",
      "Op memory: 76091392.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7902904960.0\n",
      "Op memory: 76091392.0\n",
      "True\n",
      "Available mem:  7902904960.0\n",
      "Op memory: 76091392.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7902904960.0\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  221184\n",
      "Available mem:  7897666176.0\n",
      "Op memory: 15053568.0\n",
      "Available mem:  7897666176.0\n",
      "Op memory: 15053568.0\n",
      "0\n",
      "Available mem:  7897666176.0\n",
      "Op memory: 15053568.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897666176.0\n",
      "Op memory: 15053568.0\n",
      "True\n",
      "Available mem:  7897666176.0\n",
      "Op memory: 15053568.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897666176.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7897665408.0\n",
      "Op memory: 3885056.0\n",
      "Available mem:  7897665408.0\n",
      "Op memory: 3885056.0\n",
      "0\n",
      "Available mem:  7897665408.0\n",
      "Op memory: 3885056.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897665408.0\n",
      "Op memory: 3885056.0\n",
      "True\n",
      "Available mem:  7897665408.0\n",
      "Op memory: 3885056.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897665408.0\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)  :  331776\n",
      "Available mem:  7908835200.0\n",
      "Op memory: 3552000.0\n",
      "Available mem:  7908835200.0\n",
      "Op memory: 3552000.0\n",
      "0\n",
      "Available mem:  7908835200.0\n",
      "Op memory: 3552000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7908835200.0\n",
      "Op memory: 3552000.0\n",
      "True\n",
      "Available mem:  7908835200.0\n",
      "Op memory: 3552000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7908835200.0\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  768\n",
      "Available mem:  7908834432.0\n",
      "Op memory: 28409856.0\n",
      "0\n",
      "Available mem:  7908834432.0\n",
      "Op memory: 28409856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7908834432.0\n",
      "Op memory: 28409856.0\n",
      "True\n",
      "Available mem:  7908834432.0\n",
      "Op memory: 28409856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7908834432.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 5130240.0\n",
      "0\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 5130240.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 5130240.0\n",
      "True\n",
      "Available mem:  7943339136.0\n",
      "Op memory: 5130240.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7943339136.0\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  393216\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7938210944.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938210944.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7930518656.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930518656.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "True\n",
      "Available mem:  7930517632.0\n",
      "Op memory: 5130240.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930517632.0\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  393216\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7925389440.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7925389440.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7925388416.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7925388416.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7925388416.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "True\n",
      "Available mem:  7925386880.0\n",
      "Op memory: 26362368.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7925386880.0\n",
      "Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  458752\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7924928128.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924928128.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 34808320.0\n",
      "0\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7924927104.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924927104.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "True\n",
      "Available mem:  7945644672.0\n",
      "Op memory: 26362368.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7945644672.0\n",
      "Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  458752\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7945185920.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7945185920.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7945184896.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7945184896.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 34808320.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 34808320.0\n",
      "True\n",
      "Available mem:  7945183360.0\n",
      "Op memory: 34808320.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7945183360.0\n",
      "Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  688128\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7942127744.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7942127744.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7942126208.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7942126208.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7942126208.0\n",
      "Op memory: 26362368.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7942126208.0\n",
      "Op memory: 26362368.0\n",
      "True\n",
      "Available mem:  7942126208.0\n",
      "Op memory: 26362368.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7942126208.0\n",
      "Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  458752\n",
      "Available mem:  7941667456.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7941667456.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7941667456.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7941667456.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7941667456.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7941667456.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7941666432.0\n",
      "Op memory: 26362368.0\n",
      "Available mem:  7941666432.0\n",
      "Op memory: 26362368.0\n",
      "0\n",
      "Available mem:  7941666432.0\n",
      "Op memory: 26362368.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7941666432.0\n",
      "Op memory: 26362368.0\n",
      "True\n",
      "Available mem:  7941666432.0\n",
      "Op memory: 26362368.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7941666432.0\n",
      "Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  458752\n",
      "Available mem:  7941207680.0\n",
      "Op memory: 4736000.0\n",
      "Available mem:  7941207680.0\n",
      "Op memory: 4736000.0\n",
      "0\n",
      "Available mem:  7941207680.0\n",
      "Op memory: 4736000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7941207680.0\n",
      "Op memory: 4736000.0\n",
      "True\n",
      "Available mem:  7941207680.0\n",
      "Op memory: 4736000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7941207680.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7941206656.0\n",
      "Op memory: 34808320.0\n",
      "Available mem:  7941206656.0\n",
      "Op memory: 34808320.0\n",
      "0\n",
      "Available mem:  7941206656.0\n",
      "Op memory: 34808320.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7941206656.0\n",
      "Op memory: 34808320.0\n",
      "True\n",
      "Available mem:  7941206656.0\n",
      "Op memory: 34808320.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7941206656.0\n",
      "Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  688128\n",
      "Available mem:  7938151040.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7938151040.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7938151040.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938151040.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7938151040.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938151040.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 28409856.0\n",
      "0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 28409856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 28409856.0\n",
      "True\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 28409856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938149504.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 6412288.0\n",
      "0\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 6412288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 6412288.0\n",
      "True\n",
      "Available mem:  7938149504.0\n",
      "Op memory: 6412288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938149504.0\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  491520\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7931739264.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931739264.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7931737984.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931737984.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "True\n",
      "Available mem:  7924045696.0\n",
      "Op memory: 6412288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924045696.0\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  491520\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7917635456.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7917635456.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7917633920.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7917633920.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7938351488.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938351488.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7938350208.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938350208.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7938348672.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7938348672.0\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  716800\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7937631872.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7937631872.0\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  716800\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7936915072.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936915072.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 38183424.0\n",
      "0\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 38183424.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 38183424.0\n",
      "True\n",
      "Available mem:  7936913792.0\n",
      "Op memory: 38183424.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7936913792.0\n",
      "Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  860160\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7934869888.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7934869888.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7934868352.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7934868352.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7934868352.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7934868352.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7934868352.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7934868352.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7934867072.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7934867072.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7934867072.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7934867072.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7934867072.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7934867072.0\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  716800\n",
      "Available mem:  7934150272.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7934150272.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7934150272.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7934150272.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7934150272.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7934150272.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7934148992.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7934148992.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7934148992.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7934148992.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7934148992.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7934148992.0\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  716800\n",
      "Available mem:  7933432192.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7933432192.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7933432192.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7933432192.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7933432192.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7933432192.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7933430912.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7933430912.0\n",
      "Op memory: 38183424.0\n",
      "0\n",
      "Available mem:  7933430912.0\n",
      "Op memory: 38183424.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7933430912.0\n",
      "Op memory: 38183424.0\n",
      "True\n",
      "Available mem:  7933430912.0\n",
      "Op memory: 38183424.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7933430912.0\n",
      "Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  860160\n",
      "Available mem:  7931387008.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931387008.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7931387008.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931387008.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7931387008.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931387008.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 28409856.0\n",
      "0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 28409856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 28409856.0\n",
      "True\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 28409856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931385472.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 6412288.0\n",
      "0\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 6412288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 6412288.0\n",
      "True\n",
      "Available mem:  7931385472.0\n",
      "Op memory: 6412288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931385472.0\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  491520\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "True\n",
      "Available mem:  7924975232.0\n",
      "Op memory: 6412288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924975232.0\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  491520\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7918564992.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7918564992.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7918563712.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7918563712.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7910871424.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7910871424.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7931588992.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931588992.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7931587456.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931587456.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7931586176.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7931586176.0\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  716800\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7930869376.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930869376.0\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  716800\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7930152576.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930152576.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7930151296.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930151296.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 38183424.0\n",
      "0\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7930150016.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930150016.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 38183424.0\n",
      "0\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7930148480.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7930148480.0\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  716800\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "True\n",
      "Available mem:  7929431680.0\n",
      "Op memory: 38183424.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7929431680.0\n",
      "Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  860160\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7927387776.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7927387776.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7927386496.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7927386496.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7927386496.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7927384960.0\n",
      "Op memory: 33792512.0\n",
      "Available mem:  7927384960.0\n",
      "Op memory: 33792512.0\n",
      "0\n",
      "Available mem:  7927384960.0\n",
      "Op memory: 33792512.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7927384960.0\n",
      "Op memory: 33792512.0\n",
      "True\n",
      "Available mem:  7927384960.0\n",
      "Op memory: 33792512.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7927384960.0\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  716800\n",
      "Available mem:  7926668160.0\n",
      "Op memory: 5920000.0\n",
      "Available mem:  7926668160.0\n",
      "Op memory: 5920000.0\n",
      "0\n",
      "Available mem:  7926668160.0\n",
      "Op memory: 5920000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7926668160.0\n",
      "Op memory: 5920000.0\n",
      "True\n",
      "Available mem:  7926668160.0\n",
      "Op memory: 5920000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7926668160.0\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1280\n",
      "Available mem:  7926666880.0\n",
      "Op memory: 38183424.0\n",
      "Available mem:  7926666880.0\n",
      "Op memory: 38183424.0\n",
      "0\n",
      "Available mem:  7926666880.0\n",
      "Op memory: 38183424.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7926666880.0\n",
      "Op memory: 38183424.0\n",
      "True\n",
      "Available mem:  7926666880.0\n",
      "Op memory: 38183424.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7926666880.0\n",
      "Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  860160\n",
      "Available mem:  7924622976.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7924622976.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7924622976.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924622976.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7924622976.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924622976.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 28409856.0\n",
      "0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 28409856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 28409856.0\n",
      "True\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 28409856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924621440.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "0\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7924621440.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7924621440.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7916929152.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7916929152.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7909236864.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7909236864.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7909235328.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7909235328.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7901543040.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7901543040.0\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  1032192\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7900510848.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7900510848.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7900509312.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7900509312.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7921226880.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7921226880.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7921225344.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7921225344.0\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  1032192\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7920193152.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7920193152.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7920191616.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7920191616.0\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  1032192\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7919159424.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7919159424.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7919157888.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7919157888.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7919156352.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7919156352.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7919154816.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7919154816.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7919154816.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7919154816.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7919154816.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7919154816.0\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  1032192\n",
      "Available mem:  7918122624.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7918122624.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7918122624.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7918122624.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7918122624.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7918122624.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7918121088.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7918121088.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7918121088.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7918121088.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7918121088.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7918121088.0\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  1032192\n",
      "Available mem:  7917088896.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7917088896.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7917088896.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7917088896.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7917088896.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7917088896.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7917087360.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7917087360.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7917087360.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7917087360.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7917087360.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7917087360.0\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  1032192\n",
      "Available mem:  7916055168.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7916055168.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7916055168.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7916055168.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7916055168.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7916055168.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 28409856.0\n",
      "0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 28409856.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 28409856.0\n",
      "True\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 28409856.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7916053632.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 802816.0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 802816.0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 7694336.0\n",
      "0\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 802816.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 802816.0\n",
      "True\n",
      "Available mem:  7916053632.0\n",
      "Op memory: 802816.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7916053632.0\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  393216\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 410624.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 410624.0\n",
      "0\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7915250816.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7915250816.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "True\n",
      "Available mem:  7907558528.0\n",
      "Op memory: 410624.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7907558528.0\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1024\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 9928704.0\n",
      "0\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "True\n",
      "Available mem:  7907557504.0\n",
      "Op memory: 7694336.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7907557504.0\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  589824\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7899865216.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7899865216.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7899863680.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7899863680.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 4833792.0\n",
      "0\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "True\n",
      "Available mem:  7899862144.0\n",
      "Op memory: 9928704.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-21 15:25:27,658 - m_sct:172 - INFO - SCT estimated runtime: 0.000067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Availale memory:  7899862144.0\n",
      "Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)  :  9830400\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 104448.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 104448.0\n",
      "0\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7890343040.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7890343040.0\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)  :  1032192\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "True\n",
      "Available mem:  7889310848.0\n",
      "Op memory: 104448.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889310848.0\n",
      "BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  6144\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 3204000.0\n",
      "0\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "True\n",
      "Available mem:  7889304704.0\n",
      "Op memory: 4833792.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889304704.0\n",
      "Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)  :  2211840\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 2624000.0\n",
      "0\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7891573888.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891573888.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "True\n",
      "Available mem:  7891572352.0\n",
      "Op memory: 3204000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891572352.0\n",
      "Linear(in_features=768, out_features=1000, bias=True)  :  3076000\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 2624000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 2624000.0\n",
      "True\n",
      "Available mem:  7888466656.0\n",
      "Op memory: 2624000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7888466656.0\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  2560\n",
      "Available mem:  7888464096.0\n",
      "Op memory: 41558528.0\n",
      "Available mem:  7888464096.0\n",
      "Op memory: 41558528.0\n",
      "0\n",
      "Available mem:  7888464096.0\n",
      "Op memory: 41558528.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7888464096.0\n",
      "Op memory: 41558528.0\n",
      "True\n",
      "Available mem:  7888464096.0\n",
      "Op memory: 41558528.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7888464096.0\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)  :  1032192\n",
      "Available mem:  7887431904.0\n",
      "Op memory: 7104000.0\n",
      "Available mem:  7887431904.0\n",
      "Op memory: 7104000.0\n",
      "0\n",
      "Available mem:  7887431904.0\n",
      "Op memory: 7104000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7887431904.0\n",
      "Op memory: 7104000.0\n",
      "True\n",
      "Available mem:  7887431904.0\n",
      "Op memory: 7104000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7887431904.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7887430368.0\n",
      "Op memory: 2900480.0\n",
      "Available mem:  7887430368.0\n",
      "Op memory: 2900480.0\n",
      "0\n",
      "Available mem:  7887430368.0\n",
      "Op memory: 2900480.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7887430368.0\n",
      "Op memory: 2900480.0\n",
      "True\n",
      "Available mem:  7887430368.0\n",
      "Op memory: 2900480.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7887430368.0\n",
      "Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)  :  1327104\n",
      "Available mem:  7891632864.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7891632864.0\n",
      "Op memory: 1574400.0\n",
      "0\n",
      "Available mem:  7891632864.0\n",
      "Op memory: 1574400.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891632864.0\n",
      "Op memory: 1574400.0\n",
      "True\n",
      "Available mem:  7891632864.0\n",
      "Op memory: 1574400.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891632864.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7891631328.0\n",
      "Op memory: 10485760.0\n",
      "0\n",
      "Available mem:  7891631328.0\n",
      "Op memory: 10485760.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891631328.0\n",
      "Op memory: 10485760.0\n",
      "True\n",
      "Available mem:  7891631328.0\n",
      "Op memory: 10485760.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891631328.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 4260352.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 5964288.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 4260352.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 5964288.0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 2556416.0\n",
      "0\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 4260352.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 4260352.0\n",
      "True\n",
      "Available mem:  7913749728.0\n",
      "Op memory: 4260352.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7913749728.0\n",
      "Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  1638400\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 2624000.0\n",
      "0\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "True\n",
      "Available mem:  7909489888.0\n",
      "Op memory: 5964288.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7909489888.0\n",
      "Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  2293760\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 3673600.0\n",
      "0\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "True\n",
      "Available mem:  7903526112.0\n",
      "Op memory: 5112320.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7903526112.0\n",
      "Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  1966080\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "True\n",
      "Available mem:  7898414304.0\n",
      "Op memory: 2624000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898414304.0\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  2560\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 2556416.0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 2556416.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 2556416.0\n",
      "True\n",
      "Available mem:  7898411744.0\n",
      "Op memory: 2556416.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898411744.0\n",
      "Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  983040\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 1574400.0\n",
      "0\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "True\n",
      "Available mem:  7906341600.0\n",
      "Op memory: 3673600.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7906341600.0\n",
      "BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3584\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 49446912.0\n",
      "0\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7906338016.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7906338016.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "True\n",
      "Available mem:  7906334944.0\n",
      "Op memory: 1574400.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7906334944.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 49446912.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 49446912.0\n",
      "True\n",
      "Available mem:  7906333408.0\n",
      "Op memory: 49446912.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7906333408.0\n",
      "Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  6193152\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7900664544.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7900664544.0\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)  :  1769472\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7898895072.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898895072.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7898892000.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898892000.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 6291456.0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 6291456.0\n",
      "0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 6291456.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 6291456.0\n",
      "True\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 6291456.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898888928.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7898888928.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7898888928.0\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)  :  1769472\n",
      "Available mem:  7897119456.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7897119456.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7897119456.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897119456.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7897119456.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897119456.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291456.0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291456.0\n",
      "0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291456.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291456.0\n",
      "True\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291456.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897116384.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 16777216.0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 16777216.0\n",
      "0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 16777216.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 16777216.0\n",
      "True\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 16777216.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897116384.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 5243392.0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 7340544.0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 3146240.0\n",
      "0\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 5243392.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 5243392.0\n",
      "True\n",
      "Available mem:  7897116384.0\n",
      "Op memory: 5243392.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7897116384.0\n",
      "Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  2621440\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 2624000.0\n",
      "0\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "True\n",
      "Available mem:  7891873504.0\n",
      "Op memory: 7340544.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891873504.0\n",
      "Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  3670016\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3673600.0\n",
      "0\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "True\n",
      "Available mem:  7884533472.0\n",
      "Op memory: 3146240.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7884533472.0\n",
      "Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  1572864\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 1574400.0\n",
      "0\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "True\n",
      "Available mem:  7881387744.0\n",
      "Op memory: 2624000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7881387744.0\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  2560\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 6291968.0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 1574400.0\n",
      "0\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 6291968.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 6291968.0\n",
      "True\n",
      "Available mem:  7881385184.0\n",
      "Op memory: 6291968.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7881385184.0\n",
      "Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)  :  3145728\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "True\n",
      "Available mem:  7891870944.0\n",
      "Op memory: 1574400.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891870944.0\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  1536\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3673600.0\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3673600.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3673600.0\n",
      "True\n",
      "Available mem:  7891869408.0\n",
      "Op memory: 3673600.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891869408.0\n",
      "BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3584\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 49446912.0\n",
      "0\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7891865824.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891865824.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "True\n",
      "Available mem:  7891862752.0\n",
      "Op memory: 49446912.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891862752.0\n",
      "Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)  :  6193152\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7886193888.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7886193888.0\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)  :  1769472\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7884424416.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7884424416.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7884421344.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7884421344.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 6291456.0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 6291456.0\n",
      "0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 6291456.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 6291456.0\n",
      "True\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 6291456.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7884418272.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "0\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "True\n",
      "Available mem:  7884418272.0\n",
      "Op memory: 4915712.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7884418272.0\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)  :  1769472\n",
      "Available mem:  7882648800.0\n",
      "Op memory: 3148800.0\n",
      "Available mem:  7882648800.0\n",
      "Op memory: 3148800.0\n",
      "0\n",
      "Available mem:  7882648800.0\n",
      "Op memory: 3148800.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7882648800.0\n",
      "Op memory: 3148800.0\n",
      "True\n",
      "Available mem:  7882648800.0\n",
      "Op memory: 3148800.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7882648800.0\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)  :  3072\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 6291456.0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 6291456.0\n",
      "0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 6291456.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 6291456.0\n",
      "True\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 6291456.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7882645728.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 16777216.0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 16777216.0\n",
      "0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 16777216.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 16777216.0\n",
      "True\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 16777216.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7882645728.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 262144.0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 262144.0\n",
      "0\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 262144.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 262144.0\n",
      "True\n",
      "Available mem:  7882645728.0\n",
      "Op memory: 262144.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7882645728.0\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))  :  0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 262144.0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 262144.0\n",
      "0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 262144.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 262144.0\n",
      "True\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 262144.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7899160800.0\n",
      "Dropout(p=0.5, inplace=False)  :  0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 8324000.0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 8324000.0\n",
      "0\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 8324000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 8324000.0\n",
      "True\n",
      "Available mem:  7899160800.0\n",
      "Op memory: 8324000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7899160800.0\n",
      "Linear(in_features=2048, out_features=1000, bias=True)  :  8196000\n",
      "Available mem:  7891098944.0\n",
      "Op memory: 4000.0\n",
      "Available mem:  7891098944.0\n",
      "Op memory: 4000.0\n",
      "0\n",
      "Available mem:  7891098944.0\n",
      "Op memory: 4000.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7891098944.0\n",
      "Op memory: 4000.0\n",
      "True\n",
      "Available mem:  7891098944.0\n",
      "Op memory: 4000.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7891098944.0\n",
      "_addLayer()  :  0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    placed_op_graph = m_sct(return_graph, DEVICE_GRAPH_MULTIPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_p(return_graph, tester)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Virtual Scheduler\n",
    "scheduler = VirtualScheduler(placed_op_graph, DEVICE_GRAPH_MULTIPLE, True)\n",
    "copy_p(return_graph, tester)\n",
    "scheduler.initialize()\n",
    "result = scheduler.run()\n",
    "# second last print line\n",
    "print(\"virtual scheduler result: {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "0\n",
      "\n",
      "Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "0\n",
      "\n",
      "Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Linear(in_features=768, out_features=1000, bias=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "0\n",
      "\n",
      "BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "0\n",
      "\n",
      "_concatenateLayer()\n",
      "0\n",
      "\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "0\n",
      "\n",
      "Dropout(p=0.5, inplace=False)\n",
      "0\n",
      "\n",
      "Linear(in_features=2048, out_features=1000, bias=True)\n",
      "0\n",
      "\n",
      "_addLayer()\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node_id in tester.sub_module_nodes:\n",
    "    print(tester.sub_module_nodes[node_id].module)\n",
    "    print(tester.sub_module_nodes[node_id].p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.20613289 GB\n",
      "Cached:    3.78320312 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually assign the nodes to the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assign(object):\n",
    "    \"\"\"\n",
    "    This class actually put each submodule to the gpu it is assigned to\n",
    "    \"\"\"\n",
    "    def __init__(self, model_wrapper):\n",
    "        self.model = model_wrapper\n",
    "        self.original_forwards = {}\n",
    "        self.assigned = self.recur_move_layers_to_gpus(model_wrapper.model)\n",
    "    \n",
    "    def recur_move_layers_to_gpus(self, module):\n",
    "        \n",
    "        this_assigner = self\n",
    "        sub_modules = module.__dict__['_modules']\n",
    "        if len(sub_modules) > 0:\n",
    "            for name, sub_module in sub_modules.items():\n",
    "                this_assigner.recur_move_layers_to_gpus(sub_module)\n",
    "        else:\n",
    "            module_id = id(module)\n",
    "            gpu_id = this_assigner.model.sub_module_nodes[module_id].p\n",
    "    \n",
    "            ### Move layers to the allotted GPUs\n",
    "            # module.to(gpu_id)\n",
    "            ########### FOR TESTING ##################################################\n",
    "            mem0, _ = print_mem(gpu_id, cached=0, unit='B')\n",
    "            module.to(gpu_id)\n",
    "            mem1, _ = print_mem(gpu_id, cached=0, unit='B')\n",
    "            print(\"Module:              \", module)\n",
    "            print(\"GPU:                 \", gpu_id)\n",
    "            print(\"Memory change:       \", mem1-mem0)\n",
    "            print(\"Layer size:          \", estimate_model_size(module, unit='B', to_print=False))\n",
    "            print(\"Net memory occupied: \", mem1)\n",
    "            print(\"*\"*50)\n",
    "            #########################################################################\n",
    "            \n",
    "            this_assigner.original_forwards[module_id] = module.forward\n",
    "\n",
    "            def modified_forward(self, *inputs):\n",
    "                #print(self)\n",
    "                #print(gpu_id)\n",
    "                #print('*'*50)\n",
    "                input_list = list(inputs)\n",
    "                for i, inp in enumerate(input_list):\n",
    "                    if isinstance(inp, torch.Tensor):\n",
    "                        #print(\"Getting input from \", inp.get_device(), \" to \", gpu_id)\n",
    "                        input_list[i] = inp.to(gpu_id)\n",
    "                    else:\n",
    "                        print(\"Input not a Tensor!\") ## Fix this\n",
    "                inputs = tuple(input_list)\n",
    "                output = this_assigner.original_forwards[module_id](*inputs) \n",
    "                # id(self) = module_id since forward is method of a module\n",
    "                return output\n",
    "\n",
    "            module.forward =  modified_forward.__get__(module, module.__class__)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tester' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-53bc141f5b9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAssign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtester\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tester' is not defined"
     ]
    }
   ],
   "source": [
    "Assign(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (int(args.batch_size),) + inp_size  # Concatenate the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken: 73.49387407302856\n"
     ]
    }
   ],
   "source": [
    "### Forward only run\n",
    "\n",
    "time2 = []\n",
    "\n",
    "for _ in range(50):\n",
    "    inp   = torch.rand(inp_size)\n",
    "    torch.cuda.synchronize(0); torch.cuda.synchronize(1)\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "    #if 1:\n",
    "        output = tester.model(inp)\n",
    "    torch.cuda.synchronize(0); torch.cuda.synchronize(1)\n",
    "    end = time.time()\n",
    "    time2.append(1000*(end-start))\n",
    "\n",
    "print(\"Mean time taken:\", np.mean(time2[10:]))\n",
    "mean_native = np.mean(time2[10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: 0\n",
      "Memory Usage:\n",
      "Allocated: 0.2046032 GB\n",
      "Cached:    1.23242188 GB\n",
      "-----------\n",
      "GPU: 1\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 2\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "-----------\n",
      "GPU: 3\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    3.78320312 GB\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Single GPU RUN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = sm.toyToyModel(factor=3)\n",
    "#inp_size = (args.batch_size, 3, 299, 299)\n",
    "\n",
    "#model = sm.linearModel(factor=3)\n",
    "#inp_size = (args.batch_size, 1, 10000)\n",
    "\n",
    "#model = sm.parallelToyModel(factor=3)\n",
    "#inp_size = (args.batch_size, 3, 299, 299)\n",
    "\n",
    "#model = sm.toyModel(factor=1)\n",
    "#inp_size = (args.batch_size, 3, 299, 299)\n",
    "\n",
    "model = inception_modified.inception_v3(pretrained=True)\n",
    "inp_size = (int(args.batch_size), 3, 299, 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean time taken: 65.67983627319336\n"
     ]
    }
   ],
   "source": [
    "### Forward only run\n",
    "model = model.to(1)\n",
    "time2 = []\n",
    "\n",
    "for _ in range(50):\n",
    "    inp   = torch.rand(inp_size).to(1)\n",
    "    torch.cuda.synchronize(0); torch.cuda.synchronize(1)\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "    #if 1:\n",
    "        output = model(inp)\n",
    "    torch.cuda.synchronize(0); torch.cuda.synchronize(1)\n",
    "    end = time.time()\n",
    "    time2.append(1000*(end-start))\n",
    "\n",
    "print(\"Mean time taken:\", np.mean(time2[10:]))\n",
    "mean_native = np.mean(time2[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Becnhmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _concatenateLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, *x):\n",
    "        return torch.cat(x, 1)\n",
    "    \n",
    "class _squeezeLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerLinearModel(nn.Module):\n",
    "\n",
    "    def __init__(self, factor: int = 1) -> None:\n",
    "        #super(TwoLayerLinearModel, self).__init__()  # syntax in python2, works in python3\n",
    "        # Explained here: https://stackoverflow.com/questions/61288224/why-not-super-init-model-self-in-pytorch\n",
    "        super().__init__() # python 3 syntax\n",
    "        \n",
    "        self.factor = factor\n",
    "        self.linear1N = 512*self.factor\n",
    "        self.linear2N = 2048*self.factor\n",
    "        self.linear3N = 1024*self.factor\n",
    "        self.linear4N = 2*self.linear3N\n",
    "        self.linear5N = 512*self.factor\n",
    "\n",
    "        self.squeeze = _squeezeLayer()\n",
    "        self.fc1 = nn.Linear(self.linear1N, self.linear2N)\n",
    "        self.fc2a = nn.Linear(self.linear2N, self.linear3N)\n",
    "        self.fc2b = nn.Linear(self.linear2N, self.linear3N)\n",
    "        self.concatenate = _concatenateLayer()\n",
    "        self.fc3 = nn.Linear(self.linear4N, self.linear5N)\n",
    "        self.fc4 = nn.Linear(self.linear5N, self.linear5N)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = self.fc1(x)\n",
    "        xb = self.fc2b(x)\n",
    "        xa = self.fc2a(x)\n",
    "        y = self.concatenate(xa,xb)\n",
    "        y = self.fc3(y)\n",
    "        y = self.fc4(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoLayerLinearModel(\n",
      "  (squeeze): _squeezeLayer()\n",
      "  (fc1): Linear(in_features=2560, out_features=10240, bias=True)\n",
      "  (fc2a): Linear(in_features=10240, out_features=5120, bias=True)\n",
      "  (fc2b): Linear(in_features=10240, out_features=5120, bias=True)\n",
      "  (concatenate): _concatenateLayer()\n",
      "  (fc3): Linear(in_features=10240, out_features=2560, bias=True)\n",
      "  (fc4): Linear(in_features=2560, out_features=2560, bias=True)\n",
      ")\n",
      "Profiling started ********************\n",
      "--> Module name:  _squeezeLayer()\n",
      "--> Module name:  Linear(in_features=2560, out_features=10240, bias=True)\n",
      "--> Module name:  Linear(in_features=10240, out_features=5120, bias=True)\n",
      "--> Module name:  Linear(in_features=10240, out_features=5120, bias=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Linear(in_features=10240, out_features=2560, bias=True)\n",
      "--> Module name:  Linear(in_features=2560, out_features=2560, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/loss.py:528: UserWarning: Using a target size (torch.Size([128, 128])) that is different to the input size (torch.Size([128, 2560])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/cshetty2/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/cuda/memory.py:263: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_dot started ********************\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd12c524940>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40f7da0>\n",
      "Dealing with this variable: <CatBackward object at 0x7fd12c50ccc0>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0db595f60>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0db5959b0>\n",
      "Dealing with this variable: <SqueezeBackward0 object at 0x7fd0db595e80>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0db595eb8>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0db5956d8>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0db5955c0>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0db5959b0>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0db595438>\n",
      "Dealing with this variable: <TBackward object at 0x7fd12c50ce10>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40f7438>\n",
      "Sort topologically ********************\n",
      "Replacing sub module id ********************\n",
      "Filling in the edges ********************\n"
     ]
    }
   ],
   "source": [
    "# Ensure these settings:\n",
    "# factor = 5\n",
    "# prof_gpu_id = 3\n",
    "# prof_rounds = 40\n",
    "# gpu_num = 2\n",
    "\n",
    "\n",
    "factor = 5\n",
    "inp_size = (1,512*factor)\n",
    "\n",
    "model = TwoLayerLinearModel(factor)\n",
    "\n",
    "print(model)\n",
    "\n",
    "\n",
    "#model = sm.parallelToyModel(factor=3)\n",
    "#inp_size = (3, 299, 299)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling started ********************\n",
      "--> Module name:  _squeezeLayer()\n",
      "--> Module name:  Linear(in_features=2560, out_features=10240, bias=True)\n",
      "--> Module name:  Linear(in_features=10240, out_features=5120, bias=True)\n",
      "--> Module name:  Linear(in_features=10240, out_features=5120, bias=True)\n",
      "--> Module name:  _concatenateLayer()\n",
      "--> Module name:  Linear(in_features=10240, out_features=2560, bias=True)\n",
      "--> Module name:  Linear(in_features=2560, out_features=2560, bias=True)\n",
      "make_dot started ********************\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd12c524940>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40cb710>\n",
      "Dealing with this variable: <CatBackward object at 0x7fd0d40cb668>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40cb518>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40cb438>\n",
      "Dealing with this variable: <SqueezeBackward0 object at 0x7fd0d40cbd68>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40cbf60>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40cb828>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40cbf28>\n",
      "Dealing with this variable: <AddmmBackward object at 0x7fd0d40cb438>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40cb5f8>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40cbfd0>\n",
      "Dealing with this variable: <TBackward object at 0x7fd0d40cb908>\n",
      "Sort topologically ********************\n",
      "Replacing sub module id ********************\n",
      "Filling in the edges ********************\n"
     ]
    }
   ],
   "source": [
    "return_graph, tester = build_graph(model, args.prof_gpu_id, args.prof_rounds, inp_size = inp_size)\n",
    "available_devices = range(args.gpu_num)\n",
    "available_device_list = {k:device_list[k] for k in available_devices}\n",
    "DEVICE_GRAPH_MULTIPLE = create_device_graph(available_device_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 10:45:22,385 - m_sct_v1:157 - INFO - Start LP solver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : min             \n",
      "  Type                   : LO (linear optimization problem)\n",
      "  Constraints            : 47              \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 15              \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer started.\n",
      "Presolve started.\n",
      "Linear dependency checker started.\n",
      "Linear dependency checker terminated.\n",
      "Eliminator started.\n",
      "Freed constraints in eliminator : 2\n",
      "Eliminator terminated.\n",
      "Eliminator - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - number                 : 0               \n",
      "Presolve terminated. Time: 0.00    \n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : min             \n",
      "  Type                   : LO (linear optimization problem)\n",
      "  Constraints            : 47              \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 15              \n",
      "  Matrix variables       : 0               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer  - threads                : 16              \n",
      "Optimizer  - solved problem         : the primal      \n",
      "Optimizer  - Constraints            : 8\n",
      "Optimizer  - Cones                  : 0\n",
      "Optimizer  - Scalar variables       : 16                conic                  : 0               \n",
      "Optimizer  - Semi-definite variables: 0                 scalarized             : 0               \n",
      "Factor     - setup time             : 0.00              dense det. time        : 0.00            \n",
      "Factor     - ML order time          : 0.00              GP order time          : 0.00            \n",
      "Factor     - nonzeros before factor : 23                after factor           : 25              \n",
      "Factor     - dense dim.             : 0                 flops                  : 3.58e+02        \n",
      "ITE PFEAS    DFEAS    GFEAS    PRSTATUS   POBJ              DOBJ              MU       TIME  \n",
      "0   3.1e+00  1.0e+00  3.0e+00  1.00e+00   5.984427452e+00   3.984427452e+00   1.0e+00  0.01  \n",
      "1   2.1e+00  2.0e+00  7.9e-01  0.00e+00   9.932826593e+00   1.172466284e+01   2.9e+00  0.02  \n",
      "2   4.5e-01  4.3e-01  1.7e-01  1.16e+00   1.002094406e+01   1.031390279e+01   6.3e-01  0.02  \n",
      "3   6.0e-02  5.7e-02  2.3e-02  1.48e+00   9.600098240e+00   9.635038197e+00   8.4e-02  0.02  \n",
      "4   1.4e-04  1.3e-04  5.2e-05  1.07e+00   9.427365271e+00   9.427494108e+00   1.9e-04  0.02  \n",
      "5   1.4e-08  1.3e-08  5.2e-09  1.00e+00   9.427269863e+00   9.427269876e+00   1.9e-08  0.02  \n",
      "Basis identification started.\n",
      "Basis identification terminated. Time: 0.00\n",
      "Optimizer terminated. Time: 0.04    \n",
      "\n",
      "\n",
      "Interior-point solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 9.4272698635e+00    nrm: 9e+00    Viol.  con: 1e-08    var: 0e+00  \n",
      "  Dual.    obj: 9.4272698964e+00    nrm: 4e+00    Viol.  con: 5e-09    var: 9e-09  \n",
      "\n",
      "Basic solution summary\n",
      "  Problem status  : PRIMAL_AND_DUAL_FEASIBLE\n",
      "  Solution status : OPTIMAL\n",
      "  Primal.  obj: 9.4272698539e+00    nrm: 9e+00    Viol.  con: 1e-15    var: 0e+00  \n",
      "  Dual.    obj: 9.4272698813e+00    nrm: 4e+00    Viol.  con: 1e-09    var: 6e-09  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-27 10:45:22,447 - m_sct_v1:162 - INFO - LP solver finished. Relaxed makespan soultion: 9.427270\n",
      "2021-09-27 10:45:22,450 - m_sct_v1:140 - INFO - Favorite child round threshold: 0.5\n",
      "2021-09-27 10:45:22,452 - m_sct:143 - INFO - # favorite child: 5\n",
      "2021-09-27 10:45:22,454 - m_sct:144 - INFO - # favorite child changes: 0\n",
      "2021-09-27 10:45:22,478 - m_sct:172 - INFO - SCT estimated runtime: 0.000010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "0\n",
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "Checking placement***************************************\n",
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "True\n",
      "Available mem:  8000000000\n",
      "Op memory: 1310720.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  8000000000\n",
      "_squeezeLayer()  :  0\n",
      "Available mem:  7998689280.0\n",
      "Op memory: 110141440.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 110141440.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 110141440.0\n",
      "Available mem:  7998689280.0\n",
      "Op memory: 110141440.0\n",
      "0\n",
      "Available mem:  7998689280.0\n",
      "Op memory: 110141440.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7998689280.0\n",
      "Op memory: 110141440.0\n",
      "True\n",
      "Available mem:  7998689280.0\n",
      "Op memory: 110141440.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7998689280.0\n",
      "Linear(in_features=2560, out_features=10240, bias=True)  :  104898560\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "0\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "True\n",
      "Available mem:  7889858560.0\n",
      "Op memory: 212357120.0\n",
      "********************\n",
      "Device id:  0\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7889858560.0\n",
      "Linear(in_features=10240, out_features=5120, bias=True)  :  209735680\n",
      "Available mem:  7677501440.0\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  7677501440.0\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "1\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "Checking placement***************************************\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "True\n",
      "Available mem:  8000000000\n",
      "Op memory: 212357120.0\n",
      "********************\n",
      "Device id:  1\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  8000000000\n",
      "Linear(in_features=10240, out_features=5120, bias=True)  :  209735680\n",
      "Available mem:  7682744320.0\n",
      "Op memory: 5242880.0\n",
      "Available mem:  7787642880.0\n",
      "Op memory: 5242880.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 5242880.0\n",
      "Available mem:  7787642880.0\n",
      "Op memory: 5242880.0\n",
      "1\n",
      "Available mem:  7787642880.0\n",
      "Op memory: 5242880.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7787642880.0\n",
      "Op memory: 5242880.0\n",
      "True\n",
      "Available mem:  7787642880.0\n",
      "Op memory: 5242880.0\n",
      "********************\n",
      "Device id:  1\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7787642880.0\n",
      "_concatenateLayer()  :  0\n",
      "Available mem:  7685365760.0\n",
      "Op memory: 106178560.0\n",
      "Available mem:  7785021440.0\n",
      "Op memory: 106178560.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 106178560.0\n",
      "Available mem:  7785021440.0\n",
      "Op memory: 106178560.0\n",
      "1\n",
      "Available mem:  7785021440.0\n",
      "Op memory: 106178560.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7785021440.0\n",
      "Op memory: 106178560.0\n",
      "True\n",
      "Available mem:  7785021440.0\n",
      "Op memory: 106178560.0\n",
      "********************\n",
      "Device id:  1\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7785021440.0\n",
      "Linear(in_features=10240, out_features=2560, bias=True)  :  104867840\n",
      "Available mem:  7685365760.0\n",
      "Op memory: 27535360.0\n",
      "Available mem:  7684085760.0\n",
      "Op memory: 27535360.0\n",
      "Available mem:  8000000000\n",
      "Op memory: 27535360.0\n",
      "Available mem:  7684085760.0\n",
      "Op memory: 27535360.0\n",
      "1\n",
      "Available mem:  7684085760.0\n",
      "Op memory: 27535360.0\n",
      "Checking placement***************************************\n",
      "Available mem:  7684085760.0\n",
      "Op memory: 27535360.0\n",
      "True\n",
      "Available mem:  7684085760.0\n",
      "Op memory: 27535360.0\n",
      "********************\n",
      "Device id:  1\n",
      "Memory limit:  8000000000\n",
      "Availale memory:  7684085760.0\n",
      "Linear(in_features=2560, out_features=2560, bias=True)  :  26224640\n",
      "_squeezeLayer()\n",
      "0\n",
      "\n",
      "Linear(in_features=2560, out_features=10240, bias=True)\n",
      "0\n",
      "\n",
      "Linear(in_features=10240, out_features=5120, bias=True)\n",
      "0\n",
      "\n",
      "Linear(in_features=10240, out_features=5120, bias=True)\n",
      "1\n",
      "\n",
      "_concatenateLayer()\n",
      "1\n",
      "\n",
      "Linear(in_features=10240, out_features=2560, bias=True)\n",
      "1\n",
      "\n",
      "Linear(in_features=2560, out_features=2560, bias=True)\n",
      "1\n",
      "\n",
      "Module:               _squeezeLayer()\n",
      "GPU:                  0\n",
      "Memory change:        0\n",
      "Layer size:           0\n",
      "Net memory occupied:  0\n",
      "**************************************************\n",
      "Module:               Linear(in_features=2560, out_features=10240, bias=True)\n",
      "GPU:                  0\n",
      "Memory change:        209797120\n",
      "Layer size:           104898560\n",
      "Net memory occupied:  209797120\n",
      "**************************************************\n",
      "Module:               Linear(in_features=10240, out_features=5120, bias=True)\n",
      "GPU:                  1\n",
      "Memory change:        419471360\n",
      "Layer size:           209735680\n",
      "Net memory occupied:  419471360\n",
      "**************************************************\n",
      "Module:               Linear(in_features=10240, out_features=5120, bias=True)\n",
      "GPU:                  0\n",
      "Memory change:        419471360\n",
      "Layer size:           209735680\n",
      "Net memory occupied:  629268480\n",
      "**************************************************\n",
      "Module:               _concatenateLayer()\n",
      "GPU:                  1\n",
      "Memory change:        0\n",
      "Layer size:           0\n",
      "Net memory occupied:  419471360\n",
      "**************************************************\n",
      "Module:               Linear(in_features=10240, out_features=2560, bias=True)\n",
      "GPU:                  1\n",
      "Memory change:        209735680\n",
      "Layer size:           104867840\n",
      "Net memory occupied:  629207040\n",
      "**************************************************\n",
      "Module:               Linear(in_features=2560, out_features=2560, bias=True)\n",
      "GPU:                  1\n",
      "Memory change:        54546432\n",
      "Layer size:           26224640\n",
      "Net memory occupied:  683753472\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Assign at 0x7fd0d4103160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    placed_op_graph = m_sct(return_graph, DEVICE_GRAPH_MULTIPLE)\n",
    "copy_p(return_graph, tester)\n",
    "\n",
    "for node_id in tester.sub_module_nodes:\n",
    "    print(tester.sub_module_nodes[node_id].module)\n",
    "    print(tester.sub_module_nodes[node_id].p)\n",
    "    print()\n",
    "\n",
    "    \n",
    "Assign(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-654db89ad645>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtester\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-7f09c7322493>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mxa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-67686597906e>\u001b[0m in \u001b[0;36mmodified_forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input not a Tensor!\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## Fix this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_assigner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_forwards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0;31m# id(self) = module_id since forward is method of a module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/baechi/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_INVALID_VALUE when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`"
     ]
    }
   ],
   "source": [
    "inp_size = (int(args.batch_size),) + inp_size\n",
    "\n",
    "times = []\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA]) as prof:\n",
    "    for _ in range(200):\n",
    "        torch.cuda.synchronize(0); torch.cuda.synchronize(1); torch.cuda.synchronize(2)\n",
    "        inp   = torch.rand(inp_size)\n",
    "        start = time.time()\n",
    "        #with torch.no_grad():\n",
    "        output = tester.model(inp)\n",
    "        torch.cuda.synchronize(0); torch.cuda.synchronize(1); torch.cuda.synchronize(2)\n",
    "        end = time.time()\n",
    "        times.append(1000*(end-start))\n",
    "prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "print(\"Mean time taken:\", np.mean(times[10:]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(args.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
